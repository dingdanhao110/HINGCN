NodeProblem: loading started
loading edge embedding for MAM complete, num of embeddings: 129098
loading edge embedding for MDM complete, num of embeddings: 5949
loading edge embedding for MWM complete, num of embeddings: 7100
NodeProblem: loading finished
Let's use 2 GPUs!
DataParallel(
  (module): HINGCN_GS(
    (prep): NodeEmbeddingPrep(
      (embedding): Embedding(3493, 32)
      (fc): Linear(in_features=32, out_features=32, bias=True)
    )
    (agg_0_0): ModuleList(
      (0): AttentionAggregator2(
        (att): Sequential(
          (0): Linear(in_features=32, out_features=512, bias=False)
          (1): Tanh()
          (2): Linear(in_features=512, out_features=512, bias=False)
        )
        (att2): Sequential(
          (0): Linear(in_features=50, out_features=512, bias=False)
          (1): Tanh()
          (2): Linear(in_features=512, out_features=512, bias=False)
        )
        (fc_x): Linear(in_features=32, out_features=64, bias=False)
        (fc_neib): Linear(in_features=50, out_features=64, bias=False)
        (dropout): Dropout(p=0.5)
      )
      (1): AttentionAggregator2(
        (att): Sequential(
          (0): Linear(in_features=32, out_features=512, bias=False)
          (1): Tanh()
          (2): Linear(in_features=512, out_features=512, bias=False)
        )
        (att2): Sequential(
          (0): Linear(in_features=50, out_features=512, bias=False)
          (1): Tanh()
          (2): Linear(in_features=512, out_features=512, bias=False)
        )
        (fc_x): Linear(in_features=32, out_features=64, bias=False)
        (fc_neib): Linear(in_features=50, out_features=64, bias=False)
        (dropout): Dropout(p=0.5)
      )
      (2): AttentionAggregator2(
        (att): Sequential(
          (0): Linear(in_features=32, out_features=512, bias=False)
          (1): Tanh()
          (2): Linear(in_features=512, out_features=512, bias=False)
        )
        (att2): Sequential(
          (0): Linear(in_features=50, out_features=512, bias=False)
          (1): Tanh()
          (2): Linear(in_features=512, out_features=512, bias=False)
        )
        (fc_x): Linear(in_features=32, out_features=64, bias=False)
        (fc_neib): Linear(in_features=50, out_features=64, bias=False)
        (dropout): Dropout(p=0.5)
      )
      (3): AttentionAggregator2(
        (att): Sequential(
          (0): Linear(in_features=32, out_features=512, bias=False)
          (1): Tanh()
          (2): Linear(in_features=512, out_features=512, bias=False)
        )
        (att2): Sequential(
          (0): Linear(in_features=50, out_features=512, bias=False)
          (1): Tanh()
          (2): Linear(in_features=512, out_features=512, bias=False)
        )
        (fc_x): Linear(in_features=32, out_features=64, bias=False)
        (fc_neib): Linear(in_features=50, out_features=64, bias=False)
        (dropout): Dropout(p=0.5)
      )
      (4): AttentionAggregator2(
        (att): Sequential(
          (0): Linear(in_features=32, out_features=512, bias=False)
          (1): Tanh()
          (2): Linear(in_features=512, out_features=512, bias=False)
        )
        (att2): Sequential(
          (0): Linear(in_features=50, out_features=512, bias=False)
          (1): Tanh()
          (2): Linear(in_features=512, out_features=512, bias=False)
        )
        (fc_x): Linear(in_features=32, out_features=64, bias=False)
        (fc_neib): Linear(in_features=50, out_features=64, bias=False)
        (dropout): Dropout(p=0.5)
      )
      (5): AttentionAggregator2(
        (att): Sequential(
          (0): Linear(in_features=32, out_features=512, bias=False)
          (1): Tanh()
          (2): Linear(in_features=512, out_features=512, bias=False)
        )
        (att2): Sequential(
          (0): Linear(in_features=50, out_features=512, bias=False)
          (1): Tanh()
          (2): Linear(in_features=512, out_features=512, bias=False)
        )
        (fc_x): Linear(in_features=32, out_features=64, bias=False)
        (fc_neib): Linear(in_features=50, out_features=64, bias=False)
        (dropout): Dropout(p=0.5)
      )
      (6): AttentionAggregator2(
        (att): Sequential(
          (0): Linear(in_features=32, out_features=512, bias=False)
          (1): Tanh()
          (2): Linear(in_features=512, out_features=512, bias=False)
        )
        (att2): Sequential(
          (0): Linear(in_features=50, out_features=512, bias=False)
          (1): Tanh()
          (2): Linear(in_features=512, out_features=512, bias=False)
        )
        (fc_x): Linear(in_features=32, out_features=64, bias=False)
        (fc_neib): Linear(in_features=50, out_features=64, bias=False)
        (dropout): Dropout(p=0.5)
      )
      (7): AttentionAggregator2(
        (att): Sequential(
          (0): Linear(in_features=32, out_features=512, bias=False)
          (1): Tanh()
          (2): Linear(in_features=512, out_features=512, bias=False)
        )
        (att2): Sequential(
          (0): Linear(in_features=50, out_features=512, bias=False)
          (1): Tanh()
          (2): Linear(in_features=512, out_features=512, bias=False)
        )
        (fc_x): Linear(in_features=32, out_features=64, bias=False)
        (fc_neib): Linear(in_features=50, out_features=64, bias=False)
        (dropout): Dropout(p=0.5)
      )
      (8): AttentionAggregator2(
        (att): Sequential(
          (0): Linear(in_features=32, out_features=512, bias=False)
          (1): Tanh()
          (2): Linear(in_features=512, out_features=512, bias=False)
        )
        (att2): Sequential(
          (0): Linear(in_features=50, out_features=512, bias=False)
          (1): Tanh()
          (2): Linear(in_features=512, out_features=512, bias=False)
        )
        (fc_x): Linear(in_features=32, out_features=64, bias=False)
        (fc_neib): Linear(in_features=50, out_features=64, bias=False)
        (dropout): Dropout(p=0.5)
      )
      (9): AttentionAggregator2(
        (att): Sequential(
          (0): Linear(in_features=32, out_features=512, bias=False)
          (1): Tanh()
          (2): Linear(in_features=512, out_features=512, bias=False)
        )
        (att2): Sequential(
          (0): Linear(in_features=50, out_features=512, bias=False)
          (1): Tanh()
          (2): Linear(in_features=512, out_features=512, bias=False)
        )
        (fc_x): Linear(in_features=32, out_features=64, bias=False)
        (fc_neib): Linear(in_features=50, out_features=64, bias=False)
        (dropout): Dropout(p=0.5)
      )
      (10): AttentionAggregator2(
        (att): Sequential(
          (0): Linear(in_features=32, out_features=512, bias=False)
          (1): Tanh()
          (2): Linear(in_features=512, out_features=512, bias=False)
        )
        (att2): Sequential(
          (0): Linear(in_features=50, out_features=512, bias=False)
          (1): Tanh()
          (2): Linear(in_features=512, out_features=512, bias=False)
        )
        (fc_x): Linear(in_features=32, out_features=64, bias=False)
        (fc_neib): Linear(in_features=50, out_features=64, bias=False)
        (dropout): Dropout(p=0.5)
      )
      (11): AttentionAggregator2(
        (att): Sequential(
          (0): Linear(in_features=32, out_features=512, bias=False)
          (1): Tanh()
          (2): Linear(in_features=512, out_features=512, bias=False)
        )
        (att2): Sequential(
          (0): Linear(in_features=50, out_features=512, bias=False)
          (1): Tanh()
          (2): Linear(in_features=512, out_features=512, bias=False)
        )
        (fc_x): Linear(in_features=32, out_features=64, bias=False)
        (fc_neib): Linear(in_features=50, out_features=64, bias=False)
        (dropout): Dropout(p=0.5)
      )
      (12): AttentionAggregator2(
        (att): Sequential(
          (0): Linear(in_features=32, out_features=512, bias=False)
          (1): Tanh()
          (2): Linear(in_features=512, out_features=512, bias=False)
        )
        (att2): Sequential(
          (0): Linear(in_features=50, out_features=512, bias=False)
          (1): Tanh()
          (2): Linear(in_features=512, out_features=512, bias=False)
        )
        (fc_x): Linear(in_features=32, out_features=64, bias=False)
        (fc_neib): Linear(in_features=50, out_features=64, bias=False)
        (dropout): Dropout(p=0.5)
      )
      (13): AttentionAggregator2(
        (att): Sequential(
          (0): Linear(in_features=32, out_features=512, bias=False)
          (1): Tanh()
          (2): Linear(in_features=512, out_features=512, bias=False)
        )
        (att2): Sequential(
          (0): Linear(in_features=50, out_features=512, bias=False)
          (1): Tanh()
          (2): Linear(in_features=512, out_features=512, bias=False)
        )
        (fc_x): Linear(in_features=32, out_features=64, bias=False)
        (fc_neib): Linear(in_features=50, out_features=64, bias=False)
        (dropout): Dropout(p=0.5)
      )
      (14): AttentionAggregator2(
        (att): Sequential(
          (0): Linear(in_features=32, out_features=512, bias=False)
          (1): Tanh()
          (2): Linear(in_features=512, out_features=512, bias=False)
        )
        (att2): Sequential(
          (0): Linear(in_features=50, out_features=512, bias=False)
          (1): Tanh()
          (2): Linear(in_features=512, out_features=512, bias=False)
        )
        (fc_x): Linear(in_features=32, out_features=64, bias=False)
        (fc_neib): Linear(in_features=50, out_features=64, bias=False)
        (dropout): Dropout(p=0.5)
      )
      (15): AttentionAggregator2(
        (att): Sequential(
          (0): Linear(in_features=32, out_features=512, bias=False)
          (1): Tanh()
          (2): Linear(in_features=512, out_features=512, bias=False)
        )
        (att2): Sequential(
          (0): Linear(in_features=50, out_features=512, bias=False)
          (1): Tanh()
          (2): Linear(in_features=512, out_features=512, bias=False)
        )
        (fc_x): Linear(in_features=32, out_features=64, bias=False)
        (fc_neib): Linear(in_features=50, out_features=64, bias=False)
        (dropout): Dropout(p=0.5)
      )
    )
    (edge_0_0): IdEdgeAggregator(
      (dropout): Dropout(p=0.5)
    )
    (agg_1_0): ModuleList(
      (0): AttentionAggregator2(
        (att): Sequential(
          (0): Linear(in_features=32, out_features=512, bias=False)
          (1): Tanh()
          (2): Linear(in_features=512, out_features=512, bias=False)
        )
        (att2): Sequential(
          (0): Linear(in_features=50, out_features=512, bias=False)
          (1): Tanh()
          (2): Linear(in_features=512, out_features=512, bias=False)
        )
        (fc_x): Linear(in_features=32, out_features=64, bias=False)
        (fc_neib): Linear(in_features=50, out_features=64, bias=False)
        (dropout): Dropout(p=0.5)
      )
      (1): AttentionAggregator2(
        (att): Sequential(
          (0): Linear(in_features=32, out_features=512, bias=False)
          (1): Tanh()
          (2): Linear(in_features=512, out_features=512, bias=False)
        )
        (att2): Sequential(
          (0): Linear(in_features=50, out_features=512, bias=False)
          (1): Tanh()
          (2): Linear(in_features=512, out_features=512, bias=False)
        )
        (fc_x): Linear(in_features=32, out_features=64, bias=False)
        (fc_neib): Linear(in_features=50, out_features=64, bias=False)
        (dropout): Dropout(p=0.5)
      )
      (2): AttentionAggregator2(
        (att): Sequential(
          (0): Linear(in_features=32, out_features=512, bias=False)
          (1): Tanh()
          (2): Linear(in_features=512, out_features=512, bias=False)
        )
        (att2): Sequential(
          (0): Linear(in_features=50, out_features=512, bias=False)
          (1): Tanh()
          (2): Linear(in_features=512, out_features=512, bias=False)
        )
        (fc_x): Linear(in_features=32, out_features=64, bias=False)
        (fc_neib): Linear(in_features=50, out_features=64, bias=False)
        (dropout): Dropout(p=0.5)
      )
      (3): AttentionAggregator2(
        (att): Sequential(
          (0): Linear(in_features=32, out_features=512, bias=False)
          (1): Tanh()
          (2): Linear(in_features=512, out_features=512, bias=False)
        )
        (att2): Sequential(
          (0): Linear(in_features=50, out_features=512, bias=False)
          (1): Tanh()
          (2): Linear(in_features=512, out_features=512, bias=False)
        )
        (fc_x): Linear(in_features=32, out_features=64, bias=False)
        (fc_neib): Linear(in_features=50, out_features=64, bias=False)
        (dropout): Dropout(p=0.5)
      )
      (4): AttentionAggregator2(
        (att): Sequential(
          (0): Linear(in_features=32, out_features=512, bias=False)
          (1): Tanh()
          (2): Linear(in_features=512, out_features=512, bias=False)
        )
        (att2): Sequential(
          (0): Linear(in_features=50, out_features=512, bias=False)
          (1): Tanh()
          (2): Linear(in_features=512, out_features=512, bias=False)
        )
        (fc_x): Linear(in_features=32, out_features=64, bias=False)
        (fc_neib): Linear(in_features=50, out_features=64, bias=False)
        (dropout): Dropout(p=0.5)
      )
      (5): AttentionAggregator2(
        (att): Sequential(
          (0): Linear(in_features=32, out_features=512, bias=False)
          (1): Tanh()
          (2): Linear(in_features=512, out_features=512, bias=False)
        )
        (att2): Sequential(
          (0): Linear(in_features=50, out_features=512, bias=False)
          (1): Tanh()
          (2): Linear(in_features=512, out_features=512, bias=False)
        )
        (fc_x): Linear(in_features=32, out_features=64, bias=False)
        (fc_neib): Linear(in_features=50, out_features=64, bias=False)
        (dropout): Dropout(p=0.5)
      )
      (6): AttentionAggregator2(
        (att): Sequential(
          (0): Linear(in_features=32, out_features=512, bias=False)
          (1): Tanh()
          (2): Linear(in_features=512, out_features=512, bias=False)
        )
        (att2): Sequential(
          (0): Linear(in_features=50, out_features=512, bias=False)
          (1): Tanh()
          (2): Linear(in_features=512, out_features=512, bias=False)
        )
        (fc_x): Linear(in_features=32, out_features=64, bias=False)
        (fc_neib): Linear(in_features=50, out_features=64, bias=False)
        (dropout): Dropout(p=0.5)
      )
      (7): AttentionAggregator2(
        (att): Sequential(
          (0): Linear(in_features=32, out_features=512, bias=False)
          (1): Tanh()
          (2): Linear(in_features=512, out_features=512, bias=False)
        )
        (att2): Sequential(
          (0): Linear(in_features=50, out_features=512, bias=False)
          (1): Tanh()
          (2): Linear(in_features=512, out_features=512, bias=False)
        )
        (fc_x): Linear(in_features=32, out_features=64, bias=False)
        (fc_neib): Linear(in_features=50, out_features=64, bias=False)
        (dropout): Dropout(p=0.5)
      )
      (8): AttentionAggregator2(
        (att): Sequential(
          (0): Linear(in_features=32, out_features=512, bias=False)
          (1): Tanh()
          (2): Linear(in_features=512, out_features=512, bias=False)
        )
        (att2): Sequential(
          (0): Linear(in_features=50, out_features=512, bias=False)
          (1): Tanh()
          (2): Linear(in_features=512, out_features=512, bias=False)
        )
        (fc_x): Linear(in_features=32, out_features=64, bias=False)
        (fc_neib): Linear(in_features=50, out_features=64, bias=False)
        (dropout): Dropout(p=0.5)
      )
      (9): AttentionAggregator2(
        (att): Sequential(
          (0): Linear(in_features=32, out_features=512, bias=False)
          (1): Tanh()
          (2): Linear(in_features=512, out_features=512, bias=False)
        )
        (att2): Sequential(
          (0): Linear(in_features=50, out_features=512, bias=False)
          (1): Tanh()
          (2): Linear(in_features=512, out_features=512, bias=False)
        )
        (fc_x): Linear(in_features=32, out_features=64, bias=False)
        (fc_neib): Linear(in_features=50, out_features=64, bias=False)
        (dropout): Dropout(p=0.5)
      )
      (10): AttentionAggregator2(
        (att): Sequential(
          (0): Linear(in_features=32, out_features=512, bias=False)
          (1): Tanh()
          (2): Linear(in_features=512, out_features=512, bias=False)
        )
        (att2): Sequential(
          (0): Linear(in_features=50, out_features=512, bias=False)
          (1): Tanh()
          (2): Linear(in_features=512, out_features=512, bias=False)
        )
        (fc_x): Linear(in_features=32, out_features=64, bias=False)
        (fc_neib): Linear(in_features=50, out_features=64, bias=False)
        (dropout): Dropout(p=0.5)
      )
      (11): AttentionAggregator2(
        (att): Sequential(
          (0): Linear(in_features=32, out_features=512, bias=False)
          (1): Tanh()
          (2): Linear(in_features=512, out_features=512, bias=False)
        )
        (att2): Sequential(
          (0): Linear(in_features=50, out_features=512, bias=False)
          (1): Tanh()
          (2): Linear(in_features=512, out_features=512, bias=False)
        )
        (fc_x): Linear(in_features=32, out_features=64, bias=False)
        (fc_neib): Linear(in_features=50, out_features=64, bias=False)
        (dropout): Dropout(p=0.5)
      )
      (12): AttentionAggregator2(
        (att): Sequential(
          (0): Linear(in_features=32, out_features=512, bias=False)
          (1): Tanh()
          (2): Linear(in_features=512, out_features=512, bias=False)
        )
        (att2): Sequential(
          (0): Linear(in_features=50, out_features=512, bias=False)
          (1): Tanh()
          (2): Linear(in_features=512, out_features=512, bias=False)
        )
        (fc_x): Linear(in_features=32, out_features=64, bias=False)
        (fc_neib): Linear(in_features=50, out_features=64, bias=False)
        (dropout): Dropout(p=0.5)
      )
      (13): AttentionAggregator2(
        (att): Sequential(
          (0): Linear(in_features=32, out_features=512, bias=False)
          (1): Tanh()
          (2): Linear(in_features=512, out_features=512, bias=False)
        )
        (att2): Sequential(
          (0): Linear(in_features=50, out_features=512, bias=False)
          (1): Tanh()
          (2): Linear(in_features=512, out_features=512, bias=False)
        )
        (fc_x): Linear(in_features=32, out_features=64, bias=False)
        (fc_neib): Linear(in_features=50, out_features=64, bias=False)
        (dropout): Dropout(p=0.5)
      )
      (14): AttentionAggregator2(
        (att): Sequential(
          (0): Linear(in_features=32, out_features=512, bias=False)
          (1): Tanh()
          (2): Linear(in_features=512, out_features=512, bias=False)
        )
        (att2): Sequential(
          (0): Linear(in_features=50, out_features=512, bias=False)
          (1): Tanh()
          (2): Linear(in_features=512, out_features=512, bias=False)
        )
        (fc_x): Linear(in_features=32, out_features=64, bias=False)
        (fc_neib): Linear(in_features=50, out_features=64, bias=False)
        (dropout): Dropout(p=0.5)
      )
      (15): AttentionAggregator2(
        (att): Sequential(
          (0): Linear(in_features=32, out_features=512, bias=False)
          (1): Tanh()
          (2): Linear(in_features=512, out_features=512, bias=False)
        )
        (att2): Sequential(
          (0): Linear(in_features=50, out_features=512, bias=False)
          (1): Tanh()
          (2): Linear(in_features=512, out_features=512, bias=False)
        )
        (fc_x): Linear(in_features=32, out_features=64, bias=False)
        (fc_neib): Linear(in_features=50, out_features=64, bias=False)
        (dropout): Dropout(p=0.5)
      )
    )
    (edge_1_0): IdEdgeAggregator(
      (dropout): Dropout(p=0.5)
    )
    (agg_2_0): ModuleList(
      (0): AttentionAggregator2(
        (att): Sequential(
          (0): Linear(in_features=32, out_features=512, bias=False)
          (1): Tanh()
          (2): Linear(in_features=512, out_features=512, bias=False)
        )
        (att2): Sequential(
          (0): Linear(in_features=50, out_features=512, bias=False)
          (1): Tanh()
          (2): Linear(in_features=512, out_features=512, bias=False)
        )
        (fc_x): Linear(in_features=32, out_features=64, bias=False)
        (fc_neib): Linear(in_features=50, out_features=64, bias=False)
        (dropout): Dropout(p=0.5)
      )
      (1): AttentionAggregator2(
        (att): Sequential(
          (0): Linear(in_features=32, out_features=512, bias=False)
          (1): Tanh()
          (2): Linear(in_features=512, out_features=512, bias=False)
        )
        (att2): Sequential(
          (0): Linear(in_features=50, out_features=512, bias=False)
          (1): Tanh()
          (2): Linear(in_features=512, out_features=512, bias=False)
        )
        (fc_x): Linear(in_features=32, out_features=64, bias=False)
        (fc_neib): Linear(in_features=50, out_features=64, bias=False)
        (dropout): Dropout(p=0.5)
      )
      (2): AttentionAggregator2(
        (att): Sequential(
          (0): Linear(in_features=32, out_features=512, bias=False)
          (1): Tanh()
          (2): Linear(in_features=512, out_features=512, bias=False)
        )
        (att2): Sequential(
          (0): Linear(in_features=50, out_features=512, bias=False)
          (1): Tanh()
          (2): Linear(in_features=512, out_features=512, bias=False)
        )
        (fc_x): Linear(in_features=32, out_features=64, bias=False)
        (fc_neib): Linear(in_features=50, out_features=64, bias=False)
        (dropout): Dropout(p=0.5)
      )
      (3): AttentionAggregator2(
        (att): Sequential(
          (0): Linear(in_features=32, out_features=512, bias=False)
          (1): Tanh()
          (2): Linear(in_features=512, out_features=512, bias=False)
        )
        (att2): Sequential(
          (0): Linear(in_features=50, out_features=512, bias=False)
          (1): Tanh()
          (2): Linear(in_features=512, out_features=512, bias=False)
        )
        (fc_x): Linear(in_features=32, out_features=64, bias=False)
        (fc_neib): Linear(in_features=50, out_features=64, bias=False)
        (dropout): Dropout(p=0.5)
      )
      (4): AttentionAggregator2(
        (att): Sequential(
          (0): Linear(in_features=32, out_features=512, bias=False)
          (1): Tanh()
          (2): Linear(in_features=512, out_features=512, bias=False)
        )
        (att2): Sequential(
          (0): Linear(in_features=50, out_features=512, bias=False)
          (1): Tanh()
          (2): Linear(in_features=512, out_features=512, bias=False)
        )
        (fc_x): Linear(in_features=32, out_features=64, bias=False)
        (fc_neib): Linear(in_features=50, out_features=64, bias=False)
        (dropout): Dropout(p=0.5)
      )
      (5): AttentionAggregator2(
        (att): Sequential(
          (0): Linear(in_features=32, out_features=512, bias=False)
          (1): Tanh()
          (2): Linear(in_features=512, out_features=512, bias=False)
        )
        (att2): Sequential(
          (0): Linear(in_features=50, out_features=512, bias=False)
          (1): Tanh()
          (2): Linear(in_features=512, out_features=512, bias=False)
        )
        (fc_x): Linear(in_features=32, out_features=64, bias=False)
        (fc_neib): Linear(in_features=50, out_features=64, bias=False)
        (dropout): Dropout(p=0.5)
      )
      (6): AttentionAggregator2(
        (att): Sequential(
          (0): Linear(in_features=32, out_features=512, bias=False)
          (1): Tanh()
          (2): Linear(in_features=512, out_features=512, bias=False)
        )
        (att2): Sequential(
          (0): Linear(in_features=50, out_features=512, bias=False)
          (1): Tanh()
          (2): Linear(in_features=512, out_features=512, bias=False)
        )
        (fc_x): Linear(in_features=32, out_features=64, bias=False)
        (fc_neib): Linear(in_features=50, out_features=64, bias=False)
        (dropout): Dropout(p=0.5)
      )
      (7): AttentionAggregator2(
        (att): Sequential(
          (0): Linear(in_features=32, out_features=512, bias=False)
          (1): Tanh()
          (2): Linear(in_features=512, out_features=512, bias=False)
        )
        (att2): Sequential(
          (0): Linear(in_features=50, out_features=512, bias=False)
          (1): Tanh()
          (2): Linear(in_features=512, out_features=512, bias=False)
        )
        (fc_x): Linear(in_features=32, out_features=64, bias=False)
        (fc_neib): Linear(in_features=50, out_features=64, bias=False)
        (dropout): Dropout(p=0.5)
      )
      (8): AttentionAggregator2(
        (att): Sequential(
          (0): Linear(in_features=32, out_features=512, bias=False)
          (1): Tanh()
          (2): Linear(in_features=512, out_features=512, bias=False)
        )
        (att2): Sequential(
          (0): Linear(in_features=50, out_features=512, bias=False)
          (1): Tanh()
          (2): Linear(in_features=512, out_features=512, bias=False)
        )
        (fc_x): Linear(in_features=32, out_features=64, bias=False)
        (fc_neib): Linear(in_features=50, out_features=64, bias=False)
        (dropout): Dropout(p=0.5)
      )
      (9): AttentionAggregator2(
        (att): Sequential(
          (0): Linear(in_features=32, out_features=512, bias=False)
          (1): Tanh()
          (2): Linear(in_features=512, out_features=512, bias=False)
        )
        (att2): Sequential(
          (0): Linear(in_features=50, out_features=512, bias=False)
          (1): Tanh()
          (2): Linear(in_features=512, out_features=512, bias=False)
        )
        (fc_x): Linear(in_features=32, out_features=64, bias=False)
        (fc_neib): Linear(in_features=50, out_features=64, bias=False)
        (dropout): Dropout(p=0.5)
      )
      (10): AttentionAggregator2(
        (att): Sequential(
          (0): Linear(in_features=32, out_features=512, bias=False)
          (1): Tanh()
          (2): Linear(in_features=512, out_features=512, bias=False)
        )
        (att2): Sequential(
          (0): Linear(in_features=50, out_features=512, bias=False)
          (1): Tanh()
          (2): Linear(in_features=512, out_features=512, bias=False)
        )
        (fc_x): Linear(in_features=32, out_features=64, bias=False)
        (fc_neib): Linear(in_features=50, out_features=64, bias=False)
        (dropout): Dropout(p=0.5)
      )
      (11): AttentionAggregator2(
        (att): Sequential(
          (0): Linear(in_features=32, out_features=512, bias=False)
          (1): Tanh()
          (2): Linear(in_features=512, out_features=512, bias=False)
        )
        (att2): Sequential(
          (0): Linear(in_features=50, out_features=512, bias=False)
          (1): Tanh()
          (2): Linear(in_features=512, out_features=512, bias=False)
        )
        (fc_x): Linear(in_features=32, out_features=64, bias=False)
        (fc_neib): Linear(in_features=50, out_features=64, bias=False)
        (dropout): Dropout(p=0.5)
      )
      (12): AttentionAggregator2(
        (att): Sequential(
          (0): Linear(in_features=32, out_features=512, bias=False)
          (1): Tanh()
          (2): Linear(in_features=512, out_features=512, bias=False)
        )
        (att2): Sequential(
          (0): Linear(in_features=50, out_features=512, bias=False)
          (1): Tanh()
          (2): Linear(in_features=512, out_features=512, bias=False)
        )
        (fc_x): Linear(in_features=32, out_features=64, bias=False)
        (fc_neib): Linear(in_features=50, out_features=64, bias=False)
        (dropout): Dropout(p=0.5)
      )
      (13): AttentionAggregator2(
        (att): Sequential(
          (0): Linear(in_features=32, out_features=512, bias=False)
          (1): Tanh()
          (2): Linear(in_features=512, out_features=512, bias=False)
        )
        (att2): Sequential(
          (0): Linear(in_features=50, out_features=512, bias=False)
          (1): Tanh()
          (2): Linear(in_features=512, out_features=512, bias=False)
        )
        (fc_x): Linear(in_features=32, out_features=64, bias=False)
        (fc_neib): Linear(in_features=50, out_features=64, bias=False)
        (dropout): Dropout(p=0.5)
      )
      (14): AttentionAggregator2(
        (att): Sequential(
          (0): Linear(in_features=32, out_features=512, bias=False)
          (1): Tanh()
          (2): Linear(in_features=512, out_features=512, bias=False)
        )
        (att2): Sequential(
          (0): Linear(in_features=50, out_features=512, bias=False)
          (1): Tanh()
          (2): Linear(in_features=512, out_features=512, bias=False)
        )
        (fc_x): Linear(in_features=32, out_features=64, bias=False)
        (fc_neib): Linear(in_features=50, out_features=64, bias=False)
        (dropout): Dropout(p=0.5)
      )
      (15): AttentionAggregator2(
        (att): Sequential(
          (0): Linear(in_features=32, out_features=512, bias=False)
          (1): Tanh()
          (2): Linear(in_features=512, out_features=512, bias=False)
        )
        (att2): Sequential(
          (0): Linear(in_features=50, out_features=512, bias=False)
          (1): Tanh()
          (2): Linear(in_features=512, out_features=512, bias=False)
        )
        (fc_x): Linear(in_features=32, out_features=64, bias=False)
        (fc_neib): Linear(in_features=50, out_features=64, bias=False)
        (dropout): Dropout(p=0.5)
      )
    )
    (edge_2_0): IdEdgeAggregator(
      (dropout): Dropout(p=0.5)
    )
    (mp_agg): MetapathAttentionLayer (1024 -> 1024)
    (fc): Sequential(
      (0): Linear(in_features=1024, out_features=32, bias=True)
      (1): ReLU()
      (2): Dropout(p=0.5)
      (3): Linear(in_features=32, out_features=3, bias=True)
    )
  )
)
{"epoch":0,"time":26.01354,"train_loss":95.20632}
{"epoch":0,"val_loss":87.41799,"val_metric":{"accuracy":0.61346,"micro":0.61346,"macro":0.44446},"test_metric":{"accuracy":0.62804,"micro":0.62804,"macro":0.45264},"tolerance:":0}
{"epoch":1,"time":62.27155,"train_loss":87.11476}
{"epoch":1,"val_loss":78.36802,"val_metric":{"accuracy":0.65211,"micro":0.65211,"macro":0.47885},"test_metric":{"accuracy":0.67954,"micro":0.67954,"macro":0.49689},"tolerance:":0}
{"epoch":2,"time":98.49138,"train_loss":83.61352}
{"epoch":2,"val_loss":77.65043,"val_metric":{"accuracy":0.64281,"micro":0.64281,"macro":0.47162},"test_metric":{"accuracy":0.67382,"micro":0.67382,"macro":0.49255},"tolerance:":1}
{"epoch":3,"time":134.21471,"train_loss":80.3358}
{"epoch":3,"val_loss":75.50192,"val_metric":{"accuracy":0.64996,"micro":0.64996,"macro":0.4773},"test_metric":{"accuracy":0.68097,"micro":0.68097,"macro":0.4979},"tolerance:":0}
{"epoch":4,"time":170.66332,"train_loss":77.39235}
{"epoch":4,"val_loss":75.16277,"val_metric":{"accuracy":0.64853,"micro":0.64853,"macro":0.47639},"test_metric":{"accuracy":0.6824,"micro":0.6824,"macro":0.49896},"tolerance:":0}
{"epoch":5,"time":206.71635,"train_loss":75.95673}
{"epoch":5,"val_loss":74.32452,"val_metric":{"accuracy":0.6514,"micro":0.6514,"macro":0.47845},"test_metric":{"accuracy":0.68813,"micro":0.68813,"macro":0.50316},"tolerance:":0}
{"epoch":6,"time":243.83734,"train_loss":76.8139}
{"epoch":6,"val_loss":73.82275,"val_metric":{"accuracy":0.65354,"micro":0.65354,"macro":0.48003},"test_metric":{"accuracy":0.68383,"micro":0.68383,"macro":0.49988},"tolerance:":1}
{"epoch":7,"time":281.9726,"train_loss":75.07083}
{"epoch":7,"val_loss":73.5169,"val_metric":{"accuracy":0.65354,"micro":0.65354,"macro":0.48007},"test_metric":{"accuracy":0.68383,"micro":0.68383,"macro":0.49988},"tolerance:":2}
{"epoch":8,"time":319.07723,"train_loss":73.63303}
{"epoch":8,"val_loss":72.96385,"val_metric":{"accuracy":0.65426,"micro":0.65426,"macro":0.48067},"test_metric":{"accuracy":0.6867,"micro":0.6867,"macro":0.50207},"tolerance:":3}
{"epoch":9,"time":356.9355,"train_loss":72.98126}
{"epoch":9,"val_loss":73.39512,"val_metric":{"accuracy":0.65354,"micro":0.65354,"macro":0.47991},"test_metric":{"accuracy":0.68383,"micro":0.68383,"macro":0.5},"tolerance:":4}
{"epoch":10,"time":395.42239,"train_loss":72.58257}
{"epoch":10,"val_loss":73.16241,"val_metric":{"accuracy":0.6514,"micro":0.6514,"macro":0.47822},"test_metric":{"accuracy":0.69099,"micro":0.69099,"macro":0.50551},"tolerance:":0}
{"epoch":11,"time":432.86595,"train_loss":71.81408}
{"epoch":11,"val_loss":72.3472,"val_metric":{"accuracy":0.65283,"micro":0.65283,"macro":0.47935},"test_metric":{"accuracy":0.6824,"micro":0.6824,"macro":0.49873},"tolerance:":1}
{"epoch":12,"time":471.83404,"train_loss":67.39084}
{"epoch":12,"val_loss":74.3289,"val_metric":{"accuracy":0.66356,"micro":0.66356,"macro":0.54135},"test_metric":{"accuracy":0.69242,"micro":0.69242,"macro":0.55949},"tolerance:":0}
{"epoch":13,"time":508.9985,"train_loss":67.05191}
{"epoch":13,"val_loss":74.43785,"val_metric":{"accuracy":0.66428,"micro":0.66428,"macro":0.54722},"test_metric":{"accuracy":0.701,"micro":0.701,"macro":0.58117},"tolerance:":0}
{"epoch":14,"time":546.77978,"train_loss":64.51172}
{"epoch":14,"val_loss":72.97586,"val_metric":{"accuracy":0.67072,"micro":0.67072,"macro":0.55525},"test_metric":{"accuracy":0.69957,"micro":0.69957,"macro":0.60069},"tolerance:":1}
{"epoch":15,"time":584.51721,"train_loss":62.67654}
{"epoch":15,"val_loss":75.59873,"val_metric":{"accuracy":0.665,"micro":0.665,"macro":0.57448},"test_metric":{"accuracy":0.6824,"micro":0.6824,"macro":0.58933},"tolerance:":2}
{"epoch":16,"time":621.3951,"train_loss":62.10452}
{"epoch":16,"val_loss":76.20378,"val_metric":{"accuracy":0.66285,"micro":0.66285,"macro":0.58705},"test_metric":{"accuracy":0.69242,"micro":0.69242,"macro":0.629},"tolerance:":3}
{"epoch":17,"time":658.25214,"train_loss":58.13795}
{"epoch":17,"val_loss":78.02204,"val_metric":{"accuracy":0.66356,"micro":0.66356,"macro":0.57065},"test_metric":{"accuracy":0.68813,"micro":0.68813,"macro":0.59438},"tolerance:":4}
{"epoch":18,"time":695.23522,"train_loss":56.70787}
{"epoch":18,"val_loss":80.25126,"val_metric":{"accuracy":0.64567,"micro":0.64567,"macro":0.55755},"test_metric":{"accuracy":0.68956,"micro":0.68956,"macro":0.6179},"tolerance:":5}
{"epoch":19,"time":732.36052,"train_loss":54.28039}
{"epoch":19,"val_loss":79.90151,"val_metric":{"accuracy":0.65283,"micro":0.65283,"macro":0.57762},"test_metric":{"accuracy":0.69528,"micro":0.69528,"macro":0.63735},"tolerance:":6}
{"epoch":20,"time":768.90698,"train_loss":49.60103}
{"epoch":20,"val_loss":86.38881,"val_metric":{"accuracy":0.63135,"micro":0.63135,"macro":0.56283},"test_metric":{"accuracy":0.66953,"micro":0.66953,"macro":0.62459},"tolerance:":7}
{"epoch":21,"time":804.64201,"train_loss":47.99027}
{"epoch":21,"val_loss":85.25464,"val_metric":{"accuracy":0.63135,"micro":0.63135,"macro":0.57134},"test_metric":{"accuracy":0.65951,"micro":0.65951,"macro":0.61618},"tolerance:":8}
{"epoch":22,"time":841.57343,"train_loss":44.10408}
{"epoch":22,"val_loss":91.46027,"val_metric":{"accuracy":0.64066,"micro":0.64066,"macro":0.57854},"test_metric":{"accuracy":0.67525,"micro":0.67525,"macro":0.63201},"tolerance:":9}
{"epoch":23,"time":877.61632,"train_loss":42.23163}
{"epoch":23,"val_loss":89.8237,"val_metric":{"accuracy":0.62062,"micro":0.62062,"macro":0.56581},"test_metric":{"accuracy":0.65379,"micro":0.65379,"macro":0.61486},"tolerance:":10}
{"epoch":24,"time":914.36449,"train_loss":39.59206}
{"epoch":24,"val_loss":90.46339,"val_metric":{"accuracy":0.60702,"micro":0.60702,"macro":0.56225},"test_metric":{"accuracy":0.64521,"micro":0.64521,"macro":0.61055},"tolerance:":11}
{"epoch":25,"time":950.12865,"train_loss":35.75205}
{"epoch":25,"val_loss":102.21201,"val_metric":{"accuracy":0.61775,"micro":0.61775,"macro":0.56205},"test_metric":{"accuracy":0.66953,"micro":0.66953,"macro":0.63222},"tolerance:":12}
{"epoch":26,"time":986.68198,"train_loss":32.27559}
{"epoch":26,"val_loss":109.25993,"val_metric":{"accuracy":0.61775,"micro":0.61775,"macro":0.57983},"test_metric":{"accuracy":0.64807,"micro":0.64807,"macro":0.61103},"tolerance:":13}
{"epoch":27,"time":1022.06639,"train_loss":30.50186}
{"epoch":27,"val_loss":108.81976,"val_metric":{"accuracy":0.6199,"micro":0.6199,"macro":0.5737},"test_metric":{"accuracy":0.67382,"micro":0.67382,"macro":0.63782},"tolerance:":14}
{"epoch":28,"time":1058.94723,"train_loss":33.13723}
{"epoch":28,"val_loss":106.69213,"val_metric":{"accuracy":0.62992,"micro":0.62992,"macro":0.5931},"test_metric":{"accuracy":0.66953,"micro":0.66953,"macro":0.63548},"tolerance:":15}
{"epoch":29,"time":1095.0748,"train_loss":27.22752}
{"epoch":29,"val_loss":109.46159,"val_metric":{"accuracy":0.63422,"micro":0.63422,"macro":0.59789},"test_metric":{"accuracy":0.66524,"micro":0.66524,"macro":0.63163},"tolerance:":16}
{"epoch":30,"time":1131.35229,"train_loss":24.57362}
{"epoch":30,"val_loss":119.2399,"val_metric":{"accuracy":0.6378,"micro":0.6378,"macro":0.59753},"test_metric":{"accuracy":0.6824,"micro":0.6824,"macro":0.64268},"tolerance:":17}
{"epoch":31,"time":1167.21648,"train_loss":22.63992}
{"epoch":31,"val_loss":112.82005,"val_metric":{"accuracy":0.61203,"micro":0.61203,"macro":0.58224},"test_metric":{"accuracy":0.6495,"micro":0.6495,"macro":0.61362},"tolerance:":18}
{"epoch":32,"time":1203.3637,"train_loss":21.14798}
{"epoch":32,"val_loss":130.67615,"val_metric":{"accuracy":0.63565,"micro":0.63565,"macro":0.59092},"test_metric":{"accuracy":0.68526,"micro":0.68526,"macro":0.64351},"tolerance:":19}
{"epoch":33,"time":1239.38936,"train_loss":21.54259}
{"epoch":33,"val_loss":129.77373,"val_metric":{"accuracy":0.64567,"micro":0.64567,"macro":0.60761},"test_metric":{"accuracy":0.67239,"micro":0.67239,"macro":0.62904},"tolerance:":20}
{"epoch":34,"time":1275.50217,"train_loss":19.29091}
{"epoch":34,"val_loss":127.89361,"val_metric":{"accuracy":0.63994,"micro":0.63994,"macro":0.60404},"test_metric":{"accuracy":0.66953,"micro":0.66953,"macro":0.6253},"tolerance:":21}
{"epoch":35,"time":1311.49919,"train_loss":17.79246}
{"epoch":35,"val_loss":143.03882,"val_metric":{"accuracy":0.64925,"micro":0.64925,"macro":0.60631},"test_metric":{"accuracy":0.68097,"micro":0.68097,"macro":0.63487},"tolerance:":22}
{"epoch":36,"time":1347.61251,"train_loss":15.61449}
{"epoch":36,"val_loss":136.87251,"val_metric":{"accuracy":0.65569,"micro":0.65569,"macro":0.61015},"test_metric":{"accuracy":0.69242,"micro":0.69242,"macro":0.65239},"tolerance:":23}
{"epoch":37,"time":1383.18863,"train_loss":17.44247}
{"epoch":37,"val_loss":134.34451,"val_metric":{"accuracy":0.65068,"micro":0.65068,"macro":0.6132},"test_metric":{"accuracy":0.68956,"micro":0.68956,"macro":0.65442},"tolerance:":24}
{"epoch":38,"time":1418.55337,"train_loss":15.21236}
{"epoch":38,"val_loss":143.14882,"val_metric":{"accuracy":0.64352,"micro":0.64352,"macro":0.60659},"test_metric":{"accuracy":0.6824,"micro":0.6824,"macro":0.64613},"tolerance:":25}
{"epoch":39,"time":1455.12496,"train_loss":14.09631}
{"epoch":39,"val_loss":142.24859,"val_metric":{"accuracy":0.63708,"micro":0.63708,"macro":0.59888},"test_metric":{"accuracy":0.67239,"micro":0.67239,"macro":0.63825},"tolerance:":26}
{"epoch":40,"time":1490.93992,"train_loss":13.29777}
{"epoch":40,"val_loss":145.31565,"val_metric":{"accuracy":0.65641,"micro":0.65641,"macro":0.62131},"test_metric":{"accuracy":0.67668,"micro":0.67668,"macro":0.64296},"tolerance:":27}
{"epoch":41,"time":1527.19996,"train_loss":14.41182}
{"epoch":41,"val_loss":150.06734,"val_metric":{"accuracy":0.65641,"micro":0.65641,"macro":0.61755},"test_metric":{"accuracy":0.69385,"micro":0.69385,"macro":0.66087},"tolerance:":28}
{"epoch":42,"time":1562.82521,"train_loss":13.50539}
{"epoch":42,"val_loss":157.66307,"val_metric":{"accuracy":0.65497,"micro":0.65497,"macro":0.61492},"test_metric":{"accuracy":0.68956,"micro":0.68956,"macro":0.65541},"tolerance:":29}
{"epoch":43,"time":1598.61446,"train_loss":12.92991}
{"epoch":43,"val_loss":154.46343,"val_metric":{"accuracy":0.65927,"micro":0.65927,"macro":0.61876},"test_metric":{"accuracy":0.69385,"micro":0.69385,"macro":0.65811},"tolerance:":30}
{"epoch":44,"time":1635.05486,"train_loss":11.953}
{"epoch":44,"val_loss":141.23415,"val_metric":{"accuracy":0.63207,"micro":0.63207,"macro":0.60052},"test_metric":{"accuracy":0.67382,"micro":0.67382,"macro":0.64366},"tolerance:":31}
{"epoch":45,"time":1670.4302,"train_loss":11.31734}
{"epoch":45,"val_loss":178.98972,"val_metric":{"accuracy":0.67144,"micro":0.67144,"macro":0.62818},"test_metric":{"accuracy":0.70672,"micro":0.70672,"macro":0.67069},"tolerance:":0}
{"epoch":46,"time":1706.485,"train_loss":12.73063}
{"epoch":46,"val_loss":157.60252,"val_metric":{"accuracy":0.6514,"micro":0.6514,"macro":0.61549},"test_metric":{"accuracy":0.69385,"micro":0.69385,"macro":0.66434},"tolerance:":1}
{"epoch":47,"time":1742.63324,"train_loss":12.24951}
{"epoch":47,"val_loss":161.07773,"val_metric":{"accuracy":0.66213,"micro":0.66213,"macro":0.62026},"test_metric":{"accuracy":0.69671,"micro":0.69671,"macro":0.65712},"tolerance:":2}
{"epoch":48,"time":1778.96805,"train_loss":12.82044}
{"epoch":48,"val_loss":160.45333,"val_metric":{"accuracy":0.66714,"micro":0.66714,"macro":0.62865},"test_metric":{"accuracy":0.70672,"micro":0.70672,"macro":0.66994},"tolerance:":0}
{"epoch":49,"time":1814.41653,"train_loss":12.95885}
{"epoch":49,"val_loss":169.44873,"val_metric":{"accuracy":0.66356,"micro":0.66356,"macro":0.62836},"test_metric":{"accuracy":0.69385,"micro":0.69385,"macro":0.65841},"tolerance:":1}
{"epoch":50,"time":1850.06957,"train_loss":15.51652}
{"epoch":50,"val_loss":152.72769,"val_metric":{"accuracy":0.66571,"micro":0.66571,"macro":0.62752},"test_metric":{"accuracy":0.69671,"micro":0.69671,"macro":0.6611},"tolerance:":2}
{"epoch":51,"time":1885.97758,"train_loss":12.17376}
{"epoch":51,"val_loss":133.32603,"val_metric":{"accuracy":0.66142,"micro":0.66142,"macro":0.62652},"test_metric":{"accuracy":0.67382,"micro":0.67382,"macro":0.63861},"tolerance:":3}
{"epoch":52,"time":1922.50071,"train_loss":11.28355}
{"epoch":52,"val_loss":153.70906,"val_metric":{"accuracy":0.66428,"micro":0.66428,"macro":0.62418},"test_metric":{"accuracy":0.701,"micro":0.701,"macro":0.66653},"tolerance:":4}
{"epoch":53,"time":1958.06982,"train_loss":10.60142}
{"epoch":53,"val_loss":152.76975,"val_metric":{"accuracy":0.6514,"micro":0.6514,"macro":0.61589},"test_metric":{"accuracy":0.67668,"micro":0.67668,"macro":0.6433},"tolerance:":5}
{"epoch":54,"time":1993.2073,"train_loss":9.46636}
{"epoch":54,"val_loss":164.30248,"val_metric":{"accuracy":0.66714,"micro":0.66714,"macro":0.6245},"test_metric":{"accuracy":0.70386,"micro":0.70386,"macro":0.66805},"tolerance:":6}
{"epoch":55,"time":2029.4121,"train_loss":8.24313}
{"epoch":55,"val_loss":180.22591,"val_metric":{"accuracy":0.66142,"micro":0.66142,"macro":0.61566},"test_metric":{"accuracy":0.70815,"micro":0.70815,"macro":0.67346},"tolerance:":0}
{"epoch":56,"time":2064.6526,"train_loss":9.77449}
{"epoch":56,"val_loss":172.25833,"val_metric":{"accuracy":0.66428,"micro":0.66428,"macro":0.61941},"test_metric":{"accuracy":0.69957,"micro":0.69957,"macro":0.66419},"tolerance:":1}
{"epoch":57,"time":2100.75156,"train_loss":10.21204}
{"epoch":57,"val_loss":166.63178,"val_metric":{"accuracy":0.66428,"micro":0.66428,"macro":0.62444},"test_metric":{"accuracy":0.6824,"micro":0.6824,"macro":0.64286},"tolerance:":2}
{"epoch":58,"time":2136.00371,"train_loss":8.85004}
{"epoch":58,"val_loss":157.83937,"val_metric":{"accuracy":0.61918,"micro":0.61918,"macro":0.59714},"test_metric":{"accuracy":0.64664,"micro":0.64664,"macro":0.62317},"tolerance:":3}
{"epoch":59,"time":2172.04424,"train_loss":8.91634}
{"epoch":59,"val_loss":178.10375,"val_metric":{"accuracy":0.65999,"micro":0.65999,"macro":0.61985},"test_metric":{"accuracy":0.68813,"micro":0.68813,"macro":0.65174},"tolerance:":4}
{"epoch":60,"time":2208.1977,"train_loss":8.90476}
{"epoch":60,"val_loss":161.59276,"val_metric":{"accuracy":0.66213,"micro":0.66213,"macro":0.62479},"test_metric":{"accuracy":0.68813,"micro":0.68813,"macro":0.6526},"tolerance:":5}
{"epoch":61,"time":2243.83832,"train_loss":9.40023}
{"epoch":61,"val_loss":155.91673,"val_metric":{"accuracy":0.65354,"micro":0.65354,"macro":0.6125},"test_metric":{"accuracy":0.6824,"micro":0.6824,"macro":0.64734},"tolerance:":6}
{"epoch":62,"time":2279.77896,"train_loss":8.73132}
{"epoch":62,"val_loss":174.55891,"val_metric":{"accuracy":0.665,"micro":0.665,"macro":0.62837},"test_metric":{"accuracy":0.67811,"micro":0.67811,"macro":0.64343},"tolerance:":7}
{"epoch":63,"time":2316.28234,"train_loss":10.14058}
{"epoch":63,"val_loss":161.7946,"val_metric":{"accuracy":0.66643,"micro":0.66643,"macro":0.62662},"test_metric":{"accuracy":0.69671,"micro":0.69671,"macro":0.66166},"tolerance:":8}
{"epoch":64,"time":2352.47419,"train_loss":9.72435}
{"epoch":64,"val_loss":161.64332,"val_metric":{"accuracy":0.66714,"micro":0.66714,"macro":0.62397},"test_metric":{"accuracy":0.69385,"micro":0.69385,"macro":0.66063},"tolerance:":9}
{"epoch":65,"time":2388.61826,"train_loss":7.93895}
{"epoch":65,"val_loss":152.6258,"val_metric":{"accuracy":0.66356,"micro":0.66356,"macro":0.61447},"test_metric":{"accuracy":0.70243,"micro":0.70243,"macro":0.66638},"tolerance:":10}
{"epoch":66,"time":2424.97849,"train_loss":7.45291}
{"epoch":66,"val_loss":175.84263,"val_metric":{"accuracy":0.66714,"micro":0.66714,"macro":0.63098},"test_metric":{"accuracy":0.69528,"micro":0.69528,"macro":0.66125},"tolerance:":11}
{"epoch":67,"time":2461.24291,"train_loss":7.5131}
{"epoch":67,"val_loss":179.63716,"val_metric":{"accuracy":0.65712,"micro":0.65712,"macro":0.61968},"test_metric":{"accuracy":0.6824,"micro":0.6824,"macro":0.64625},"tolerance:":12}
{"epoch":68,"time":2497.36252,"train_loss":7.59479}
{"epoch":68,"val_loss":195.59514,"val_metric":{"accuracy":0.66714,"micro":0.66714,"macro":0.62129},"test_metric":{"accuracy":0.70672,"micro":0.70672,"macro":0.67274},"tolerance:":13}
{"epoch":69,"time":2533.93842,"train_loss":7.75918}
{"epoch":69,"val_loss":172.99362,"val_metric":{"accuracy":0.62276,"micro":0.62276,"macro":0.59759},"test_metric":{"accuracy":0.64521,"micro":0.64521,"macro":0.61787},"tolerance:":14}
{"epoch":70,"time":2569.83441,"train_loss":8.67603}
{"epoch":70,"val_loss":169.25343,"val_metric":{"accuracy":0.64639,"micro":0.64639,"macro":0.60301},"test_metric":{"accuracy":0.69385,"micro":0.69385,"macro":0.65715},"tolerance:":15}
{"epoch":71,"time":2606.17584,"train_loss":10.5191}
{"epoch":71,"val_loss":182.64153,"val_metric":{"accuracy":0.67072,"micro":0.67072,"macro":0.62602},"test_metric":{"accuracy":0.71817,"micro":0.71817,"macro":0.68459},"tolerance:":0}
{"epoch":72,"time":2642.22422,"train_loss":9.41725}
{"epoch":72,"val_loss":183.3592,"val_metric":{"accuracy":0.64853,"micro":0.64853,"macro":0.60387},"test_metric":{"accuracy":0.701,"micro":0.701,"macro":0.66566},"tolerance:":1}
{"epoch":73,"time":2677.96224,"train_loss":7.24928}
{"epoch":73,"val_loss":186.27384,"val_metric":{"accuracy":0.62062,"micro":0.62062,"macro":0.59282},"test_metric":{"accuracy":0.65379,"micro":0.65379,"macro":0.62436},"tolerance:":2}
{"epoch":74,"time":2714.28778,"train_loss":11.75704}
{"epoch":74,"val_loss":162.2545,"val_metric":{"accuracy":0.6199,"micro":0.6199,"macro":0.59573},"test_metric":{"accuracy":0.64235,"micro":0.64235,"macro":0.61583},"tolerance:":3}
{"epoch":75,"time":2750.38982,"train_loss":10.51327}
{"epoch":75,"val_loss":153.29891,"val_metric":{"accuracy":0.65712,"micro":0.65712,"macro":0.60435},"test_metric":{"accuracy":0.69957,"micro":0.69957,"macro":0.65359},"tolerance:":4}
{"epoch":76,"time":2786.79203,"train_loss":10.44569}
{"epoch":76,"val_loss":164.26412,"val_metric":{"accuracy":0.65999,"micro":0.65999,"macro":0.61173},"test_metric":{"accuracy":0.70386,"micro":0.70386,"macro":0.66655},"tolerance:":5}
{"epoch":77,"time":2822.73582,"train_loss":9.39619}
{"epoch":77,"val_loss":170.06772,"val_metric":{"accuracy":0.66571,"micro":0.66571,"macro":0.61377},"test_metric":{"accuracy":0.71817,"micro":0.71817,"macro":0.67958},"tolerance:":0}
{"epoch":78,"time":2858.79116,"train_loss":9.05118}
{"epoch":78,"val_loss":160.96537,"val_metric":{"accuracy":0.65426,"micro":0.65426,"macro":0.60781},"test_metric":{"accuracy":0.69385,"micro":0.69385,"macro":0.65586},"tolerance:":1}
{"epoch":79,"time":2894.6126,"train_loss":7.20928}
{"epoch":79,"val_loss":172.27808,"val_metric":{"accuracy":0.66571,"micro":0.66571,"macro":0.6178},"test_metric":{"accuracy":0.71531,"micro":0.71531,"macro":0.67551},"tolerance:":2}
{"epoch":80,"time":2931.30689,"train_loss":7.93091}
{"epoch":80,"val_loss":169.89941,"val_metric":{"accuracy":0.64137,"micro":0.64137,"macro":0.60731},"test_metric":{"accuracy":0.6867,"micro":0.6867,"macro":0.65279},"tolerance:":3}
{"epoch":81,"time":2967.51677,"train_loss":7.01634}
{"epoch":81,"val_loss":185.8517,"val_metric":{"accuracy":0.65927,"micro":0.65927,"macro":0.61424},"test_metric":{"accuracy":0.72246,"micro":0.72246,"macro":0.69051},"tolerance:":0}
{"epoch":82,"time":3003.37608,"train_loss":7.06596}
{"epoch":82,"val_loss":172.50813,"val_metric":{"accuracy":0.62419,"micro":0.62419,"macro":0.59156},"test_metric":{"accuracy":0.66524,"micro":0.66524,"macro":0.63673},"tolerance:":1}
{"epoch":83,"time":3039.61767,"train_loss":7.62099}
{"epoch":83,"val_loss":174.593,"val_metric":{"accuracy":0.62419,"micro":0.62419,"macro":0.59349},"test_metric":{"accuracy":0.66094,"micro":0.66094,"macro":0.63439},"tolerance:":2}
{"epoch":84,"time":3076.04277,"train_loss":7.44501}
{"epoch":84,"val_loss":198.7315,"val_metric":{"accuracy":0.67144,"micro":0.67144,"macro":0.62379},"test_metric":{"accuracy":0.71388,"micro":0.71388,"macro":0.67529},"tolerance:":3}
{"epoch":85,"time":3111.97307,"train_loss":6.79246}
{"epoch":85,"val_loss":190.3368,"val_metric":{"accuracy":0.64567,"micro":0.64567,"macro":0.61096},"test_metric":{"accuracy":0.6867,"micro":0.6867,"macro":0.65713},"tolerance:":4}
{"epoch":86,"time":3147.98016,"train_loss":7.29916}
{"epoch":86,"val_loss":193.87241,"val_metric":{"accuracy":0.66858,"micro":0.66858,"macro":0.62142},"test_metric":{"accuracy":0.70959,"micro":0.70959,"macro":0.66964},"tolerance:":5}
{"epoch":87,"time":3184.23484,"train_loss":8.22719}
{"epoch":87,"val_loss":181.65507,"val_metric":{"accuracy":0.65497,"micro":0.65497,"macro":0.61007},"test_metric":{"accuracy":0.701,"micro":0.701,"macro":0.66739},"tolerance:":6}
{"epoch":88,"time":3219.42801,"train_loss":6.9402}
{"epoch":88,"val_loss":218.27389,"val_metric":{"accuracy":0.65497,"micro":0.65497,"macro":0.60251},"test_metric":{"accuracy":0.70815,"micro":0.70815,"macro":0.67128},"tolerance:":7}
{"epoch":89,"time":3255.46283,"train_loss":7.33343}
{"epoch":89,"val_loss":168.58122,"val_metric":{"accuracy":0.65855,"micro":0.65855,"macro":0.60048},"test_metric":{"accuracy":0.70672,"micro":0.70672,"macro":0.66105},"tolerance:":8}
{"epoch":90,"time":3291.30561,"train_loss":8.28902}
{"epoch":90,"val_loss":180.99746,"val_metric":{"accuracy":0.65712,"micro":0.65712,"macro":0.60905},"test_metric":{"accuracy":0.70959,"micro":0.70959,"macro":0.66986},"tolerance:":9}
{"epoch":91,"time":3326.9195,"train_loss":6.25787}
{"epoch":91,"val_loss":188.85553,"val_metric":{"accuracy":0.6471,"micro":0.6471,"macro":0.60454},"test_metric":{"accuracy":0.69099,"micro":0.69099,"macro":0.65592},"tolerance:":10}
{"epoch":92,"time":3362.88919,"train_loss":5.8266}
{"epoch":92,"val_loss":191.86533,"val_metric":{"accuracy":0.66285,"micro":0.66285,"macro":0.61347},"test_metric":{"accuracy":0.70243,"micro":0.70243,"macro":0.66655},"tolerance:":11}
{"epoch":93,"time":3398.99466,"train_loss":6.28763}
{"epoch":93,"val_loss":194.99293,"val_metric":{"accuracy":0.66786,"micro":0.66786,"macro":0.62452},"test_metric":{"accuracy":0.69671,"micro":0.69671,"macro":0.66203},"tolerance:":12}
{"epoch":94,"time":3435.01509,"train_loss":9.00347}
{"epoch":94,"val_loss":176.7193,"val_metric":{"accuracy":0.62706,"micro":0.62706,"macro":0.59453},"test_metric":{"accuracy":0.65093,"micro":0.65093,"macro":0.61749},"tolerance:":13}
{"epoch":95,"time":3470.63588,"train_loss":7.12965}
{"epoch":95,"val_loss":198.40817,"val_metric":{"accuracy":0.6607,"micro":0.6607,"macro":0.60779},"test_metric":{"accuracy":0.71531,"micro":0.71531,"macro":0.68166},"tolerance:":14}
{"epoch":96,"time":3507.18698,"train_loss":6.93979}
{"epoch":96,"val_loss":157.83637,"val_metric":{"accuracy":0.65426,"micro":0.65426,"macro":0.60369},"test_metric":{"accuracy":0.69528,"micro":0.69528,"macro":0.65866},"tolerance:":15}
{"epoch":97,"time":3543.03178,"train_loss":7.75531}
{"epoch":97,"val_loss":170.37271,"val_metric":{"accuracy":0.5927,"micro":0.5927,"macro":0.569},"test_metric":{"accuracy":0.63519,"micro":0.63519,"macro":0.60916},"tolerance:":16}
{"epoch":98,"time":3578.37005,"train_loss":7.39407}
{"epoch":98,"val_loss":171.82101,"val_metric":{"accuracy":0.63064,"micro":0.63064,"macro":0.59739},"test_metric":{"accuracy":0.66953,"micro":0.66953,"macro":0.63524},"tolerance:":17}
{"epoch":99,"time":3614.46042,"train_loss":7.79228}
{"epoch":99,"val_loss":176.26878,"val_metric":{"accuracy":0.66714,"micro":0.66714,"macro":0.61493},"test_metric":{"accuracy":0.72675,"micro":0.72675,"macro":0.68983},"tolerance:":0}
{"epoch":100,"time":3650.21425,"train_loss":8.862}
{"epoch":100,"val_loss":188.31112,"val_metric":{"accuracy":0.63851,"micro":0.63851,"macro":0.60392},"test_metric":{"accuracy":0.69099,"micro":0.69099,"macro":0.65764},"tolerance:":1}
{"epoch":101,"time":3686.58939,"train_loss":7.93475}
{"epoch":101,"val_loss":199.8638,"val_metric":{"accuracy":0.66356,"micro":0.66356,"macro":0.60135},"test_metric":{"accuracy":0.72532,"micro":0.72532,"macro":0.68465},"tolerance:":2}
{"epoch":102,"time":3722.42263,"train_loss":8.22044}
{"epoch":102,"val_loss":163.71489,"val_metric":{"accuracy":0.6378,"micro":0.6378,"macro":0.60076},"test_metric":{"accuracy":0.6681,"micro":0.6681,"macro":0.62997},"tolerance:":3}
{"epoch":103,"time":3758.02835,"train_loss":6.5183}
{"epoch":103,"val_loss":186.45172,"val_metric":{"accuracy":0.6199,"micro":0.6199,"macro":0.58783},"test_metric":{"accuracy":0.65379,"micro":0.65379,"macro":0.62064},"tolerance:":4}
{"epoch":104,"time":3794.22126,"train_loss":7.28666}
{"epoch":104,"val_loss":164.38075,"val_metric":{"accuracy":0.5884,"micro":0.5884,"macro":0.5684},"test_metric":{"accuracy":0.6123,"micro":0.6123,"macro":0.58805},"tolerance:":5}
{"epoch":105,"time":3830.20655,"train_loss":10.10684}
{"epoch":105,"val_loss":182.66816,"val_metric":{"accuracy":0.65784,"micro":0.65784,"macro":0.6056},"test_metric":{"accuracy":0.70386,"micro":0.70386,"macro":0.65819},"tolerance:":6}
{"epoch":106,"time":3866.54084,"train_loss":6.72658}
{"epoch":106,"val_loss":187.01994,"val_metric":{"accuracy":0.64281,"micro":0.64281,"macro":0.59968},"test_metric":{"accuracy":0.6824,"micro":0.6824,"macro":0.6425},"tolerance:":7}
{"epoch":107,"time":3902.60143,"train_loss":7.00653}
{"epoch":107,"val_loss":179.01571,"val_metric":{"accuracy":0.62062,"micro":0.62062,"macro":0.58685},"test_metric":{"accuracy":0.66237,"micro":0.66237,"macro":0.62941},"tolerance:":8}
{"epoch":108,"time":3938.31922,"train_loss":6.5553}
{"epoch":108,"val_loss":194.98207,"val_metric":{"accuracy":0.65354,"micro":0.65354,"macro":0.61277},"test_metric":{"accuracy":0.69385,"micro":0.69385,"macro":0.66194},"tolerance:":9}
{"epoch":109,"time":3973.77349,"train_loss":5.90882}
{"epoch":109,"val_loss":196.04592,"val_metric":{"accuracy":0.61059,"micro":0.61059,"macro":0.57758},"test_metric":{"accuracy":0.65951,"micro":0.65951,"macro":0.62642},"tolerance:":10}
{"epoch":110,"time":4009.92467,"train_loss":8.35531}
{"epoch":110,"val_loss":180.93324,"val_metric":{"accuracy":0.60773,"micro":0.60773,"macro":0.58015},"test_metric":{"accuracy":0.64521,"micro":0.64521,"macro":0.61463},"tolerance:":11}
{"epoch":111,"time":4046.32253,"train_loss":6.67232}
{"epoch":111,"val_loss":190.50837,"val_metric":{"accuracy":0.60344,"micro":0.60344,"macro":0.57409},"test_metric":{"accuracy":0.6309,"micro":0.6309,"macro":0.59813},"tolerance:":12}
{"epoch":112,"time":4082.60974,"train_loss":7.67066}
{"epoch":112,"val_loss":161.7146,"val_metric":{"accuracy":0.58125,"micro":0.58125,"macro":0.56301},"test_metric":{"accuracy":0.59371,"micro":0.59371,"macro":0.57014},"tolerance:":13}
{"epoch":113,"time":4118.1032,"train_loss":8.87536}
{"epoch":113,"val_loss":165.97401,"val_metric":{"accuracy":0.66428,"micro":0.66428,"macro":0.60998},"test_metric":{"accuracy":0.69099,"micro":0.69099,"macro":0.64515},"tolerance:":14}
{"epoch":114,"time":4154.1663,"train_loss":7.26896}
{"epoch":114,"val_loss":181.29655,"val_metric":{"accuracy":0.65569,"micro":0.65569,"macro":0.59719},"test_metric":{"accuracy":0.69671,"micro":0.69671,"macro":0.65356},"tolerance:":15}
{"epoch":115,"time":4190.63689,"train_loss":8.05072}
{"epoch":115,"val_loss":188.65264,"val_metric":{"accuracy":0.62062,"micro":0.62062,"macro":0.59622},"test_metric":{"accuracy":0.64664,"micro":0.64664,"macro":0.61811},"tolerance:":16}
{"epoch":116,"time":4227.10503,"train_loss":6.87191}
{"epoch":116,"val_loss":185.19235,"val_metric":{"accuracy":0.5927,"micro":0.5927,"macro":0.55823},"test_metric":{"accuracy":0.62089,"micro":0.62089,"macro":0.59255},"tolerance:":17}
{"epoch":117,"time":4263.67804,"train_loss":7.61881}
{"epoch":117,"val_loss":181.01611,"val_metric":{"accuracy":0.60702,"micro":0.60702,"macro":0.58033},"test_metric":{"accuracy":0.62947,"micro":0.62947,"macro":0.60255},"tolerance:":18}
{"epoch":118,"time":4300.00412,"train_loss":7.26579}
{"epoch":118,"val_loss":191.1416,"val_metric":{"accuracy":0.61131,"micro":0.61131,"macro":0.57519},"test_metric":{"accuracy":0.64378,"micro":0.64378,"macro":0.61221},"tolerance:":19}
{"epoch":119,"time":4336.43275,"train_loss":6.30334}
{"epoch":119,"val_loss":172.29837,"val_metric":{"accuracy":0.60773,"micro":0.60773,"macro":0.57998},"test_metric":{"accuracy":0.64235,"micro":0.64235,"macro":0.61049},"tolerance:":20}
{"epoch":120,"time":4372.24378,"train_loss":6.22268}
{"epoch":120,"val_loss":170.63249,"val_metric":{"accuracy":0.62348,"micro":0.62348,"macro":0.57839},"test_metric":{"accuracy":0.6681,"micro":0.6681,"macro":0.63502},"tolerance:":21}
{"epoch":121,"time":4409.0315,"train_loss":5.69001}
{"epoch":121,"val_loss":187.43124,"val_metric":{"accuracy":0.60487,"micro":0.60487,"macro":0.56634},"test_metric":{"accuracy":0.62518,"micro":0.62518,"macro":0.58863},"tolerance:":22}
{"epoch":122,"time":4445.64922,"train_loss":6.8962}
{"epoch":122,"val_loss":196.30112,"val_metric":{"accuracy":0.6514,"micro":0.6514,"macro":0.609},"test_metric":{"accuracy":0.68383,"micro":0.68383,"macro":0.64193},"tolerance:":23}
{"epoch":123,"time":4481.61294,"train_loss":4.2745}
{"epoch":123,"val_loss":200.97347,"val_metric":{"accuracy":0.62563,"micro":0.62563,"macro":0.59695},"test_metric":{"accuracy":0.64378,"micro":0.64378,"macro":0.60862},"tolerance:":24}
{"epoch":124,"time":4517.02516,"train_loss":7.35372}
{"epoch":124,"val_loss":188.77991,"val_metric":{"accuracy":0.63636,"micro":0.63636,"macro":0.59545},"test_metric":{"accuracy":0.67239,"micro":0.67239,"macro":0.6357},"tolerance:":25}
{"epoch":125,"time":4552.45128,"train_loss":6.26386}
{"epoch":125,"val_loss":201.00192,"val_metric":{"accuracy":0.65855,"micro":0.65855,"macro":0.60316},"test_metric":{"accuracy":0.71245,"micro":0.71245,"macro":0.66908},"tolerance:":26}
{"epoch":126,"time":4588.50568,"train_loss":5.80246}
{"epoch":126,"val_loss":205.82255,"val_metric":{"accuracy":0.65426,"micro":0.65426,"macro":0.60293},"test_metric":{"accuracy":0.701,"micro":0.701,"macro":0.65398},"tolerance:":27}
{"epoch":127,"time":4624.71068,"train_loss":5.66436}
{"epoch":127,"val_loss":211.05634,"val_metric":{"accuracy":0.6471,"micro":0.6471,"macro":0.59918},"test_metric":{"accuracy":0.69671,"micro":0.69671,"macro":0.65758},"tolerance:":28}
{"epoch":128,"time":4660.63721,"train_loss":5.62915}
{"epoch":128,"val_loss":203.3683,"val_metric":{"accuracy":0.65999,"micro":0.65999,"macro":0.60541},"test_metric":{"accuracy":0.71674,"micro":0.71674,"macro":0.68208},"tolerance:":29}
{"epoch":129,"time":4697.16685,"train_loss":6.98025}
{"epoch":129,"val_loss":222.23704,"val_metric":{"accuracy":0.65354,"micro":0.65354,"macro":0.59532},"test_metric":{"accuracy":0.71531,"micro":0.71531,"macro":0.67427},"tolerance:":30}
{"epoch":130,"time":4733.41378,"train_loss":6.88164}
{"epoch":130,"val_loss":209.55641,"val_metric":{"accuracy":0.62276,"micro":0.62276,"macro":0.58591},"test_metric":{"accuracy":0.67954,"micro":0.67954,"macro":0.64561},"tolerance:":31}
{"epoch":131,"time":4769.7216,"train_loss":6.27496}
{"epoch":131,"val_loss":214.02026,"val_metric":{"accuracy":0.63923,"micro":0.63923,"macro":0.58938},"test_metric":{"accuracy":0.68383,"micro":0.68383,"macro":0.64109},"tolerance:":32}
{"epoch":132,"time":4806.18974,"train_loss":5.54483}
{"epoch":132,"val_loss":188.78488,"val_metric":{"accuracy":0.64495,"micro":0.64495,"macro":0.60198},"test_metric":{"accuracy":0.67382,"micro":0.67382,"macro":0.635},"tolerance:":33}
{"epoch":133,"time":4842.71534,"train_loss":6.17757}
{"epoch":133,"val_loss":169.74225,"val_metric":{"accuracy":0.56407,"micro":0.56407,"macro":0.54445},"test_metric":{"accuracy":0.598,"micro":0.598,"macro":0.57351},"tolerance:":34}
{"epoch":134,"time":4878.95,"train_loss":8.24359}
{"epoch":134,"val_loss":195.11099,"val_metric":{"accuracy":0.61417,"micro":0.61417,"macro":0.57825},"test_metric":{"accuracy":0.65093,"micro":0.65093,"macro":0.61394},"tolerance:":35}
{"epoch":135,"time":4915.44294,"train_loss":6.53611}
{"epoch":135,"val_loss":215.18691,"val_metric":{"accuracy":0.58769,"micro":0.58769,"macro":0.56172},"test_metric":{"accuracy":0.60801,"micro":0.60801,"macro":0.57773},"tolerance:":36}
{"epoch":136,"time":4951.53365,"train_loss":7.23612}
{"epoch":136,"val_loss":159.27591,"val_metric":{"accuracy":0.56621,"micro":0.56621,"macro":0.54364},"test_metric":{"accuracy":0.598,"micro":0.598,"macro":0.56992},"tolerance:":37}
{"epoch":137,"time":4987.58386,"train_loss":11.78083}
{"epoch":137,"val_loss":190.63756,"val_metric":{"accuracy":0.58053,"micro":0.58053,"macro":0.55657},"test_metric":{"accuracy":0.59514,"micro":0.59514,"macro":0.56883},"tolerance:":38}
{"epoch":138,"time":5024.3171,"train_loss":8.07522}
{"epoch":138,"val_loss":192.52517,"val_metric":{"accuracy":0.62849,"micro":0.62849,"macro":0.57769},"test_metric":{"accuracy":0.65951,"micro":0.65951,"macro":0.61768},"tolerance:":39}
{"epoch":139,"time":5060.37019,"train_loss":7.70822}
{"epoch":139,"val_loss":188.4992,"val_metric":{"accuracy":0.59771,"micro":0.59771,"macro":0.56287},"test_metric":{"accuracy":0.62804,"micro":0.62804,"macro":0.59518},"tolerance:":40}
{"epoch":140,"time":5096.57785,"train_loss":7.19425}
{"epoch":140,"val_loss":170.61521,"val_metric":{"accuracy":0.5927,"micro":0.5927,"macro":0.56337},"test_metric":{"accuracy":0.61373,"micro":0.61373,"macro":0.58354},"tolerance:":41}
{"epoch":141,"time":5132.97592,"train_loss":5.94705}
{"epoch":141,"val_loss":175.46569,"val_metric":{"accuracy":0.59485,"micro":0.59485,"macro":0.55374},"test_metric":{"accuracy":0.6123,"micro":0.6123,"macro":0.58361},"tolerance:":42}
{"epoch":142,"time":5169.37753,"train_loss":5.46405}
{"epoch":142,"val_loss":183.67603,"val_metric":{"accuracy":0.5927,"micro":0.5927,"macro":0.5626},"test_metric":{"accuracy":0.60944,"micro":0.60944,"macro":0.58054},"tolerance:":43}
{"epoch":143,"time":5204.92173,"train_loss":5.10999}
{"epoch":143,"val_loss":198.08334,"val_metric":{"accuracy":0.60415,"micro":0.60415,"macro":0.56536},"test_metric":{"accuracy":0.63376,"micro":0.63376,"macro":0.60421},"tolerance:":44}
{"epoch":144,"time":5240.11641,"train_loss":7.57621}
{"epoch":144,"val_loss":193.09681,"val_metric":{"accuracy":0.60415,"micro":0.60415,"macro":0.56218},"test_metric":{"accuracy":0.62375,"micro":0.62375,"macro":0.59391},"tolerance:":45}
{"epoch":145,"time":5276.47868,"train_loss":6.25752}
{"epoch":145,"val_loss":184.90051,"val_metric":{"accuracy":0.57623,"micro":0.57623,"macro":0.55194},"test_metric":{"accuracy":0.59514,"micro":0.59514,"macro":0.56474},"tolerance:":46}
{"epoch":146,"time":5312.34949,"train_loss":7.58346}
{"epoch":146,"val_loss":208.02962,"val_metric":{"accuracy":0.6199,"micro":0.6199,"macro":0.57536},"test_metric":{"accuracy":0.67096,"micro":0.67096,"macro":0.63278},"tolerance:":47}
{"epoch":147,"time":5348.60958,"train_loss":7.85386}
{"epoch":147,"val_loss":181.01436,"val_metric":{"accuracy":0.58554,"micro":0.58554,"macro":0.54965},"test_metric":{"accuracy":0.65236,"micro":0.65236,"macro":0.62532},"tolerance:":48}
{"epoch":148,"time":5384.6943,"train_loss":5.48258}
{"epoch":148,"val_loss":190.78265,"val_metric":{"accuracy":0.65497,"micro":0.65497,"macro":0.60424},"test_metric":{"accuracy":0.69957,"micro":0.69957,"macro":0.65991},"tolerance:":49}
{"epoch":149,"time":5420.1802,"train_loss":9.36408}
{"epoch":149,"val_loss":183.12271,"val_metric":{"accuracy":0.59341,"micro":0.59341,"macro":0.55724},"test_metric":{"accuracy":0.63805,"micro":0.63805,"macro":0.61558},"tolerance:":50}
{"epoch":150,"time":5456.64619,"train_loss":6.36367}
{"epoch":150,"val_loss":180.76728,"val_metric":{"accuracy":0.6063,"micro":0.6063,"macro":0.57307},"test_metric":{"accuracy":0.64664,"micro":0.64664,"macro":0.61959},"tolerance:":51}
{"epoch":151,"time":5492.60656,"train_loss":5.91647}
{"epoch":151,"val_loss":186.59355,"val_metric":{"accuracy":0.59628,"micro":0.59628,"macro":0.56311},"test_metric":{"accuracy":0.63376,"micro":0.63376,"macro":0.60429},"tolerance:":52}
{"epoch":152,"time":5529.42329,"train_loss":5.56231}
{"epoch":152,"val_loss":202.63303,"val_metric":{"accuracy":0.5927,"micro":0.5927,"macro":0.55818},"test_metric":{"accuracy":0.63519,"micro":0.63519,"macro":0.60398},"tolerance:":53}
{"epoch":153,"time":5565.1064,"train_loss":6.6289}
{"epoch":153,"val_loss":184.99206,"val_metric":{"accuracy":0.58912,"micro":0.58912,"macro":0.55837},"test_metric":{"accuracy":0.6166,"micro":0.6166,"macro":0.59345},"tolerance:":54}
{"epoch":154,"time":5602.00205,"train_loss":5.06618}
{"epoch":154,"val_loss":206.9698,"val_metric":{"accuracy":0.61346,"micro":0.61346,"macro":0.58147},"test_metric":{"accuracy":0.65379,"micro":0.65379,"macro":0.62087},"tolerance:":55}
{"epoch":155,"time":5638.48394,"train_loss":7.3078}
{"epoch":155,"val_loss":191.61571,"val_metric":{"accuracy":0.60702,"micro":0.60702,"macro":0.57091},"test_metric":{"accuracy":0.64092,"micro":0.64092,"macro":0.61129},"tolerance:":56}
{"epoch":156,"time":5674.78564,"train_loss":5.55921}
{"epoch":156,"val_loss":186.2287,"val_metric":{"accuracy":0.62921,"micro":0.62921,"macro":0.58828},"test_metric":{"accuracy":0.66237,"micro":0.66237,"macro":0.63268},"tolerance:":57}
{"epoch":157,"time":5711.19158,"train_loss":5.81778}
{"epoch":157,"val_loss":190.2512,"val_metric":{"accuracy":0.61131,"micro":0.61131,"macro":0.56917},"test_metric":{"accuracy":0.64092,"micro":0.64092,"macro":0.61018},"tolerance:":58}
{"epoch":158,"time":5747.49414,"train_loss":4.92316}
{"epoch":158,"val_loss":195.9483,"val_metric":{"accuracy":0.64925,"micro":0.64925,"macro":0.59301},"test_metric":{"accuracy":0.6824,"micro":0.6824,"macro":0.64094},"tolerance:":59}
{"epoch":159,"time":5783.79964,"train_loss":5.88457}
{"epoch":159,"val_loss":215.4514,"val_metric":{"accuracy":0.60702,"micro":0.60702,"macro":0.56473},"test_metric":{"accuracy":0.66237,"micro":0.66237,"macro":0.63518},"tolerance:":60}
{"epoch":160,"time":5820.27286,"train_loss":7.57312}
{"epoch":160,"val_loss":201.0881,"val_metric":{"accuracy":0.63565,"micro":0.63565,"macro":0.57836},"test_metric":{"accuracy":0.6867,"micro":0.6867,"macro":0.65019},"tolerance:":61}
{"epoch":161,"time":5856.39101,"train_loss":6.6258}
{"epoch":161,"val_loss":182.50885,"val_metric":{"accuracy":0.64495,"micro":0.64495,"macro":0.58189},"test_metric":{"accuracy":0.68097,"micro":0.68097,"macro":0.63378},"tolerance:":62}
{"epoch":162,"time":5892.62105,"train_loss":5.94304}
{"epoch":162,"val_loss":207.31251,"val_metric":{"accuracy":0.58912,"micro":0.58912,"macro":0.5615},"test_metric":{"accuracy":0.60801,"micro":0.60801,"macro":0.58194},"tolerance:":63}
{"epoch":163,"time":5928.35264,"train_loss":5.32415}
{"epoch":163,"val_loss":222.05777,"val_metric":{"accuracy":0.64996,"micro":0.64996,"macro":0.58157},"test_metric":{"accuracy":0.67525,"micro":0.67525,"macro":0.62095},"tolerance:":64}
{"epoch":164,"time":5964.60435,"train_loss":7.74489}
{"epoch":164,"val_loss":190.10855,"val_metric":{"accuracy":0.62348,"micro":0.62348,"macro":0.5762},"test_metric":{"accuracy":0.66094,"micro":0.66094,"macro":0.62625},"tolerance:":65}
{"epoch":165,"time":6000.60748,"train_loss":8.04393}
{"epoch":165,"val_loss":175.30695,"val_metric":{"accuracy":0.57767,"micro":0.57767,"macro":0.546},"test_metric":{"accuracy":0.6309,"micro":0.6309,"macro":0.59513},"tolerance:":66}
{"epoch":166,"time":6036.50858,"train_loss":5.57764}
{"epoch":166,"val_loss":202.99877,"val_metric":{"accuracy":0.58697,"micro":0.58697,"macro":0.5525},"test_metric":{"accuracy":0.63805,"micro":0.63805,"macro":0.5989},"tolerance:":67}
{"epoch":167,"time":6073.13757,"train_loss":7.66655}
{"epoch":167,"val_loss":200.73289,"val_metric":{"accuracy":0.57767,"micro":0.57767,"macro":0.54078},"test_metric":{"accuracy":0.62661,"micro":0.62661,"macro":0.5905},"tolerance:":68}
{"epoch":168,"time":6109.38568,"train_loss":5.3104}
{"epoch":168,"val_loss":210.15623,"val_metric":{"accuracy":0.59986,"micro":0.59986,"macro":0.56807},"test_metric":{"accuracy":0.65808,"micro":0.65808,"macro":0.62291},"tolerance:":69}
{"epoch":169,"time":6145.59566,"train_loss":6.02219}
{"epoch":169,"val_loss":191.59128,"val_metric":{"accuracy":0.59556,"micro":0.59556,"macro":0.56394},"test_metric":{"accuracy":0.63805,"micro":0.63805,"macro":0.60205},"tolerance:":70}
{"epoch":170,"time":6182.53691,"train_loss":5.16201}
{"epoch":170,"val_loss":215.77573,"val_metric":{"accuracy":0.60916,"micro":0.60916,"macro":0.57451},"test_metric":{"accuracy":0.65379,"micro":0.65379,"macro":0.61734},"tolerance:":71}
{"epoch":171,"time":6219.21283,"train_loss":4.16713}
{"epoch":171,"val_loss":223.39933,"val_metric":{"accuracy":0.59986,"micro":0.59986,"macro":0.56143},"test_metric":{"accuracy":0.64807,"micro":0.64807,"macro":0.6107},"tolerance:":72}
{"epoch":172,"time":6256.01598,"train_loss":7.52542}
{"epoch":172,"val_loss":163.87022,"val_metric":{"accuracy":0.55619,"micro":0.55619,"macro":0.53421},"test_metric":{"accuracy":0.57511,"micro":0.57511,"macro":0.55191},"tolerance:":73}
{"epoch":173,"time":6291.72439,"train_loss":5.29901}
{"epoch":173,"val_loss":199.04908,"val_metric":{"accuracy":0.59771,"micro":0.59771,"macro":0.55777},"test_metric":{"accuracy":0.64235,"micro":0.64235,"macro":0.60395},"tolerance:":74}
{"epoch":174,"time":6327.41689,"train_loss":7.47138}
{"epoch":174,"val_loss":194.73108,"val_metric":{"accuracy":0.60773,"micro":0.60773,"macro":0.57123},"test_metric":{"accuracy":0.6309,"micro":0.6309,"macro":0.59289},"tolerance:":75}
{"epoch":175,"time":6363.13879,"train_loss":5.95337}
{"epoch":175,"val_loss":192.72188,"val_metric":{"accuracy":0.58411,"micro":0.58411,"macro":0.5584},"test_metric":{"accuracy":0.62089,"micro":0.62089,"macro":0.59137},"tolerance:":76}
{"epoch":176,"time":6399.87782,"train_loss":4.66151}
{"epoch":176,"val_loss":214.59183,"val_metric":{"accuracy":0.58411,"micro":0.58411,"macro":0.55663},"test_metric":{"accuracy":0.61087,"micro":0.61087,"macro":0.58126},"tolerance:":77}
{"epoch":177,"time":6435.99134,"train_loss":5.24791}
{"epoch":177,"val_loss":175.79111,"val_metric":{"accuracy":0.58268,"micro":0.58268,"macro":0.53733},"test_metric":{"accuracy":0.59514,"micro":0.59514,"macro":0.56731},"tolerance:":78}
{"epoch":178,"time":6472.45517,"train_loss":7.08057}
{"epoch":178,"val_loss":215.07363,"val_metric":{"accuracy":0.61704,"micro":0.61704,"macro":0.58294},"test_metric":{"accuracy":0.65951,"micro":0.65951,"macro":0.62457},"tolerance:":79}
{"epoch":179,"time":6508.38779,"train_loss":5.07282}
{"epoch":179,"val_loss":202.84878,"val_metric":{"accuracy":0.58697,"micro":0.58697,"macro":0.55639},"test_metric":{"accuracy":0.62518,"micro":0.62518,"macro":0.59316},"tolerance:":80}
{"epoch":180,"time":6544.73145,"train_loss":6.25172}
{"epoch":180,"val_loss":197.91191,"val_metric":{"accuracy":0.5884,"micro":0.5884,"macro":0.54608},"test_metric":{"accuracy":0.64521,"micro":0.64521,"macro":0.61288},"tolerance:":81}
{"epoch":181,"time":6581.48638,"train_loss":4.3849}
{"epoch":181,"val_loss":212.96777,"val_metric":{"accuracy":0.58482,"micro":0.58482,"macro":0.53543},"test_metric":{"accuracy":0.64378,"micro":0.64378,"macro":0.61634},"tolerance:":82}
{"epoch":182,"time":6617.72887,"train_loss":4.54203}
{"epoch":182,"val_loss":201.31747,"val_metric":{"accuracy":0.55476,"micro":0.55476,"macro":0.5361},"test_metric":{"accuracy":0.57511,"micro":0.57511,"macro":0.55202},"tolerance:":83}
{"epoch":183,"time":6654.1275,"train_loss":6.52695}
{"epoch":183,"val_loss":199.45509,"val_metric":{"accuracy":0.57623,"micro":0.57623,"macro":0.55246},"test_metric":{"accuracy":0.6123,"micro":0.6123,"macro":0.58711},"tolerance:":84}
{"epoch":184,"time":6690.39436,"train_loss":5.42221}
{"epoch":184,"val_loss":206.04112,"val_metric":{"accuracy":0.60129,"micro":0.60129,"macro":0.56966},"test_metric":{"accuracy":0.64235,"micro":0.64235,"macro":0.60862},"tolerance:":85}
{"epoch":185,"time":6726.88579,"train_loss":5.62309}
{"epoch":185,"val_loss":214.58073,"val_metric":{"accuracy":0.58268,"micro":0.58268,"macro":0.54844},"test_metric":{"accuracy":0.62518,"micro":0.62518,"macro":0.59269},"tolerance:":86}
{"epoch":186,"time":6763.17313,"train_loss":6.26645}
{"epoch":186,"val_loss":189.91821,"val_metric":{"accuracy":0.57552,"micro":0.57552,"macro":0.55124},"test_metric":{"accuracy":0.61946,"micro":0.61946,"macro":0.59151},"tolerance:":87}
{"epoch":187,"time":6799.64037,"train_loss":8.29903}
{"epoch":187,"val_loss":183.89533,"val_metric":{"accuracy":0.54832,"micro":0.54832,"macro":0.50976},"test_metric":{"accuracy":0.60229,"micro":0.60229,"macro":0.57774},"tolerance:":88}
{"epoch":188,"time":6836.32917,"train_loss":8.83562}
{"epoch":188,"val_loss":162.70465,"val_metric":{"accuracy":0.6063,"micro":0.6063,"macro":0.56652},"test_metric":{"accuracy":0.62947,"micro":0.62947,"macro":0.59392},"tolerance:":89}
{"epoch":189,"time":6872.54877,"train_loss":9.21014}
{"epoch":189,"val_loss":169.99771,"val_metric":{"accuracy":0.59986,"micro":0.59986,"macro":0.56335},"test_metric":{"accuracy":0.65093,"micro":0.65093,"macro":0.61232},"tolerance:":90}
{"epoch":190,"time":6908.74195,"train_loss":5.35053}
{"epoch":190,"val_loss":204.545,"val_metric":{"accuracy":0.60272,"micro":0.60272,"macro":0.56354},"test_metric":{"accuracy":0.64521,"micro":0.64521,"macro":0.60697},"tolerance:":91}
{"epoch":191,"time":6945.19703,"train_loss":6.2423}
{"epoch":191,"val_loss":179.63527,"val_metric":{"accuracy":0.57552,"micro":0.57552,"macro":0.5536},"test_metric":{"accuracy":0.62089,"micro":0.62089,"macro":0.59215},"tolerance:":92}
{"epoch":192,"time":6981.52128,"train_loss":7.82308}
{"epoch":192,"val_loss":180.14002,"val_metric":{"accuracy":0.56049,"micro":0.56049,"macro":0.53835},"test_metric":{"accuracy":0.59371,"micro":0.59371,"macro":0.56526},"tolerance:":93}
{"epoch":193,"time":7017.77996,"train_loss":6.60285}
{"epoch":193,"val_loss":174.85714,"val_metric":{"accuracy":0.56407,"micro":0.56407,"macro":0.54037},"test_metric":{"accuracy":0.598,"micro":0.598,"macro":0.5707},"tolerance:":94}
{"epoch":194,"time":7054.23939,"train_loss":6.46572}
{"epoch":194,"val_loss":161.52621,"val_metric":{"accuracy":0.56192,"micro":0.56192,"macro":0.54219},"test_metric":{"accuracy":0.62232,"micro":0.62232,"macro":0.59628},"tolerance:":95}
{"epoch":195,"time":7089.92545,"train_loss":6.9388}
{"epoch":195,"val_loss":190.00383,"val_metric":{"accuracy":0.59341,"micro":0.59341,"macro":0.56382},"test_metric":{"accuracy":0.64092,"micro":0.64092,"macro":0.60512},"tolerance:":96}
{"epoch":196,"time":7126.2682,"train_loss":5.83774}
{"epoch":196,"val_loss":179.92666,"val_metric":{"accuracy":0.55333,"micro":0.55333,"macro":0.53682},"test_metric":{"accuracy":0.59227,"micro":0.59227,"macro":0.57134},"tolerance:":97}
{"epoch":197,"time":7162.73532,"train_loss":6.30518}
{"epoch":197,"val_loss":201.27833,"val_metric":{"accuracy":0.56908,"micro":0.56908,"macro":0.53076},"test_metric":{"accuracy":0.61803,"micro":0.61803,"macro":0.5907},"tolerance:":98}
{"epoch":198,"time":7198.96278,"train_loss":5.05774}
{"epoch":198,"val_loss":212.59511,"val_metric":{"accuracy":0.57695,"micro":0.57695,"macro":0.54571},"test_metric":{"accuracy":0.6123,"micro":0.6123,"macro":0.58848},"tolerance:":99}
{"epoch":199,"time":7235.10253,"train_loss":5.19492}
{"epoch":199,"val_loss":191.08379,"val_metric":{"accuracy":0.55691,"micro":0.55691,"macro":0.52135},"test_metric":{"accuracy":0.59084,"micro":0.59084,"macro":0.5605},"tolerance:":100}
{"epoch":200,"time":7272.329,"train_loss":4.68456}
{"epoch":200,"val_loss":200.06862,"val_metric":{"accuracy":0.5791,"micro":0.5791,"macro":0.55138},"test_metric":{"accuracy":0.60944,"micro":0.60944,"macro":0.58106},"tolerance:":101}
{"epoch":99,"val_loss":176.26878,"val_metric":{"accuracy":0.66714,"micro":0.66714,"macro":0.61493},"test_metric":{"accuracy":0.72675,"micro":0.72675,"macro":0.68983}}
/home/daniel/local/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/home/daniel/local/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1145: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.
  'recall', 'true', average, warn_for)
-- done --
