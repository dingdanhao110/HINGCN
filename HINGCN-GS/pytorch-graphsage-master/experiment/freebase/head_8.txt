NodeProblem: loading started
loading edge embedding for MAM complete, num of embeddings: 129098
loading edge embedding for MDM complete, num of embeddings: 5949
loading edge embedding for MWM complete, num of embeddings: 7100
NodeProblem: loading finished
Let's use 2 GPUs!
DataParallel(
  (module): HINGCN_GS(
    (prep): NodeEmbeddingPrep(
      (embedding): Embedding(3493, 32)
      (fc): Linear(in_features=32, out_features=32, bias=True)
    )
    (agg_0_0): ModuleList(
      (0): AttentionAggregator2(
        (attn_dropout): Dropout(p=0.3)
        (att): Sequential(
          (0): Linear(in_features=32, out_features=512, bias=False)
          (1): Tanh()
          (2): Linear(in_features=512, out_features=512, bias=False)
        )
        (att2): Sequential(
          (0): Linear(in_features=50, out_features=512, bias=False)
          (1): Tanh()
          (2): Linear(in_features=512, out_features=512, bias=False)
        )
        (fc_x): Linear(in_features=32, out_features=64, bias=False)
        (fc_neib): Linear(in_features=50, out_features=64, bias=False)
        (dropout): Dropout(p=0.5)
      )
      (1): AttentionAggregator2(
        (attn_dropout): Dropout(p=0.3)
        (att): Sequential(
          (0): Linear(in_features=32, out_features=512, bias=False)
          (1): Tanh()
          (2): Linear(in_features=512, out_features=512, bias=False)
        )
        (att2): Sequential(
          (0): Linear(in_features=50, out_features=512, bias=False)
          (1): Tanh()
          (2): Linear(in_features=512, out_features=512, bias=False)
        )
        (fc_x): Linear(in_features=32, out_features=64, bias=False)
        (fc_neib): Linear(in_features=50, out_features=64, bias=False)
        (dropout): Dropout(p=0.5)
      )
      (2): AttentionAggregator2(
        (attn_dropout): Dropout(p=0.3)
        (att): Sequential(
          (0): Linear(in_features=32, out_features=512, bias=False)
          (1): Tanh()
          (2): Linear(in_features=512, out_features=512, bias=False)
        )
        (att2): Sequential(
          (0): Linear(in_features=50, out_features=512, bias=False)
          (1): Tanh()
          (2): Linear(in_features=512, out_features=512, bias=False)
        )
        (fc_x): Linear(in_features=32, out_features=64, bias=False)
        (fc_neib): Linear(in_features=50, out_features=64, bias=False)
        (dropout): Dropout(p=0.5)
      )
      (3): AttentionAggregator2(
        (attn_dropout): Dropout(p=0.3)
        (att): Sequential(
          (0): Linear(in_features=32, out_features=512, bias=False)
          (1): Tanh()
          (2): Linear(in_features=512, out_features=512, bias=False)
        )
        (att2): Sequential(
          (0): Linear(in_features=50, out_features=512, bias=False)
          (1): Tanh()
          (2): Linear(in_features=512, out_features=512, bias=False)
        )
        (fc_x): Linear(in_features=32, out_features=64, bias=False)
        (fc_neib): Linear(in_features=50, out_features=64, bias=False)
        (dropout): Dropout(p=0.5)
      )
      (4): AttentionAggregator2(
        (attn_dropout): Dropout(p=0.3)
        (att): Sequential(
          (0): Linear(in_features=32, out_features=512, bias=False)
          (1): Tanh()
          (2): Linear(in_features=512, out_features=512, bias=False)
        )
        (att2): Sequential(
          (0): Linear(in_features=50, out_features=512, bias=False)
          (1): Tanh()
          (2): Linear(in_features=512, out_features=512, bias=False)
        )
        (fc_x): Linear(in_features=32, out_features=64, bias=False)
        (fc_neib): Linear(in_features=50, out_features=64, bias=False)
        (dropout): Dropout(p=0.5)
      )
      (5): AttentionAggregator2(
        (attn_dropout): Dropout(p=0.3)
        (att): Sequential(
          (0): Linear(in_features=32, out_features=512, bias=False)
          (1): Tanh()
          (2): Linear(in_features=512, out_features=512, bias=False)
        )
        (att2): Sequential(
          (0): Linear(in_features=50, out_features=512, bias=False)
          (1): Tanh()
          (2): Linear(in_features=512, out_features=512, bias=False)
        )
        (fc_x): Linear(in_features=32, out_features=64, bias=False)
        (fc_neib): Linear(in_features=50, out_features=64, bias=False)
        (dropout): Dropout(p=0.5)
      )
      (6): AttentionAggregator2(
        (attn_dropout): Dropout(p=0.3)
        (att): Sequential(
          (0): Linear(in_features=32, out_features=512, bias=False)
          (1): Tanh()
          (2): Linear(in_features=512, out_features=512, bias=False)
        )
        (att2): Sequential(
          (0): Linear(in_features=50, out_features=512, bias=False)
          (1): Tanh()
          (2): Linear(in_features=512, out_features=512, bias=False)
        )
        (fc_x): Linear(in_features=32, out_features=64, bias=False)
        (fc_neib): Linear(in_features=50, out_features=64, bias=False)
        (dropout): Dropout(p=0.5)
      )
      (7): AttentionAggregator2(
        (attn_dropout): Dropout(p=0.3)
        (att): Sequential(
          (0): Linear(in_features=32, out_features=512, bias=False)
          (1): Tanh()
          (2): Linear(in_features=512, out_features=512, bias=False)
        )
        (att2): Sequential(
          (0): Linear(in_features=50, out_features=512, bias=False)
          (1): Tanh()
          (2): Linear(in_features=512, out_features=512, bias=False)
        )
        (fc_x): Linear(in_features=32, out_features=64, bias=False)
        (fc_neib): Linear(in_features=50, out_features=64, bias=False)
        (dropout): Dropout(p=0.5)
      )
    )
    (edge_0_0): IdEdgeAggregator(
      (dropout): Dropout(p=0.5)
    )
    (agg_1_0): ModuleList(
      (0): AttentionAggregator2(
        (attn_dropout): Dropout(p=0.3)
        (att): Sequential(
          (0): Linear(in_features=32, out_features=512, bias=False)
          (1): Tanh()
          (2): Linear(in_features=512, out_features=512, bias=False)
        )
        (att2): Sequential(
          (0): Linear(in_features=50, out_features=512, bias=False)
          (1): Tanh()
          (2): Linear(in_features=512, out_features=512, bias=False)
        )
        (fc_x): Linear(in_features=32, out_features=64, bias=False)
        (fc_neib): Linear(in_features=50, out_features=64, bias=False)
        (dropout): Dropout(p=0.5)
      )
      (1): AttentionAggregator2(
        (attn_dropout): Dropout(p=0.3)
        (att): Sequential(
          (0): Linear(in_features=32, out_features=512, bias=False)
          (1): Tanh()
          (2): Linear(in_features=512, out_features=512, bias=False)
        )
        (att2): Sequential(
          (0): Linear(in_features=50, out_features=512, bias=False)
          (1): Tanh()
          (2): Linear(in_features=512, out_features=512, bias=False)
        )
        (fc_x): Linear(in_features=32, out_features=64, bias=False)
        (fc_neib): Linear(in_features=50, out_features=64, bias=False)
        (dropout): Dropout(p=0.5)
      )
      (2): AttentionAggregator2(
        (attn_dropout): Dropout(p=0.3)
        (att): Sequential(
          (0): Linear(in_features=32, out_features=512, bias=False)
          (1): Tanh()
          (2): Linear(in_features=512, out_features=512, bias=False)
        )
        (att2): Sequential(
          (0): Linear(in_features=50, out_features=512, bias=False)
          (1): Tanh()
          (2): Linear(in_features=512, out_features=512, bias=False)
        )
        (fc_x): Linear(in_features=32, out_features=64, bias=False)
        (fc_neib): Linear(in_features=50, out_features=64, bias=False)
        (dropout): Dropout(p=0.5)
      )
      (3): AttentionAggregator2(
        (attn_dropout): Dropout(p=0.3)
        (att): Sequential(
          (0): Linear(in_features=32, out_features=512, bias=False)
          (1): Tanh()
          (2): Linear(in_features=512, out_features=512, bias=False)
        )
        (att2): Sequential(
          (0): Linear(in_features=50, out_features=512, bias=False)
          (1): Tanh()
          (2): Linear(in_features=512, out_features=512, bias=False)
        )
        (fc_x): Linear(in_features=32, out_features=64, bias=False)
        (fc_neib): Linear(in_features=50, out_features=64, bias=False)
        (dropout): Dropout(p=0.5)
      )
      (4): AttentionAggregator2(
        (attn_dropout): Dropout(p=0.3)
        (att): Sequential(
          (0): Linear(in_features=32, out_features=512, bias=False)
          (1): Tanh()
          (2): Linear(in_features=512, out_features=512, bias=False)
        )
        (att2): Sequential(
          (0): Linear(in_features=50, out_features=512, bias=False)
          (1): Tanh()
          (2): Linear(in_features=512, out_features=512, bias=False)
        )
        (fc_x): Linear(in_features=32, out_features=64, bias=False)
        (fc_neib): Linear(in_features=50, out_features=64, bias=False)
        (dropout): Dropout(p=0.5)
      )
      (5): AttentionAggregator2(
        (attn_dropout): Dropout(p=0.3)
        (att): Sequential(
          (0): Linear(in_features=32, out_features=512, bias=False)
          (1): Tanh()
          (2): Linear(in_features=512, out_features=512, bias=False)
        )
        (att2): Sequential(
          (0): Linear(in_features=50, out_features=512, bias=False)
          (1): Tanh()
          (2): Linear(in_features=512, out_features=512, bias=False)
        )
        (fc_x): Linear(in_features=32, out_features=64, bias=False)
        (fc_neib): Linear(in_features=50, out_features=64, bias=False)
        (dropout): Dropout(p=0.5)
      )
      (6): AttentionAggregator2(
        (attn_dropout): Dropout(p=0.3)
        (att): Sequential(
          (0): Linear(in_features=32, out_features=512, bias=False)
          (1): Tanh()
          (2): Linear(in_features=512, out_features=512, bias=False)
        )
        (att2): Sequential(
          (0): Linear(in_features=50, out_features=512, bias=False)
          (1): Tanh()
          (2): Linear(in_features=512, out_features=512, bias=False)
        )
        (fc_x): Linear(in_features=32, out_features=64, bias=False)
        (fc_neib): Linear(in_features=50, out_features=64, bias=False)
        (dropout): Dropout(p=0.5)
      )
      (7): AttentionAggregator2(
        (attn_dropout): Dropout(p=0.3)
        (att): Sequential(
          (0): Linear(in_features=32, out_features=512, bias=False)
          (1): Tanh()
          (2): Linear(in_features=512, out_features=512, bias=False)
        )
        (att2): Sequential(
          (0): Linear(in_features=50, out_features=512, bias=False)
          (1): Tanh()
          (2): Linear(in_features=512, out_features=512, bias=False)
        )
        (fc_x): Linear(in_features=32, out_features=64, bias=False)
        (fc_neib): Linear(in_features=50, out_features=64, bias=False)
        (dropout): Dropout(p=0.5)
      )
    )
    (edge_1_0): IdEdgeAggregator(
      (dropout): Dropout(p=0.5)
    )
    (agg_2_0): ModuleList(
      (0): AttentionAggregator2(
        (attn_dropout): Dropout(p=0.3)
        (att): Sequential(
          (0): Linear(in_features=32, out_features=512, bias=False)
          (1): Tanh()
          (2): Linear(in_features=512, out_features=512, bias=False)
        )
        (att2): Sequential(
          (0): Linear(in_features=50, out_features=512, bias=False)
          (1): Tanh()
          (2): Linear(in_features=512, out_features=512, bias=False)
        )
        (fc_x): Linear(in_features=32, out_features=64, bias=False)
        (fc_neib): Linear(in_features=50, out_features=64, bias=False)
        (dropout): Dropout(p=0.5)
      )
      (1): AttentionAggregator2(
        (attn_dropout): Dropout(p=0.3)
        (att): Sequential(
          (0): Linear(in_features=32, out_features=512, bias=False)
          (1): Tanh()
          (2): Linear(in_features=512, out_features=512, bias=False)
        )
        (att2): Sequential(
          (0): Linear(in_features=50, out_features=512, bias=False)
          (1): Tanh()
          (2): Linear(in_features=512, out_features=512, bias=False)
        )
        (fc_x): Linear(in_features=32, out_features=64, bias=False)
        (fc_neib): Linear(in_features=50, out_features=64, bias=False)
        (dropout): Dropout(p=0.5)
      )
      (2): AttentionAggregator2(
        (attn_dropout): Dropout(p=0.3)
        (att): Sequential(
          (0): Linear(in_features=32, out_features=512, bias=False)
          (1): Tanh()
          (2): Linear(in_features=512, out_features=512, bias=False)
        )
        (att2): Sequential(
          (0): Linear(in_features=50, out_features=512, bias=False)
          (1): Tanh()
          (2): Linear(in_features=512, out_features=512, bias=False)
        )
        (fc_x): Linear(in_features=32, out_features=64, bias=False)
        (fc_neib): Linear(in_features=50, out_features=64, bias=False)
        (dropout): Dropout(p=0.5)
      )
      (3): AttentionAggregator2(
        (attn_dropout): Dropout(p=0.3)
        (att): Sequential(
          (0): Linear(in_features=32, out_features=512, bias=False)
          (1): Tanh()
          (2): Linear(in_features=512, out_features=512, bias=False)
        )
        (att2): Sequential(
          (0): Linear(in_features=50, out_features=512, bias=False)
          (1): Tanh()
          (2): Linear(in_features=512, out_features=512, bias=False)
        )
        (fc_x): Linear(in_features=32, out_features=64, bias=False)
        (fc_neib): Linear(in_features=50, out_features=64, bias=False)
        (dropout): Dropout(p=0.5)
      )
      (4): AttentionAggregator2(
        (attn_dropout): Dropout(p=0.3)
        (att): Sequential(
          (0): Linear(in_features=32, out_features=512, bias=False)
          (1): Tanh()
          (2): Linear(in_features=512, out_features=512, bias=False)
        )
        (att2): Sequential(
          (0): Linear(in_features=50, out_features=512, bias=False)
          (1): Tanh()
          (2): Linear(in_features=512, out_features=512, bias=False)
        )
        (fc_x): Linear(in_features=32, out_features=64, bias=False)
        (fc_neib): Linear(in_features=50, out_features=64, bias=False)
        (dropout): Dropout(p=0.5)
      )
      (5): AttentionAggregator2(
        (attn_dropout): Dropout(p=0.3)
        (att): Sequential(
          (0): Linear(in_features=32, out_features=512, bias=False)
          (1): Tanh()
          (2): Linear(in_features=512, out_features=512, bias=False)
        )
        (att2): Sequential(
          (0): Linear(in_features=50, out_features=512, bias=False)
          (1): Tanh()
          (2): Linear(in_features=512, out_features=512, bias=False)
        )
        (fc_x): Linear(in_features=32, out_features=64, bias=False)
        (fc_neib): Linear(in_features=50, out_features=64, bias=False)
        (dropout): Dropout(p=0.5)
      )
      (6): AttentionAggregator2(
        (attn_dropout): Dropout(p=0.3)
        (att): Sequential(
          (0): Linear(in_features=32, out_features=512, bias=False)
          (1): Tanh()
          (2): Linear(in_features=512, out_features=512, bias=False)
        )
        (att2): Sequential(
          (0): Linear(in_features=50, out_features=512, bias=False)
          (1): Tanh()
          (2): Linear(in_features=512, out_features=512, bias=False)
        )
        (fc_x): Linear(in_features=32, out_features=64, bias=False)
        (fc_neib): Linear(in_features=50, out_features=64, bias=False)
        (dropout): Dropout(p=0.5)
      )
      (7): AttentionAggregator2(
        (attn_dropout): Dropout(p=0.3)
        (att): Sequential(
          (0): Linear(in_features=32, out_features=512, bias=False)
          (1): Tanh()
          (2): Linear(in_features=512, out_features=512, bias=False)
        )
        (att2): Sequential(
          (0): Linear(in_features=50, out_features=512, bias=False)
          (1): Tanh()
          (2): Linear(in_features=512, out_features=512, bias=False)
        )
        (fc_x): Linear(in_features=32, out_features=64, bias=False)
        (fc_neib): Linear(in_features=50, out_features=64, bias=False)
        (dropout): Dropout(p=0.5)
      )
    )
    (edge_2_0): IdEdgeAggregator(
      (dropout): Dropout(p=0.5)
    )
    (mp_agg): MetapathGateLayer (512 -> 512)
    (fc): Sequential(
      (0): Linear(in_features=512, out_features=32, bias=True)
      (1): ReLU()
      (2): Dropout(p=0.5)
      (3): Linear(in_features=32, out_features=3, bias=True)
    )
  )
)
{"epoch":0,"time":26.18312,"train_loss":187.15075}
{"epoch":0,"val_loss":181.76311,"val_metric":{"accuracy":0.44667,"micro":0.44667,"macro":0.20584},"test_metric":{"accuracy":0.44778,"micro":0.44778,"macro":0.20619},"tolerance:":0}
{"epoch":1,"time":66.56322,"train_loss":183.8056}
{"epoch":1,"val_loss":179.23464,"val_metric":{"accuracy":0.44667,"micro":0.44667,"macro":0.20584},"test_metric":{"accuracy":0.44778,"micro":0.44778,"macro":0.20619},"tolerance:":0}
{"epoch":2,"time":107.03728,"train_loss":181.13402}
{"epoch":2,"val_loss":176.10205,"val_metric":{"accuracy":0.6514,"micro":0.6514,"macro":0.4783},"test_metric":{"accuracy":0.6824,"micro":0.6824,"macro":0.49918},"tolerance:":0}
{"epoch":3,"time":147.29639,"train_loss":175.38488}
{"epoch":3,"val_loss":169.32301,"val_metric":{"accuracy":0.65068,"micro":0.65068,"macro":0.47778},"test_metric":{"accuracy":0.68526,"micro":0.68526,"macro":0.50109},"tolerance:":0}
{"epoch":4,"time":187.65594,"train_loss":169.46046}
{"epoch":4,"val_loss":160.22098,"val_metric":{"accuracy":0.61775,"micro":0.61775,"macro":0.45331},"test_metric":{"accuracy":0.65236,"micro":0.65236,"macro":0.47662},"tolerance:":1}
{"epoch":5,"time":227.90357,"train_loss":160.62603}
{"epoch":5,"val_loss":151.43936,"val_metric":{"accuracy":0.64925,"micro":0.64925,"macro":0.47676},"test_metric":{"accuracy":0.68383,"micro":0.68383,"macro":0.49993},"tolerance:":2}
{"epoch":6,"time":268.35206,"train_loss":154.43867}
{"epoch":6,"val_loss":149.10696,"val_metric":{"accuracy":0.65283,"micro":0.65283,"macro":0.4796},"test_metric":{"accuracy":0.68526,"micro":0.68526,"macro":0.50105},"tolerance:":0}
{"epoch":7,"time":308.74708,"train_loss":153.80587}
{"epoch":7,"val_loss":149.71508,"val_metric":{"accuracy":0.64782,"micro":0.64782,"macro":0.47582},"test_metric":{"accuracy":0.6867,"micro":0.6867,"macro":0.50214},"tolerance:":0}
{"epoch":8,"time":349.37073,"train_loss":152.4762}
{"epoch":8,"val_loss":147.98223,"val_metric":{"accuracy":0.65426,"micro":0.65426,"macro":0.48077},"test_metric":{"accuracy":0.68526,"micro":0.68526,"macro":0.50121},"tolerance:":1}
{"epoch":9,"time":389.71121,"train_loss":151.22704}
{"epoch":9,"val_loss":148.35214,"val_metric":{"accuracy":0.65283,"micro":0.65283,"macro":0.47962},"test_metric":{"accuracy":0.6867,"micro":0.6867,"macro":0.50223},"tolerance:":0}
{"epoch":10,"time":430.06599,"train_loss":149.93635}
{"epoch":10,"val_loss":147.8692,"val_metric":{"accuracy":0.65354,"micro":0.65354,"macro":0.48023},"test_metric":{"accuracy":0.68526,"micro":0.68526,"macro":0.50114},"tolerance:":1}
{"epoch":11,"time":470.53394,"train_loss":148.94578}
{"epoch":11,"val_loss":147.08734,"val_metric":{"accuracy":0.65426,"micro":0.65426,"macro":0.48073},"test_metric":{"accuracy":0.68526,"micro":0.68526,"macro":0.50105},"tolerance:":2}
{"epoch":12,"time":510.64152,"train_loss":147.48872}
{"epoch":12,"val_loss":149.62739,"val_metric":{"accuracy":0.65426,"micro":0.65426,"macro":0.48064},"test_metric":{"accuracy":0.68383,"micro":0.68383,"macro":0.50004},"tolerance:":3}
{"epoch":13,"time":551.20821,"train_loss":149.51945}
{"epoch":13,"val_loss":146.87017,"val_metric":{"accuracy":0.65712,"micro":0.65712,"macro":0.48296},"test_metric":{"accuracy":0.6867,"micro":0.6867,"macro":0.50214},"tolerance:":0}
{"epoch":14,"time":591.34394,"train_loss":145.50588}
{"epoch":14,"val_loss":146.10697,"val_metric":{"accuracy":0.65784,"micro":0.65784,"macro":0.48358},"test_metric":{"accuracy":0.68383,"micro":0.68383,"macro":0.49995},"tolerance:":1}
{"epoch":15,"time":631.59545,"train_loss":144.28802}
{"epoch":15,"val_loss":146.41015,"val_metric":{"accuracy":0.65426,"micro":0.65426,"macro":0.4808},"test_metric":{"accuracy":0.6867,"micro":0.6867,"macro":0.50223},"tolerance:":0}
{"epoch":16,"time":671.97585,"train_loss":146.01014}
{"epoch":16,"val_loss":145.48328,"val_metric":{"accuracy":0.65784,"micro":0.65784,"macro":0.48354},"test_metric":{"accuracy":0.68526,"micro":0.68526,"macro":0.50105},"tolerance:":1}
{"epoch":17,"time":712.63312,"train_loss":144.1072}
{"epoch":17,"val_loss":145.45797,"val_metric":{"accuracy":0.65497,"micro":0.65497,"macro":0.48134},"test_metric":{"accuracy":0.6867,"micro":0.6867,"macro":0.50219},"tolerance:":0}
{"epoch":18,"time":752.98706,"train_loss":141.39632}
{"epoch":18,"val_loss":145.38185,"val_metric":{"accuracy":0.65569,"micro":0.65569,"macro":0.4819},"test_metric":{"accuracy":0.68526,"micro":0.68526,"macro":0.50109},"tolerance:":1}
{"epoch":19,"time":793.31862,"train_loss":141.20378}
{"epoch":19,"val_loss":145.48968,"val_metric":{"accuracy":0.65641,"micro":0.65641,"macro":0.4825},"test_metric":{"accuracy":0.6867,"micro":0.6867,"macro":0.50219},"tolerance:":2}
{"epoch":20,"time":834.05959,"train_loss":141.92707}
{"epoch":20,"val_loss":144.37356,"val_metric":{"accuracy":0.65927,"micro":0.65927,"macro":0.48458},"test_metric":{"accuracy":0.68526,"micro":0.68526,"macro":0.50105},"tolerance:":3}
{"epoch":21,"time":874.42914,"train_loss":139.30847}
{"epoch":21,"val_loss":144.31272,"val_metric":{"accuracy":0.65784,"micro":0.65784,"macro":0.48354},"test_metric":{"accuracy":0.68526,"micro":0.68526,"macro":0.50105},"tolerance:":4}
{"epoch":22,"time":915.00255,"train_loss":139.25621}
{"epoch":22,"val_loss":143.73622,"val_metric":{"accuracy":0.65999,"micro":0.65999,"macro":0.4851},"test_metric":{"accuracy":0.67811,"micro":0.67811,"macro":0.49563},"tolerance:":5}
{"epoch":23,"time":955.02971,"train_loss":138.8842}
{"epoch":23,"val_loss":143.02848,"val_metric":{"accuracy":0.66213,"micro":0.66213,"macro":0.4913},"test_metric":{"accuracy":0.67954,"micro":0.67954,"macro":0.50143},"tolerance:":6}
{"epoch":24,"time":995.14514,"train_loss":137.05556}
{"epoch":24,"val_loss":142.27937,"val_metric":{"accuracy":0.66714,"micro":0.66714,"macro":0.50843},"test_metric":{"accuracy":0.68526,"micro":0.68526,"macro":0.51542},"tolerance:":7}
{"epoch":25,"time":1035.63639,"train_loss":137.92895}
{"epoch":25,"val_loss":142.65377,"val_metric":{"accuracy":0.66428,"micro":0.66428,"macro":0.5042},"test_metric":{"accuracy":0.68813,"micro":0.68813,"macro":0.51759},"tolerance:":0}
{"epoch":26,"time":1075.85844,"train_loss":135.45088}
{"epoch":26,"val_loss":142.38151,"val_metric":{"accuracy":0.67215,"micro":0.67215,"macro":0.54275},"test_metric":{"accuracy":0.70529,"micro":0.70529,"macro":0.58047},"tolerance:":0}
{"epoch":27,"time":1115.82807,"train_loss":131.886}
{"epoch":27,"val_loss":141.7616,"val_metric":{"accuracy":0.67359,"micro":0.67359,"macro":0.53218},"test_metric":{"accuracy":0.69814,"micro":0.69814,"macro":0.56348},"tolerance:":1}
{"epoch":28,"time":1156.2491,"train_loss":133.14864}
{"epoch":28,"val_loss":142.54485,"val_metric":{"accuracy":0.68074,"micro":0.68074,"macro":0.57504},"test_metric":{"accuracy":0.69385,"micro":0.69385,"macro":0.59805},"tolerance:":2}
{"epoch":29,"time":1196.62046,"train_loss":132.58807}
{"epoch":29,"val_loss":140.43107,"val_metric":{"accuracy":0.69291,"micro":0.69291,"macro":0.60713},"test_metric":{"accuracy":0.71245,"micro":0.71245,"macro":0.63226},"tolerance:":0}
{"epoch":30,"time":1237.06841,"train_loss":131.78054}
{"epoch":30,"val_loss":140.26683,"val_metric":{"accuracy":0.69005,"micro":0.69005,"macro":0.59723},"test_metric":{"accuracy":0.71102,"micro":0.71102,"macro":0.6289},"tolerance:":1}
{"epoch":31,"time":1277.63257,"train_loss":129.08665}
{"epoch":31,"val_loss":141.20671,"val_metric":{"accuracy":0.6786,"micro":0.6786,"macro":0.56905},"test_metric":{"accuracy":0.701,"micro":0.701,"macro":0.60372},"tolerance:":2}
{"epoch":32,"time":1318.30418,"train_loss":128.86921}
{"epoch":32,"val_loss":140.97895,"val_metric":{"accuracy":0.69148,"micro":0.69148,"macro":0.60238},"test_metric":{"accuracy":0.71102,"micro":0.71102,"macro":0.63099},"tolerance:":3}
{"epoch":33,"time":1358.59104,"train_loss":125.13957}
{"epoch":33,"val_loss":141.48678,"val_metric":{"accuracy":0.69435,"micro":0.69435,"macro":0.62292},"test_metric":{"accuracy":0.71531,"micro":0.71531,"macro":0.65322},"tolerance:":0}
{"epoch":34,"time":1398.93846,"train_loss":124.22406}
{"epoch":34,"val_loss":140.5966,"val_metric":{"accuracy":0.69077,"micro":0.69077,"macro":0.62419},"test_metric":{"accuracy":0.71388,"micro":0.71388,"macro":0.65822},"tolerance:":1}
{"epoch":35,"time":1439.37036,"train_loss":124.88796}
{"epoch":35,"val_loss":141.82868,"val_metric":{"accuracy":0.69148,"micro":0.69148,"macro":0.61379},"test_metric":{"accuracy":0.71102,"micro":0.71102,"macro":0.64833},"tolerance:":2}
{"epoch":36,"time":1479.6132,"train_loss":121.42616}
{"epoch":36,"val_loss":140.66734,"val_metric":{"accuracy":0.6879,"micro":0.6879,"macro":0.63172},"test_metric":{"accuracy":0.70959,"micro":0.70959,"macro":0.65791},"tolerance:":3}
{"epoch":37,"time":1520.14857,"train_loss":116.73951}
{"epoch":37,"val_loss":141.0745,"val_metric":{"accuracy":0.67645,"micro":0.67645,"macro":0.62402},"test_metric":{"accuracy":0.71102,"micro":0.71102,"macro":0.66836},"tolerance:":4}
{"epoch":38,"time":1560.23956,"train_loss":121.24509}
{"epoch":38,"val_loss":141.92543,"val_metric":{"accuracy":0.68074,"micro":0.68074,"macro":0.62758},"test_metric":{"accuracy":0.71388,"micro":0.71388,"macro":0.66857},"tolerance:":5}
{"epoch":39,"time":1600.52647,"train_loss":120.60202}
{"epoch":39,"val_loss":140.83054,"val_metric":{"accuracy":0.68432,"micro":0.68432,"macro":0.62937},"test_metric":{"accuracy":0.70959,"micro":0.70959,"macro":0.66161},"tolerance:":6}
{"epoch":40,"time":1640.76875,"train_loss":119.41162}
{"epoch":40,"val_loss":142.60724,"val_metric":{"accuracy":0.68576,"micro":0.68576,"macro":0.62992},"test_metric":{"accuracy":0.71102,"micro":0.71102,"macro":0.66379},"tolerance:":7}
{"epoch":41,"time":1680.81668,"train_loss":119.2251}
{"epoch":41,"val_loss":140.59311,"val_metric":{"accuracy":0.68146,"micro":0.68146,"macro":0.62794},"test_metric":{"accuracy":0.71245,"micro":0.71245,"macro":0.67001},"tolerance:":8}
{"epoch":42,"time":1721.05124,"train_loss":113.82232}
{"epoch":42,"val_loss":141.86225,"val_metric":{"accuracy":0.68361,"micro":0.68361,"macro":0.62915},"test_metric":{"accuracy":0.70959,"micro":0.70959,"macro":0.66397},"tolerance:":9}
{"epoch":43,"time":1761.38164,"train_loss":116.91096}
{"epoch":43,"val_loss":145.21996,"val_metric":{"accuracy":0.68719,"micro":0.68719,"macro":0.63007},"test_metric":{"accuracy":0.71388,"micro":0.71388,"macro":0.66478},"tolerance:":10}
{"epoch":44,"time":1801.6427,"train_loss":109.01905}
{"epoch":44,"val_loss":143.59082,"val_metric":{"accuracy":0.6786,"micro":0.6786,"macro":0.63285},"test_metric":{"accuracy":0.70815,"micro":0.70815,"macro":0.67415},"tolerance:":11}
{"epoch":45,"time":1841.88309,"train_loss":113.53607}
{"epoch":45,"val_loss":143.95956,"val_metric":{"accuracy":0.68003,"micro":0.68003,"macro":0.63},"test_metric":{"accuracy":0.70386,"micro":0.70386,"macro":0.66575},"tolerance:":12}
{"epoch":46,"time":1882.13095,"train_loss":109.65841}
{"epoch":46,"val_loss":144.89699,"val_metric":{"accuracy":0.67788,"micro":0.67788,"macro":0.63095},"test_metric":{"accuracy":0.70672,"micro":0.70672,"macro":0.66999},"tolerance:":13}
{"epoch":47,"time":1922.7044,"train_loss":109.19646}
{"epoch":47,"val_loss":145.12519,"val_metric":{"accuracy":0.68074,"micro":0.68074,"macro":0.62765},"test_metric":{"accuracy":0.71245,"micro":0.71245,"macro":0.67301},"tolerance:":14}
{"epoch":48,"time":1963.5105,"train_loss":108.19343}
{"epoch":48,"val_loss":147.22391,"val_metric":{"accuracy":0.68719,"micro":0.68719,"macro":0.6311},"test_metric":{"accuracy":0.71102,"micro":0.71102,"macro":0.66736},"tolerance:":15}
{"epoch":49,"time":2004.37932,"train_loss":104.35277}
{"epoch":49,"val_loss":145.41385,"val_metric":{"accuracy":0.67931,"micro":0.67931,"macro":0.63077},"test_metric":{"accuracy":0.71102,"micro":0.71102,"macro":0.67246},"tolerance:":16}
{"epoch":50,"time":2044.82915,"train_loss":102.34327}
{"epoch":50,"val_loss":149.21946,"val_metric":{"accuracy":0.68146,"micro":0.68146,"macro":0.62926},"test_metric":{"accuracy":0.71245,"micro":0.71245,"macro":0.66803},"tolerance:":17}
{"epoch":51,"time":2085.64549,"train_loss":104.37119}
{"epoch":51,"val_loss":149.57509,"val_metric":{"accuracy":0.69077,"micro":0.69077,"macro":0.63484},"test_metric":{"accuracy":0.71102,"micro":0.71102,"macro":0.66554},"tolerance:":18}
{"epoch":52,"time":2126.36534,"train_loss":103.46289}
{"epoch":52,"val_loss":149.05966,"val_metric":{"accuracy":0.68289,"micro":0.68289,"macro":0.63771},"test_metric":{"accuracy":0.70386,"micro":0.70386,"macro":0.66357},"tolerance:":19}
{"epoch":53,"time":2166.78137,"train_loss":103.46513}
{"epoch":53,"val_loss":149.15635,"val_metric":{"accuracy":0.68432,"micro":0.68432,"macro":0.62918},"test_metric":{"accuracy":0.71102,"micro":0.71102,"macro":0.66815},"tolerance:":20}
{"epoch":54,"time":2206.99891,"train_loss":99.67163}
{"epoch":54,"val_loss":149.71809,"val_metric":{"accuracy":0.69005,"micro":0.69005,"macro":0.63457},"test_metric":{"accuracy":0.71531,"micro":0.71531,"macro":0.67208},"tolerance:":21}
{"epoch":55,"time":2247.71998,"train_loss":101.62387}
{"epoch":55,"val_loss":148.80356,"val_metric":{"accuracy":0.68003,"micro":0.68003,"macro":0.62693},"test_metric":{"accuracy":0.72246,"micro":0.72246,"macro":0.68483},"tolerance:":0}
{"epoch":56,"time":2286.71398,"train_loss":96.5563}
{"epoch":56,"val_loss":152.17713,"val_metric":{"accuracy":0.69077,"micro":0.69077,"macro":0.63677},"test_metric":{"accuracy":0.71245,"micro":0.71245,"macro":0.66421},"tolerance:":1}
{"epoch":57,"time":2326.81064,"train_loss":97.27352}
{"epoch":57,"val_loss":152.68912,"val_metric":{"accuracy":0.68003,"micro":0.68003,"macro":0.63742},"test_metric":{"accuracy":0.70959,"micro":0.70959,"macro":0.67631},"tolerance:":2}
{"epoch":58,"time":2367.52559,"train_loss":90.53003}
{"epoch":58,"val_loss":157.55635,"val_metric":{"accuracy":0.67931,"micro":0.67931,"macro":0.6355},"test_metric":{"accuracy":0.70529,"micro":0.70529,"macro":0.67194},"tolerance:":3}
{"epoch":59,"time":2407.72614,"train_loss":91.79672}
{"epoch":59,"val_loss":157.16814,"val_metric":{"accuracy":0.68218,"micro":0.68218,"macro":0.6331},"test_metric":{"accuracy":0.70815,"micro":0.70815,"macro":0.66786},"tolerance:":4}
{"epoch":60,"time":2447.90418,"train_loss":94.40627}
{"epoch":60,"val_loss":155.07723,"val_metric":{"accuracy":0.68647,"micro":0.68647,"macro":0.63455},"test_metric":{"accuracy":0.71102,"micro":0.71102,"macro":0.67122},"tolerance:":5}
{"epoch":61,"time":2488.34225,"train_loss":90.07775}
{"epoch":61,"val_loss":156.40576,"val_metric":{"accuracy":0.6786,"micro":0.6786,"macro":0.6392},"test_metric":{"accuracy":0.69814,"micro":0.69814,"macro":0.66705},"tolerance:":6}
{"epoch":62,"time":2529.05792,"train_loss":85.29902}
{"epoch":62,"val_loss":156.09252,"val_metric":{"accuracy":0.67573,"micro":0.67573,"macro":0.6365},"test_metric":{"accuracy":0.70529,"micro":0.70529,"macro":0.67575},"tolerance:":7}
{"epoch":63,"time":2569.82332,"train_loss":90.78408}
{"epoch":63,"val_loss":157.98236,"val_metric":{"accuracy":0.6786,"micro":0.6786,"macro":0.62938},"test_metric":{"accuracy":0.70815,"micro":0.70815,"macro":0.66918},"tolerance:":8}
{"epoch":64,"time":2610.06175,"train_loss":88.71542}
{"epoch":64,"val_loss":160.62094,"val_metric":{"accuracy":0.68003,"micro":0.68003,"macro":0.63361},"test_metric":{"accuracy":0.71388,"micro":0.71388,"macro":0.67885},"tolerance:":9}
{"epoch":65,"time":2650.44862,"train_loss":88.75174}
{"epoch":65,"val_loss":158.62354,"val_metric":{"accuracy":0.68146,"micro":0.68146,"macro":0.63294},"test_metric":{"accuracy":0.71245,"micro":0.71245,"macro":0.67276},"tolerance:":10}
{"epoch":66,"time":2690.91609,"train_loss":87.67123}
{"epoch":66,"val_loss":157.50638,"val_metric":{"accuracy":0.68504,"micro":0.68504,"macro":0.63859},"test_metric":{"accuracy":0.71388,"micro":0.71388,"macro":0.67383},"tolerance:":11}
{"epoch":67,"time":2731.02953,"train_loss":83.51377}
{"epoch":67,"val_loss":159.47871,"val_metric":{"accuracy":0.67645,"micro":0.67645,"macro":0.63336},"test_metric":{"accuracy":0.71245,"micro":0.71245,"macro":0.67953},"tolerance:":12}
{"epoch":68,"time":2771.84252,"train_loss":79.19001}
{"epoch":68,"val_loss":168.86786,"val_metric":{"accuracy":0.68074,"micro":0.68074,"macro":0.63002},"test_metric":{"accuracy":0.70815,"micro":0.70815,"macro":0.67063},"tolerance:":13}
{"epoch":69,"time":2812.27207,"train_loss":80.18662}
{"epoch":69,"val_loss":161.61949,"val_metric":{"accuracy":0.67215,"micro":0.67215,"macro":0.63613},"test_metric":{"accuracy":0.69242,"micro":0.69242,"macro":0.66274},"tolerance:":14}
{"epoch":70,"time":2853.04721,"train_loss":81.34594}
{"epoch":70,"val_loss":166.45021,"val_metric":{"accuracy":0.68361,"micro":0.68361,"macro":0.63627},"test_metric":{"accuracy":0.70959,"micro":0.70959,"macro":0.67147},"tolerance:":15}
{"epoch":71,"time":2893.45186,"train_loss":76.07978}
{"epoch":71,"val_loss":164.13128,"val_metric":{"accuracy":0.68289,"micro":0.68289,"macro":0.64359},"test_metric":{"accuracy":0.71531,"micro":0.71531,"macro":0.68613},"tolerance:":16}
{"epoch":72,"time":2934.1201,"train_loss":76.37865}
{"epoch":72,"val_loss":166.25157,"val_metric":{"accuracy":0.68289,"micro":0.68289,"macro":0.63978},"test_metric":{"accuracy":0.70672,"micro":0.70672,"macro":0.67545},"tolerance:":17}
{"epoch":73,"time":2974.50609,"train_loss":75.0351}
{"epoch":73,"val_loss":169.43164,"val_metric":{"accuracy":0.68289,"micro":0.68289,"macro":0.64689},"test_metric":{"accuracy":0.70672,"micro":0.70672,"macro":0.6766},"tolerance:":18}
{"epoch":74,"time":3014.9759,"train_loss":75.77643}
{"epoch":74,"val_loss":170.47039,"val_metric":{"accuracy":0.68862,"micro":0.68862,"macro":0.64394},"test_metric":{"accuracy":0.7196,"micro":0.7196,"macro":0.68651},"tolerance:":19}
{"epoch":75,"time":3055.38691,"train_loss":75.07507}
{"epoch":75,"val_loss":167.24559,"val_metric":{"accuracy":0.68504,"micro":0.68504,"macro":0.64046},"test_metric":{"accuracy":0.71531,"micro":0.71531,"macro":0.68182},"tolerance:":20}
{"epoch":76,"time":3095.71066,"train_loss":76.00836}
{"epoch":76,"val_loss":165.83404,"val_metric":{"accuracy":0.68862,"micro":0.68862,"macro":0.65038},"test_metric":{"accuracy":0.70959,"micro":0.70959,"macro":0.67943},"tolerance:":21}
{"epoch":77,"time":3136.46218,"train_loss":73.39166}
{"epoch":77,"val_loss":171.47735,"val_metric":{"accuracy":0.68218,"micro":0.68218,"macro":0.6393},"test_metric":{"accuracy":0.71388,"micro":0.71388,"macro":0.6856},"tolerance:":22}
{"epoch":78,"time":3177.0081,"train_loss":67.05392}
{"epoch":78,"val_loss":170.2174,"val_metric":{"accuracy":0.6786,"micro":0.6786,"macro":0.64144},"test_metric":{"accuracy":0.70386,"micro":0.70386,"macro":0.67297},"tolerance:":23}
{"epoch":79,"time":3217.58313,"train_loss":71.73525}
{"epoch":79,"val_loss":170.83346,"val_metric":{"accuracy":0.69077,"micro":0.69077,"macro":0.65026},"test_metric":{"accuracy":0.71388,"micro":0.71388,"macro":0.68054},"tolerance:":24}
{"epoch":80,"time":3258.02107,"train_loss":67.51845}
{"epoch":80,"val_loss":176.30121,"val_metric":{"accuracy":0.67645,"micro":0.67645,"macro":0.63964},"test_metric":{"accuracy":0.701,"micro":0.701,"macro":0.67186},"tolerance:":25}
{"epoch":81,"time":3298.30068,"train_loss":68.55224}
{"epoch":81,"val_loss":174.55886,"val_metric":{"accuracy":0.6743,"micro":0.6743,"macro":0.63934},"test_metric":{"accuracy":0.69242,"micro":0.69242,"macro":0.66286},"tolerance:":26}
{"epoch":82,"time":3338.72257,"train_loss":67.82366}
{"epoch":82,"val_loss":172.4431,"val_metric":{"accuracy":0.68576,"micro":0.68576,"macro":0.64896},"test_metric":{"accuracy":0.70672,"micro":0.70672,"macro":0.67873},"tolerance:":27}
{"epoch":83,"time":3379.58924,"train_loss":66.35382}
{"epoch":83,"val_loss":177.37274,"val_metric":{"accuracy":0.67215,"micro":0.67215,"macro":0.63772},"test_metric":{"accuracy":0.69528,"micro":0.69528,"macro":0.66457},"tolerance:":28}
{"epoch":84,"time":3420.08092,"train_loss":59.99609}
{"epoch":84,"val_loss":184.41672,"val_metric":{"accuracy":0.69005,"micro":0.69005,"macro":0.64547},"test_metric":{"accuracy":0.72103,"micro":0.72103,"macro":0.68587},"tolerance:":29}
{"epoch":85,"time":3460.485,"train_loss":62.82659}
{"epoch":85,"val_loss":183.9541,"val_metric":{"accuracy":0.69291,"micro":0.69291,"macro":0.64862},"test_metric":{"accuracy":0.71531,"micro":0.71531,"macro":0.67713},"tolerance:":30}
{"epoch":86,"time":3500.81616,"train_loss":58.47626}
{"epoch":86,"val_loss":183.66563,"val_metric":{"accuracy":0.69363,"micro":0.69363,"macro":0.6506},"test_metric":{"accuracy":0.71245,"micro":0.71245,"macro":0.67921},"tolerance:":31}
{"epoch":87,"time":3541.25953,"train_loss":60.89606}
{"epoch":87,"val_loss":182.50561,"val_metric":{"accuracy":0.68218,"micro":0.68218,"macro":0.64343},"test_metric":{"accuracy":0.69814,"micro":0.69814,"macro":0.66865},"tolerance:":32}
{"epoch":88,"time":3581.83032,"train_loss":58.89274}
{"epoch":88,"val_loss":185.50327,"val_metric":{"accuracy":0.67788,"micro":0.67788,"macro":0.63947},"test_metric":{"accuracy":0.69957,"micro":0.69957,"macro":0.67131},"tolerance:":33}
{"epoch":89,"time":3621.74058,"train_loss":57.88155}
{"epoch":89,"val_loss":184.49257,"val_metric":{"accuracy":0.68074,"micro":0.68074,"macro":0.6424},"test_metric":{"accuracy":0.701,"micro":0.701,"macro":0.67176},"tolerance:":34}
{"epoch":90,"time":3662.20331,"train_loss":56.14748}
{"epoch":90,"val_loss":182.98454,"val_metric":{"accuracy":0.67359,"micro":0.67359,"macro":0.63732},"test_metric":{"accuracy":0.69671,"micro":0.69671,"macro":0.66847},"tolerance:":35}
{"epoch":91,"time":3702.82612,"train_loss":57.03418}
{"epoch":91,"val_loss":186.95944,"val_metric":{"accuracy":0.67502,"micro":0.67502,"macro":0.63837},"test_metric":{"accuracy":0.701,"micro":0.701,"macro":0.67306},"tolerance:":36}
{"epoch":92,"time":3743.7425,"train_loss":55.18075}
{"epoch":92,"val_loss":188.94303,"val_metric":{"accuracy":0.68862,"micro":0.68862,"macro":0.64822},"test_metric":{"accuracy":0.71388,"micro":0.71388,"macro":0.68282},"tolerance:":37}
{"epoch":93,"time":3784.65238,"train_loss":53.85481}
{"epoch":93,"val_loss":191.43608,"val_metric":{"accuracy":0.68862,"micro":0.68862,"macro":0.6499},"test_metric":{"accuracy":0.71388,"micro":0.71388,"macro":0.6824},"tolerance:":38}
{"epoch":94,"time":3825.38488,"train_loss":53.40029}
{"epoch":94,"val_loss":190.89336,"val_metric":{"accuracy":0.6786,"micro":0.6786,"macro":0.64268},"test_metric":{"accuracy":0.701,"micro":0.701,"macro":0.67391},"tolerance:":39}
{"epoch":95,"time":3866.42526,"train_loss":52.76747}
{"epoch":95,"val_loss":195.26869,"val_metric":{"accuracy":0.68289,"micro":0.68289,"macro":0.64624},"test_metric":{"accuracy":0.70815,"micro":0.70815,"macro":0.6808},"tolerance:":40}
{"epoch":96,"time":3907.13296,"train_loss":53.53967}
{"epoch":96,"val_loss":190.62617,"val_metric":{"accuracy":0.68576,"micro":0.68576,"macro":0.6477},"test_metric":{"accuracy":0.70386,"micro":0.70386,"macro":0.67171},"tolerance:":41}
{"epoch":97,"time":3947.96457,"train_loss":52.1589}
{"epoch":97,"val_loss":191.90591,"val_metric":{"accuracy":0.67573,"micro":0.67573,"macro":0.64021},"test_metric":{"accuracy":0.69528,"micro":0.69528,"macro":0.6661},"tolerance:":42}
{"epoch":98,"time":3988.4947,"train_loss":49.17825}
{"epoch":98,"val_loss":197.06216,"val_metric":{"accuracy":0.68361,"micro":0.68361,"macro":0.64566},"test_metric":{"accuracy":0.701,"micro":0.701,"macro":0.67045},"tolerance:":43}
{"epoch":99,"time":4029.19355,"train_loss":47.92612}
{"epoch":99,"val_loss":202.70359,"val_metric":{"accuracy":0.68003,"micro":0.68003,"macro":0.64323},"test_metric":{"accuracy":0.701,"micro":0.701,"macro":0.67365},"tolerance:":44}
{"epoch":100,"time":4070.49353,"train_loss":46.52552}
{"epoch":100,"val_loss":199.42415,"val_metric":{"accuracy":0.68933,"micro":0.68933,"macro":0.65112},"test_metric":{"accuracy":0.71102,"micro":0.71102,"macro":0.68294},"tolerance:":45}
{"epoch":101,"time":4111.14341,"train_loss":46.17965}
{"epoch":101,"val_loss":202.75978,"val_metric":{"accuracy":0.68719,"micro":0.68719,"macro":0.64945},"test_metric":{"accuracy":0.70672,"micro":0.70672,"macro":0.67774},"tolerance:":46}
{"epoch":102,"time":4152.0692,"train_loss":46.09034}
{"epoch":102,"val_loss":204.50111,"val_metric":{"accuracy":0.6786,"micro":0.6786,"macro":0.64284},"test_metric":{"accuracy":0.69242,"micro":0.69242,"macro":0.66507},"tolerance:":47}
{"epoch":103,"time":4192.55515,"train_loss":49.48488}
{"epoch":103,"val_loss":202.83147,"val_metric":{"accuracy":0.68719,"micro":0.68719,"macro":0.64949},"test_metric":{"accuracy":0.70529,"micro":0.70529,"macro":0.6761},"tolerance:":48}
{"epoch":104,"time":4231.64314,"train_loss":42.36595}
{"epoch":104,"val_loss":206.79118,"val_metric":{"accuracy":0.69148,"micro":0.69148,"macro":0.65417},"test_metric":{"accuracy":0.70672,"micro":0.70672,"macro":0.67842},"tolerance:":49}
{"epoch":105,"time":4273.19905,"train_loss":40.91167}
{"epoch":105,"val_loss":215.16908,"val_metric":{"accuracy":0.6922,"micro":0.6922,"macro":0.65246},"test_metric":{"accuracy":0.70959,"micro":0.70959,"macro":0.67596},"tolerance:":50}
{"epoch":106,"time":4314.81335,"train_loss":45.58316}
{"epoch":106,"val_loss":210.01518,"val_metric":{"accuracy":0.69077,"micro":0.69077,"macro":0.65158},"test_metric":{"accuracy":0.70243,"micro":0.70243,"macro":0.67259},"tolerance:":51}
{"epoch":107,"time":4356.40299,"train_loss":42.65211}
{"epoch":107,"val_loss":209.00229,"val_metric":{"accuracy":0.69005,"micro":0.69005,"macro":0.65058},"test_metric":{"accuracy":0.70243,"micro":0.70243,"macro":0.67158},"tolerance:":52}
{"epoch":108,"time":4397.98845,"train_loss":44.73282}
{"epoch":108,"val_loss":209.9405,"val_metric":{"accuracy":0.66786,"micro":0.66786,"macro":0.63409},"test_metric":{"accuracy":0.69957,"micro":0.69957,"macro":0.67014},"tolerance:":53}
{"epoch":109,"time":4439.66064,"train_loss":39.87738}
{"epoch":109,"val_loss":213.51793,"val_metric":{"accuracy":0.6786,"micro":0.6786,"macro":0.64053},"test_metric":{"accuracy":0.69671,"micro":0.69671,"macro":0.66556},"tolerance:":54}
{"epoch":110,"time":4481.2477,"train_loss":37.14564}
{"epoch":110,"val_loss":222.22414,"val_metric":{"accuracy":0.66571,"micro":0.66571,"macro":0.62639},"test_metric":{"accuracy":0.69814,"micro":0.69814,"macro":0.66794},"tolerance:":55}
{"epoch":111,"time":4522.34956,"train_loss":36.22621}
{"epoch":111,"val_loss":219.63078,"val_metric":{"accuracy":0.68504,"micro":0.68504,"macro":0.64582},"test_metric":{"accuracy":0.69385,"micro":0.69385,"macro":0.66544},"tolerance:":56}
{"epoch":112,"time":4563.59549,"train_loss":38.45436}
{"epoch":112,"val_loss":221.67983,"val_metric":{"accuracy":0.68289,"micro":0.68289,"macro":0.64364},"test_metric":{"accuracy":0.70815,"micro":0.70815,"macro":0.67719},"tolerance:":57}
{"epoch":113,"time":4605.48264,"train_loss":39.00892}
{"epoch":113,"val_loss":227.09889,"val_metric":{"accuracy":0.68218,"micro":0.68218,"macro":0.64152},"test_metric":{"accuracy":0.70529,"micro":0.70529,"macro":0.67464},"tolerance:":58}
{"epoch":114,"time":4647.00538,"train_loss":36.54936}
{"epoch":114,"val_loss":234.9664,"val_metric":{"accuracy":0.67001,"micro":0.67001,"macro":0.62821},"test_metric":{"accuracy":0.70529,"micro":0.70529,"macro":0.67402},"tolerance:":59}
{"epoch":115,"time":4688.19819,"train_loss":36.64926}
{"epoch":115,"val_loss":230.87611,"val_metric":{"accuracy":0.68074,"micro":0.68074,"macro":0.63844},"test_metric":{"accuracy":0.70529,"micro":0.70529,"macro":0.67258},"tolerance:":60}
{"epoch":116,"time":4729.9124,"train_loss":36.67328}
{"epoch":116,"val_loss":231.30003,"val_metric":{"accuracy":0.68361,"micro":0.68361,"macro":0.64212},"test_metric":{"accuracy":0.70672,"micro":0.70672,"macro":0.67112},"tolerance:":61}
{"epoch":117,"time":4771.36634,"train_loss":35.67846}
{"epoch":117,"val_loss":228.46498,"val_metric":{"accuracy":0.68504,"micro":0.68504,"macro":0.64324},"test_metric":{"accuracy":0.70815,"micro":0.70815,"macro":0.67684},"tolerance:":62}
{"epoch":118,"time":4812.96878,"train_loss":33.87407}
{"epoch":118,"val_loss":223.60662,"val_metric":{"accuracy":0.67573,"micro":0.67573,"macro":0.64113},"test_metric":{"accuracy":0.69957,"micro":0.69957,"macro":0.66684},"tolerance:":63}
{"epoch":119,"time":4854.24437,"train_loss":36.89821}
{"epoch":119,"val_loss":223.10014,"val_metric":{"accuracy":0.67788,"micro":0.67788,"macro":0.64036},"test_metric":{"accuracy":0.69957,"micro":0.69957,"macro":0.66925},"tolerance:":64}
{"epoch":120,"time":4895.7602,"train_loss":35.22834}
{"epoch":120,"val_loss":222.93814,"val_metric":{"accuracy":0.67502,"micro":0.67502,"macro":0.63771},"test_metric":{"accuracy":0.701,"micro":0.701,"macro":0.67039},"tolerance:":65}
{"epoch":121,"time":4937.48128,"train_loss":30.0882}
{"epoch":121,"val_loss":234.92227,"val_metric":{"accuracy":0.68432,"micro":0.68432,"macro":0.64493},"test_metric":{"accuracy":0.71245,"micro":0.71245,"macro":0.67851},"tolerance:":66}
{"epoch":122,"time":4979.02648,"train_loss":34.0713}
{"epoch":122,"val_loss":233.70249,"val_metric":{"accuracy":0.6786,"micro":0.6786,"macro":0.63921},"test_metric":{"accuracy":0.70386,"micro":0.70386,"macro":0.6683},"tolerance:":67}
{"epoch":123,"time":5020.514,"train_loss":34.26914}
{"epoch":123,"val_loss":230.28059,"val_metric":{"accuracy":0.68862,"micro":0.68862,"macro":0.65053},"test_metric":{"accuracy":0.70672,"micro":0.70672,"macro":0.67188},"tolerance:":68}
{"epoch":124,"time":5062.05484,"train_loss":29.09931}
{"epoch":124,"val_loss":236.63654,"val_metric":{"accuracy":0.68504,"micro":0.68504,"macro":0.6464},"test_metric":{"accuracy":0.70529,"micro":0.70529,"macro":0.67339},"tolerance:":69}
{"epoch":125,"time":5103.91015,"train_loss":28.65649}
{"epoch":125,"val_loss":246.99112,"val_metric":{"accuracy":0.67717,"micro":0.67717,"macro":0.6372},"test_metric":{"accuracy":0.70529,"micro":0.70529,"macro":0.67094},"tolerance:":70}
{"epoch":126,"time":5145.7804,"train_loss":30.48847}
{"epoch":126,"val_loss":251.99089,"val_metric":{"accuracy":0.68003,"micro":0.68003,"macro":0.63729},"test_metric":{"accuracy":0.71245,"micro":0.71245,"macro":0.6799},"tolerance:":71}
{"epoch":127,"time":5187.23956,"train_loss":28.83703}
{"epoch":127,"val_loss":247.61004,"val_metric":{"accuracy":0.69148,"micro":0.69148,"macro":0.6507},"test_metric":{"accuracy":0.71245,"micro":0.71245,"macro":0.68007},"tolerance:":72}
{"epoch":128,"time":5229.20776,"train_loss":26.87078}
{"epoch":128,"val_loss":244.03066,"val_metric":{"accuracy":0.67502,"micro":0.67502,"macro":0.63744},"test_metric":{"accuracy":0.69957,"micro":0.69957,"macro":0.6664},"tolerance:":73}
{"epoch":129,"time":5271.04207,"train_loss":28.47964}
{"epoch":129,"val_loss":253.36243,"val_metric":{"accuracy":0.68361,"micro":0.68361,"macro":0.64098},"test_metric":{"accuracy":0.71531,"micro":0.71531,"macro":0.68103},"tolerance:":74}
{"epoch":130,"time":5313.02388,"train_loss":25.81117}
{"epoch":130,"val_loss":254.99886,"val_metric":{"accuracy":0.68218,"micro":0.68218,"macro":0.64228},"test_metric":{"accuracy":0.70386,"micro":0.70386,"macro":0.67032},"tolerance:":75}
{"epoch":131,"time":5355.24752,"train_loss":26.28345}
{"epoch":131,"val_loss":258.97286,"val_metric":{"accuracy":0.6879,"micro":0.6879,"macro":0.64785},"test_metric":{"accuracy":0.71245,"micro":0.71245,"macro":0.67869},"tolerance:":76}
{"epoch":132,"time":5397.36432,"train_loss":26.55249}
{"epoch":132,"val_loss":258.77374,"val_metric":{"accuracy":0.68361,"micro":0.68361,"macro":0.64181},"test_metric":{"accuracy":0.70672,"micro":0.70672,"macro":0.6707},"tolerance:":77}
{"epoch":133,"time":5439.45955,"train_loss":26.90115}
{"epoch":133,"val_loss":254.94862,"val_metric":{"accuracy":0.6879,"micro":0.6879,"macro":0.64971},"test_metric":{"accuracy":0.70529,"micro":0.70529,"macro":0.67067},"tolerance:":78}
{"epoch":134,"time":5481.34835,"train_loss":28.00239}
{"epoch":134,"val_loss":262.61037,"val_metric":{"accuracy":0.6922,"micro":0.6922,"macro":0.64784},"test_metric":{"accuracy":0.71674,"micro":0.71674,"macro":0.68039},"tolerance:":79}
{"epoch":135,"time":5523.40981,"train_loss":28.3287}
{"epoch":135,"val_loss":260.19073,"val_metric":{"accuracy":0.68504,"micro":0.68504,"macro":0.64231},"test_metric":{"accuracy":0.71245,"micro":0.71245,"macro":0.67935},"tolerance:":80}
{"epoch":136,"time":5565.45454,"train_loss":21.43924}
{"epoch":136,"val_loss":267.77392,"val_metric":{"accuracy":0.68504,"micro":0.68504,"macro":0.64276},"test_metric":{"accuracy":0.71245,"micro":0.71245,"macro":0.67478},"tolerance:":81}
{"epoch":137,"time":5607.427,"train_loss":23.70369}
{"epoch":137,"val_loss":268.7297,"val_metric":{"accuracy":0.67788,"micro":0.67788,"macro":0.63579},"test_metric":{"accuracy":0.70386,"micro":0.70386,"macro":0.66963},"tolerance:":82}
{"epoch":138,"time":5649.47311,"train_loss":24.01147}
{"epoch":138,"val_loss":262.38901,"val_metric":{"accuracy":0.68003,"micro":0.68003,"macro":0.63824},"test_metric":{"accuracy":0.71102,"micro":0.71102,"macro":0.67489},"tolerance:":83}
{"epoch":139,"time":5691.56392,"train_loss":23.1247}
{"epoch":139,"val_loss":263.93422,"val_metric":{"accuracy":0.67788,"micro":0.67788,"macro":0.64184},"test_metric":{"accuracy":0.70386,"micro":0.70386,"macro":0.67239},"tolerance:":84}
{"epoch":140,"time":5733.66048,"train_loss":23.14159}
{"epoch":140,"val_loss":258.13472,"val_metric":{"accuracy":0.67645,"micro":0.67645,"macro":0.6427},"test_metric":{"accuracy":0.70959,"micro":0.70959,"macro":0.67782},"tolerance:":85}
{"epoch":141,"time":5775.78573,"train_loss":22.65814}
{"epoch":141,"val_loss":266.85687,"val_metric":{"accuracy":0.67931,"micro":0.67931,"macro":0.64081},"test_metric":{"accuracy":0.71245,"micro":0.71245,"macro":0.67775},"tolerance:":86}
{"epoch":142,"time":5817.8988,"train_loss":19.73556}
{"epoch":142,"val_loss":282.07281,"val_metric":{"accuracy":0.6922,"micro":0.6922,"macro":0.64758},"test_metric":{"accuracy":0.72103,"micro":0.72103,"macro":0.68416},"tolerance:":87}
{"epoch":143,"time":5860.14121,"train_loss":19.25784}
{"epoch":143,"val_loss":287.71063,"val_metric":{"accuracy":0.68647,"micro":0.68647,"macro":0.64384},"test_metric":{"accuracy":0.71388,"micro":0.71388,"macro":0.67624},"tolerance:":88}
{"epoch":144,"time":5902.41498,"train_loss":22.3501}
{"epoch":144,"val_loss":282.19093,"val_metric":{"accuracy":0.68719,"micro":0.68719,"macro":0.64663},"test_metric":{"accuracy":0.71388,"micro":0.71388,"macro":0.67679},"tolerance:":89}
{"epoch":145,"time":5944.29398,"train_loss":18.85045}
{"epoch":145,"val_loss":272.9691,"val_metric":{"accuracy":0.68218,"micro":0.68218,"macro":0.64283},"test_metric":{"accuracy":0.70672,"micro":0.70672,"macro":0.67187},"tolerance:":90}
{"epoch":146,"time":5986.45289,"train_loss":20.57414}
{"epoch":146,"val_loss":278.34425,"val_metric":{"accuracy":0.68647,"micro":0.68647,"macro":0.64741},"test_metric":{"accuracy":0.71388,"micro":0.71388,"macro":0.68067},"tolerance:":91}
{"epoch":147,"time":6028.71916,"train_loss":22.75246}
{"epoch":147,"val_loss":274.16306,"val_metric":{"accuracy":0.6786,"micro":0.6786,"macro":0.64217},"test_metric":{"accuracy":0.69957,"micro":0.69957,"macro":0.66391},"tolerance:":92}
{"epoch":148,"time":6070.58791,"train_loss":23.16124}
{"epoch":148,"val_loss":280.10849,"val_metric":{"accuracy":0.68647,"micro":0.68647,"macro":0.64498},"test_metric":{"accuracy":0.72103,"micro":0.72103,"macro":0.68586},"tolerance:":93}
{"epoch":149,"time":6112.71267,"train_loss":21.24876}
{"epoch":149,"val_loss":277.51457,"val_metric":{"accuracy":0.68862,"micro":0.68862,"macro":0.64814},"test_metric":{"accuracy":0.71531,"micro":0.71531,"macro":0.67977},"tolerance:":94}
{"epoch":150,"time":6154.90929,"train_loss":21.22392}
{"epoch":150,"val_loss":289.87884,"val_metric":{"accuracy":0.69291,"micro":0.69291,"macro":0.6482},"test_metric":{"accuracy":0.71245,"micro":0.71245,"macro":0.67461},"tolerance:":95}
{"epoch":151,"time":6197.1713,"train_loss":20.57488}
{"epoch":151,"val_loss":275.52973,"val_metric":{"accuracy":0.68074,"micro":0.68074,"macro":0.64302},"test_metric":{"accuracy":0.70815,"micro":0.70815,"macro":0.67318},"tolerance:":96}
{"epoch":152,"time":6239.17126,"train_loss":18.96765}
{"epoch":152,"val_loss":281.12234,"val_metric":{"accuracy":0.68504,"micro":0.68504,"macro":0.64615},"test_metric":{"accuracy":0.70529,"micro":0.70529,"macro":0.66946},"tolerance:":97}
{"epoch":153,"time":6281.23385,"train_loss":19.05688}
{"epoch":153,"val_loss":284.68975,"val_metric":{"accuracy":0.69148,"micro":0.69148,"macro":0.6542},"test_metric":{"accuracy":0.70959,"micro":0.70959,"macro":0.67482},"tolerance:":98}
{"epoch":154,"time":6323.05545,"train_loss":16.12082}
{"epoch":154,"val_loss":294.63258,"val_metric":{"accuracy":0.68432,"micro":0.68432,"macro":0.64864},"test_metric":{"accuracy":0.70529,"micro":0.70529,"macro":0.67174},"tolerance:":99}
{"epoch":155,"time":6365.59385,"train_loss":22.41862}
{"epoch":155,"val_loss":284.34108,"val_metric":{"accuracy":0.68504,"micro":0.68504,"macro":0.6487},"test_metric":{"accuracy":0.71102,"micro":0.71102,"macro":0.67858},"tolerance:":100}
{"epoch":156,"time":6408.09756,"train_loss":20.79776}
{"epoch":156,"val_loss":288.99469,"val_metric":{"accuracy":0.68504,"micro":0.68504,"macro":0.64657},"test_metric":{"accuracy":0.71102,"micro":0.71102,"macro":0.67365},"tolerance:":101}
{"epoch":55,"val_loss":148.80356,"val_metric":{"accuracy":0.68003,"micro":0.68003,"macro":0.62693},"test_metric":{"accuracy":0.72246,"micro":0.72246,"macro":0.68483}}
/home/daniel/local/opt/anaconda3/lib/python3.7/site-packages/torch/nn/functional.py:1386: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.
  warnings.warn("nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.")
/home/daniel/local/opt/anaconda3/lib/python3.7/site-packages/torch/nn/functional.py:1374: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
/home/daniel/local/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/home/daniel/local/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1145: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.
  'recall', 'true', average, warn_for)
-- done --
