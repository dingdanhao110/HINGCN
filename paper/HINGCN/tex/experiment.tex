\section{Experiment}
\label{sec:exp}
We conducted extensive experiments to evaluate the performance of HINGCN.
This section summarizes our results. 
We compare the various methods using three popular measures, 
namely, \emph{accuracy}, \emph{micro-F1}, and \emph{macro-F1}.
These measures evaluate clustering quality and their values range from 0 to 1, 
with a larger value indicating a better
clustering quality. 
%We first describe the performance measures (Section~\ref{sec:measures}) and
%existing methods against which ROSC is compared (Section~\ref{sec:algo-comp}).
%We then show the performance results on both real and synthetic datasets (Section~\ref{sec:results}).
%We illustrate the grouping effect of matrix $\tilde{Z}$ (Section~\ref{}).
%Finally, we conduct a parameter sensitivity study of ROSC (Section~\ref{}).

\subsection{Datasets}
We use three datasets, namely DBLP \footnote{https://dblp.uni-trier.de/}, Yelp\footnote{https://www.yelp.com/academic{\_}dataset/} and Freebase \footnote{https://www.freebase.com/}. A summary of statistics of the datasets are shown in table \ref{tab:dataset}.

% Please add the following required packages to your document preamble:
% \usepackage{multirow}
\begin{table*}[!htbp]
\centering
\caption{Statistics of the datasets}
\label{tab:dataset}
\begin{tabular}{|c|c|c|c|c|c|c|c|}
\hline
Dataset                   & Relations                     & Number of A            & Number of B           & Number o A-B      & Feature               & Number of target nodes & Meta-paths \\ \hline
\multirow{3}{*}{DBLP}     & \multirow{2}{*}{Paper-Author} & \multirow{2}{*}{14328} & \multirow{2}{*}{4057} & \multirow{2}{*}{} & \multirow{3}{*}{8789} & \multirow{3}{*}{4057}  & APA        \\ \cline{8-8} 
                          &                               &                        &                       &                   &                       &                        & APAPA      \\ \cline{2-5} \cline{8-8} 
                          & Paper-Conf                    & 14328                  & 20                    &                   &                       &                        & APCPA      \\ \hline
\multirow{3}{*}{Yelp}     & Business-Review               & 2614                   & 33360                 &                   & \multirow{3}{*}{}     & \multirow{3}{*}{}      & -          \\ \cline{2-5} \cline{8-8} 
                          & Review-Keyword                &  33360                 &  82                   &                   &                       &                        & BRKRB      \\ \cline{2-5} \cline{8-8} 
                          & Review-User                   &  33360                 &  1286                 &                   &                       &                        & BRURB      \\ \hline
\multirow{3}{*}{Freebase} & Movie-Actor                   & 1465                    &  4019                 &                   & \multirow{3}{*}{}     & \multirow{3}{*}{}      & MAM        \\ \cline{2-5} \cline{8-8} 
                          & Movie-Director                & 1465                   &  1093                  &                   &                       &                        & MDM        \\ \cline{2-5} \cline{8-8} 
                          & Movie-Writer                  & 1465                   &  1458                 &                   &                       &                        & MWM        \\ \hline
\end{tabular}
\end{table*}

\noindent{\small$\bullet$}
\textbf{DBLP }: We extract a subset of DBLP which contains 4057 authors ($A$), 14328 papers ($P$) and 20 conferences ($C$). Authors are classified into four areas: \textit{database}, \textit{data mining}, \textit{machine learning}, \textit{information retrieval}. In addition, 8789 keyword terms are assigned to each author as feature, following tf-idf transformation. 
Links include A-P ( author publishes a paper) and P-C (paper published at a conference).
We consider meta-paths $\{APA,APAPA,APCPA\}$ for experiments. The task of semi-supervised classification is to predict which area of research an author is focusing on.
We obtained the ground truth from the dataset dblp-4area \cite{SunYH09}, which
labels each author by his/her primary research area.

\noindent{\small$\bullet$}
\textbf{Yelp-Restaurant}: We extracted information related to restaurant businesses in YELP. From extracted information, we constructed a dataset which contains 2614 business objects ($B$); 33360 review objects ($R$); 1286 user objects ($U$) and 82 food relevant keyword objects ($K$).
Restaurant businesses falls into three categories: "Fast Food", "Sushi Bars" and "American (New) Food".
Each business object is associated with 3 categorical attributes which includes reservation (whether reservation is required), service (waiter service or self service) and parking; as well as 1 numerical attribute: review count; and 1 ordinal attribute: quality star.
Links include B-R (business receives a review), U-R (user writes a review), K-R (keyword included in a review). We consider the meta-path set $\{BRURB, BRKRB\}$. The semi-supervised classification task is to classify business objects by state. We use the class information provided in the dataset as the ground truth.

\noindent{\small$\bullet$}
\textbf{Freebase-Movie}: We extract a subset of Freebase movie data which contains ? movies ($M$); ? actors ($A$); ? directors ($D$) and ? writers ($W$). The movies are divided into three classes: \textit{Action}, \textit{Comedy} and \textit{Drama}. 
%Each movie has a 5-dimensional meta-data as feature.
No attribute is provided with movies. 
Links include M-A (movie and its actor), M-D (movie and its director), M-W (movie and its writer).
We consider meta-paths $\{MAM,MDM,MWM\}$ for experiments. The task of semi-supervised classification is to predict the class of movies. We use the class information provided in the dataset as the ground truth.

\comment{
\subsection{Measures}
\label{sec:measures}
We use three popular measures, namely, \emph{purity}, \emph{adjusted mutual information (AMI)}, and \emph{rand index (RI)}, to evaluate clustering quality~\cite{vinh2010information,lin2010power}.

Consider a clustering $\mathcal{C} = \{C_1, \ldots, C_k\}$ produced by a clustering algorithm
and a gold standard (true) clustering
$\mathcal{C}_t = \{ \hat{C}_1, \ldots, \hat{C}_k\}$.
For each cluster $C_i \in \mathcal{C}$, we find the cluster $\hat{C}_j \in \mathcal{C}_t$ that overlaps
with $C_i$ the most. 
The purity of cluster $C_i$ is the fraction of objects in $C_i$ that fall in the overlap, i.e., 
($\max_j |C_i \cap \hat{C}_j|) / |C_i|$. 
The purity of a clustering $\mathcal{C}$ is the average of its clusters' purities, weighted by the cluster sizes:
\begin{equation}
purity(\mathcal{C}_t,\mathcal{C}) = \frac{1}{n}\sum_{i}\max_{j}|C_i \cap \hat C_j|.
\end{equation}
The adjusted mutual information ({\it AMI}) is mutual information with the agreement due to chance between clusterings corrected, and
is given by,
\begin{equation}
\mathit{AMI}(\mathcal{C}_t,\mathcal{C}) = \frac{MI(\mathcal{C}_t,\mathcal{C}) - E\{MI(\mathcal{C}_t,\mathcal{C})\}}{\max\{H(\mathcal{C}_t),H(\mathcal{C})\} - E\{MI(\mathcal{C}_t,\mathcal{C})\}},
\end{equation}
where $MI(\mathcal{C}_t,\mathcal{C})$ is the mutual information between $\mathcal{C}_t$ and $\mathcal{C}$,
$H(\mathcal{C}_t)$ and $H(\mathcal{C})$ are the entropies of $\mathcal{C}_t$ and $\mathcal{C}$, respectively,
and $E\{MI(\mathcal{C}_t,\mathcal{C})\}$ is the expected mutual information between the two clusterings
$\mathcal{C}_t$ and $\mathcal{C}$.

Rand index ({\it RI}) considers object pairs in measuring clustering quality. It is defined as:
\begin{equation}
RI(\mathcal{C}_t,\mathcal{C}) = (N_{00} + N_{11}) / {\tbinom n2},
\end{equation}
where $N_{00}$ is the number of object pairs that are put into the same cluster in $\mathcal{C}_t$
as well as in the same cluster in $\mathcal{C}$, and
$N_{11}$ is the number of object pairs that are put into different clusters in 
$\mathcal{C}_t$ and also in different clusters in $\mathcal{C}$.
Note that values of all three measures range from 0 to 1, with a larger value indicating a better
clustering quality. 
}

\subsection{Algorithms for comparison}
\label{sec:algo-comp}
We evaluate HINGCN and 9 other methods. To demonstrate effectiveness of our edge update mechanism and meta-path GLU layer, we also includes two variants of HINGCN.

\noindent{\small$\bullet$}
\textbf{Node2vec\cite{GroverL16}}: A random walk based homogeneous graph embedding method. Here we ignore the heterogeneity of nodes and perform node2vec on the whole heterogeneous graph. The prediction is generated by feeding embeddings to a logistics classifier.

\noindent{\small$\bullet$}
\textbf{Metpath2vec\cite{DongCS17}}: A random walk based heterogeneous graph embedding method. The algorithm performs meta-path specific random walks and generates embeddings for each meta-path. The prediction is generated by feeding embeddings to a logistics classifier. We test all meta-paths and report the best performance.

\noindent{\small$\bullet$}
\textbf{GCN\cite{KipfW17}}: A semi-supervised graph convolution network that is designed for homogeneous graphs. Here we ignore the heterogeneity of nodes and perform GCN on the whole heterogeneous graph. 

\noindent{\small$\bullet$}
\textbf{GAT\cite{VelickovicCCRLB18}}: A semi-supervised graph neural network that utilizes attention mechanism on homogeneous graphs. Here we ignore the heterogeneity of nodes and perform GAT on the whole heterogeneous graph. 

\noindent{\small$\bullet$}
\textbf{HAN\cite{WangJSWYCY19}}:
A hierarchical semi-supervised graph neural network on heterogeneous graphs. HAN employs node-level attention and meta-path level aggregation to capture node-level and semantic-level heterogeneity.

\noindent{\small$\bullet$}
\textbf{HINGCN$_{ne}$}: 
A variant of HINGCN which removes edge feature in the update process of node embeddings.

\noindent{\small$\bullet$}
\textbf{HINGCN$_{nu}$}: 
A variant of HINGCN which replace update of edge embedding by identity propagation.

\noindent{\small$\bullet$}
\textbf{HINGCN$_{at}$}:
A variant of HINGCN which uses attention mechanism for meta-path level aggregation.

\noindent{\small$\bullet$}
\textbf{HINGCN}:
The proposed semi-supervised classification method based on heterogeneous graph convolution networks.


\subsection{Experiment setup}
\label{sec:setup}
We implement HINGCN using PyTorch. We use the same learning rate 0.001 for all HINGCN variants. The models  are trained with two NVIDIA 1080Ti GPUs using data parallelism. The batch size is 1024 for each GPU. We stack two graph aggregators, and each aggregator samples 16 neighbors for both training and testing. Each aggregator is then followed by a ReLU activation layer and a dropout layer with dropout rate 0.5. Output dimension of the layers are set to 64 and 32 respectively. For dataset without node features, we encode a 1-hot matrix as input feature. As mentioned in section \ref{sec:edge}, we ensemble edge feature from pre-trained path-sim and node embeddings. These node embeddings are trained using metapath2vec \citep{DongCS17} with default parameters on the same graph and corresponding meta-paths. 
%code release
To make our experiment results repeatable, we release our datasets and implementation on Github with an anonymous account\footnote{http://github.com/TODO}.
%Baseline settings
For all baseline methods, we employ exactly the same training set, validation set and test sets for fairness. For GCNNs including GCN, GAT and HAN, we tune hyper-parameters of baseline methods on validation sets. For unsupervised random walk methods including Node2vec and Metapath2vec, we train the embedding using the whole graph, but only send training set embeddings to downstream logistics classifier. For these random walk methods, we set window size to 5, walk length to 100, walks per node to 1000, the number of negative samples to 5.
For each experiment setting, we set 10 different random seed for dataset partition and report the average statistics.

\subsection{Performance results}
\label{sec:results}

Here we present the experiment result of applying all \dan{10?} methods on \textsc{DBLP},\textsc{Yelp} and \textsc{Freebase}. We report the averaged \textit{Macro-F1} and \textit{Micro-F1} on Tab.~\ref{tab:result}.

As is shown in Tab.~\ref{tab:result}, HINGCN generally achieves the best results on all datasets.
Surprisingly, although Metapath2vec was proposed for heterogeneous graphs, it cannot produce a better result than methods designed for homogeneous graphs. One possible reason is that during training process, only part of semantic (i.e. single meta-path) is considered. ESim, however, considers multiple meta-paths at the same time and gives a better result than Node2vec. Graph neural network methods utilize both graph structure information and node feature information, and generally perform best. Among  these GCNN methods, we can see that highly engineered neural structures tailored for heterogeneous graph, e.g. HAN and HINGCN, usually perform better. Compared to GCN and GAT, HAN considers hierarchical semantic relationship instead of entire neighborhood of nodes in heterogeneous graphs. And HINGCN further includes edge features that are excluded from HAN model. Also, without edge features (HINGCN$_{ne}$) or without edge updates (HINGCN$_{ne}$), the performance is worse than HINGCN, indicating the effectiveness of proposed architecture. A comparison between HINGCN$_{at}$ and HINGCN suggest that GLU is indeed a better choice for meta-path level aggregation as suggested in section \ref{sec:mp_aggr}.

%Results
\begin{table*}[!htbp]
\centering
%\resizebox{0.9\linewidth}{!}
\caption{Quantitative results (\%) on semi-supervised classification task}
\label{tab:result}
\begin{tabular}{|c|c|c||c|c|c|c|c||c|c|c|c|}
\hline
Datasets                  & Metrics                   & Training & Node2vec & Metapath2vec & GCN & GAT & HAN & HINGCN$_{ne}$ & HINGCN$_{nu}$ & HINGCN$_{at}$ & HINGCN \\ \hline
\multirow{8}{*}{DBLP}     & \multirow{4}{*}{Macro-F1} & 10\%     &  92.63   &   92.08      &     &     &     &        &        &        &        \\
                          &                           & 20\%     &  93.97   &   93.21      &     &     &     &        &        &        &        \\
                          &                           & 30\%     &  93.47   &   92.80      &     &     &     &        &        &        &        \\
                          &                           & 40\%     &  93.84   &   92.14      &     &     &     &        &        &        &        \\ \cline{2-12} 
                          & \multirow{4}{*}{Micro-F1} & 10\%     &  92.86   &   92.36      &     &     &     &        &        &        &        \\
                          &                           & 20\%     &  94.21   &   93.47      &     &     &     &        &        &        &        \\
                          &                           & 30\%     &  93.72   &   93.10      &     &     &     &        &        &        &        \\
                          &                           & 40\%     &  94.09   &   92.49      &     &     &     &        &        &        &        \\ \hline
\multirow{8}{*}{Yelp}     & \multirow{4}{*}{Macro-F1} & 10\%     &          &   90.59      &     &     &     &        &        &        &        \\
                          &                           & 20\%     &          &   91.08      &     &     &     &        &        &        &        \\
                          &                           & 30\%     &          &   93.07      &     &     &     &        &        &        &        \\
                          &                           & 40\%     &          &   93.07      &     &     &     &        &        &        &        \\ \cline{2-12} 
                          & \multirow{4}{*}{Micro-F1} & 10\%     &          &   89.48      &     &     &     &        &        &        &        \\
                          &                           & 20\%     &          &   90.06      &     &     &     &        &        &        &        \\
                          &                           & 30\%     &          &   92.16      &     &     &     &        &        &        &        \\
                          &                           & 40\%     &          &   92.16      &     &     &     &        &        &        &        \\ \hline
\multirow{8}{*}{Freebase} & \multirow{4}{*}{Macro-F1} & 10\%     &          &   64.68      &     &     &     &        &        &        &        \\
                          &                           & 20\%     &          &   66.10      &     &     &     &        &        &        &        \\
                          &                           & 30\%     &          &   65.66      &     &     &     &        &        &        &        \\
                          &                           & 40\%     &          &   65.35      &     &     &     &        &        &        &        \\ \cline{2-12} 
                          & \multirow{4}{*}{Micro-F1} & 10\%     &          &   70.53      &     &     &     &        &        &        &        \\
                          &                           & 20\%     &          &   72.10      &     &     &     &        &        &        &        \\
                          &                           & 30\%     &          &   72.39      &     &     &     &        &        &        &        \\
                          &                           & 40\%     &          &   72.25      &     &     &     &        &        &        &        \\ \hline
\end{tabular}
\end{table*}

\subsection{Analysis of HINGCN layers}
We provide a detailed analysis of each component layer of HINGCN model.

\textbf{Analysis of edge feature.}
As mentioned in section \ref{sec:edge}, before training of HINGCN, we fuse edge features as supplementary information. To justify its effectiveness, we make a variant of HINGCN by removing edge feature in the update process in Eq.~\ref{eq:key}. We name this variant as HINGCN$_{ne}$. From Fig.~\ref{tab:result}, we can see that compared to HINGCN, removal of edge feature results in a severe degradation of performance. This experiment result confirms our claim.

\textbf{Analysis of effect of updating edge.}

\textbf{Analysis of different meta-path aggregation units.}

\subsection{Sensitivity Experiments of Hyper-parameters}
In this section, we investigate the sensitivity of hyper-parameters. We vary concerned parameters and compare against default settings described in Sec.~\ref{sec:setup} 

%\textbf{Learning rate.}We first analysis the effect of changing learning rate. 
\textbf{Dimension of edge feature.}We first analysis the effect of changing edge dimension in pre-processing.  We use experiment to see whether HINGCN is sensitive to input feature dimensions. The result is shown in Fig.~\ref{??}.
%In principle, edge feature is learned from graph structures, independent of vertex feature. Intuitively, different edge feature dimension may impose different significance in attention calculation and therefore affect model performance. On the other hand, however, the 2 layer MLP in Eq.~\ref{eq:key} may be capable address this difference.


\textbf{Number of sampled neighbors.}

\textbf{Number of node update layers.} In HINGCN, we adopt an alternative update scheme of node and edge embeddings. We would like to see if stacking more update layers would cause degradation of performance. The performance of HINGCN variants with or withour jumping connections is shown in Fig.~\ref{fig:??}. 






