NodeProblem: loading started
loading edge embedding for MAM complete, num of embeddings: 129098
loading edge embedding for MDM complete, num of embeddings: 5949
loading edge embedding for MWM complete, num of embeddings: 7100
NodeProblem: loading finished
Let's use 2 GPUs!
DataParallel(
  (module): HINGCN_GS(
    (prep): NodeEmbeddingPrep(
      (embedding): Embedding(3493, 32)
      (fc): Linear(in_features=32, out_features=32, bias=True)
    )
    (agg_0_0): ModuleList(
      (0): AttentionAggregator2(
        (att): Sequential(
          (0): Linear(in_features=32, out_features=512, bias=False)
          (1): Tanh()
          (2): Linear(in_features=512, out_features=512, bias=False)
        )
        (att2): Sequential(
          (0): Linear(in_features=50, out_features=512, bias=False)
          (1): Tanh()
          (2): Linear(in_features=512, out_features=512, bias=False)
        )
        (fc_x): Linear(in_features=32, out_features=64, bias=False)
        (fc_neib): Linear(in_features=50, out_features=64, bias=False)
        (dropout): Dropout(p=0.5)
      )
      (1): AttentionAggregator2(
        (att): Sequential(
          (0): Linear(in_features=32, out_features=512, bias=False)
          (1): Tanh()
          (2): Linear(in_features=512, out_features=512, bias=False)
        )
        (att2): Sequential(
          (0): Linear(in_features=50, out_features=512, bias=False)
          (1): Tanh()
          (2): Linear(in_features=512, out_features=512, bias=False)
        )
        (fc_x): Linear(in_features=32, out_features=64, bias=False)
        (fc_neib): Linear(in_features=50, out_features=64, bias=False)
        (dropout): Dropout(p=0.5)
      )
      (2): AttentionAggregator2(
        (att): Sequential(
          (0): Linear(in_features=32, out_features=512, bias=False)
          (1): Tanh()
          (2): Linear(in_features=512, out_features=512, bias=False)
        )
        (att2): Sequential(
          (0): Linear(in_features=50, out_features=512, bias=False)
          (1): Tanh()
          (2): Linear(in_features=512, out_features=512, bias=False)
        )
        (fc_x): Linear(in_features=32, out_features=64, bias=False)
        (fc_neib): Linear(in_features=50, out_features=64, bias=False)
        (dropout): Dropout(p=0.5)
      )
      (3): AttentionAggregator2(
        (att): Sequential(
          (0): Linear(in_features=32, out_features=512, bias=False)
          (1): Tanh()
          (2): Linear(in_features=512, out_features=512, bias=False)
        )
        (att2): Sequential(
          (0): Linear(in_features=50, out_features=512, bias=False)
          (1): Tanh()
          (2): Linear(in_features=512, out_features=512, bias=False)
        )
        (fc_x): Linear(in_features=32, out_features=64, bias=False)
        (fc_neib): Linear(in_features=50, out_features=64, bias=False)
        (dropout): Dropout(p=0.5)
      )
      (4): AttentionAggregator2(
        (att): Sequential(
          (0): Linear(in_features=32, out_features=512, bias=False)
          (1): Tanh()
          (2): Linear(in_features=512, out_features=512, bias=False)
        )
        (att2): Sequential(
          (0): Linear(in_features=50, out_features=512, bias=False)
          (1): Tanh()
          (2): Linear(in_features=512, out_features=512, bias=False)
        )
        (fc_x): Linear(in_features=32, out_features=64, bias=False)
        (fc_neib): Linear(in_features=50, out_features=64, bias=False)
        (dropout): Dropout(p=0.5)
      )
      (5): AttentionAggregator2(
        (att): Sequential(
          (0): Linear(in_features=32, out_features=512, bias=False)
          (1): Tanh()
          (2): Linear(in_features=512, out_features=512, bias=False)
        )
        (att2): Sequential(
          (0): Linear(in_features=50, out_features=512, bias=False)
          (1): Tanh()
          (2): Linear(in_features=512, out_features=512, bias=False)
        )
        (fc_x): Linear(in_features=32, out_features=64, bias=False)
        (fc_neib): Linear(in_features=50, out_features=64, bias=False)
        (dropout): Dropout(p=0.5)
      )
      (6): AttentionAggregator2(
        (att): Sequential(
          (0): Linear(in_features=32, out_features=512, bias=False)
          (1): Tanh()
          (2): Linear(in_features=512, out_features=512, bias=False)
        )
        (att2): Sequential(
          (0): Linear(in_features=50, out_features=512, bias=False)
          (1): Tanh()
          (2): Linear(in_features=512, out_features=512, bias=False)
        )
        (fc_x): Linear(in_features=32, out_features=64, bias=False)
        (fc_neib): Linear(in_features=50, out_features=64, bias=False)
        (dropout): Dropout(p=0.5)
      )
      (7): AttentionAggregator2(
        (att): Sequential(
          (0): Linear(in_features=32, out_features=512, bias=False)
          (1): Tanh()
          (2): Linear(in_features=512, out_features=512, bias=False)
        )
        (att2): Sequential(
          (0): Linear(in_features=50, out_features=512, bias=False)
          (1): Tanh()
          (2): Linear(in_features=512, out_features=512, bias=False)
        )
        (fc_x): Linear(in_features=32, out_features=64, bias=False)
        (fc_neib): Linear(in_features=50, out_features=64, bias=False)
        (dropout): Dropout(p=0.5)
      )
      (8): AttentionAggregator2(
        (att): Sequential(
          (0): Linear(in_features=32, out_features=512, bias=False)
          (1): Tanh()
          (2): Linear(in_features=512, out_features=512, bias=False)
        )
        (att2): Sequential(
          (0): Linear(in_features=50, out_features=512, bias=False)
          (1): Tanh()
          (2): Linear(in_features=512, out_features=512, bias=False)
        )
        (fc_x): Linear(in_features=32, out_features=64, bias=False)
        (fc_neib): Linear(in_features=50, out_features=64, bias=False)
        (dropout): Dropout(p=0.5)
      )
      (9): AttentionAggregator2(
        (att): Sequential(
          (0): Linear(in_features=32, out_features=512, bias=False)
          (1): Tanh()
          (2): Linear(in_features=512, out_features=512, bias=False)
        )
        (att2): Sequential(
          (0): Linear(in_features=50, out_features=512, bias=False)
          (1): Tanh()
          (2): Linear(in_features=512, out_features=512, bias=False)
        )
        (fc_x): Linear(in_features=32, out_features=64, bias=False)
        (fc_neib): Linear(in_features=50, out_features=64, bias=False)
        (dropout): Dropout(p=0.5)
      )
      (10): AttentionAggregator2(
        (att): Sequential(
          (0): Linear(in_features=32, out_features=512, bias=False)
          (1): Tanh()
          (2): Linear(in_features=512, out_features=512, bias=False)
        )
        (att2): Sequential(
          (0): Linear(in_features=50, out_features=512, bias=False)
          (1): Tanh()
          (2): Linear(in_features=512, out_features=512, bias=False)
        )
        (fc_x): Linear(in_features=32, out_features=64, bias=False)
        (fc_neib): Linear(in_features=50, out_features=64, bias=False)
        (dropout): Dropout(p=0.5)
      )
      (11): AttentionAggregator2(
        (att): Sequential(
          (0): Linear(in_features=32, out_features=512, bias=False)
          (1): Tanh()
          (2): Linear(in_features=512, out_features=512, bias=False)
        )
        (att2): Sequential(
          (0): Linear(in_features=50, out_features=512, bias=False)
          (1): Tanh()
          (2): Linear(in_features=512, out_features=512, bias=False)
        )
        (fc_x): Linear(in_features=32, out_features=64, bias=False)
        (fc_neib): Linear(in_features=50, out_features=64, bias=False)
        (dropout): Dropout(p=0.5)
      )
      (12): AttentionAggregator2(
        (att): Sequential(
          (0): Linear(in_features=32, out_features=512, bias=False)
          (1): Tanh()
          (2): Linear(in_features=512, out_features=512, bias=False)
        )
        (att2): Sequential(
          (0): Linear(in_features=50, out_features=512, bias=False)
          (1): Tanh()
          (2): Linear(in_features=512, out_features=512, bias=False)
        )
        (fc_x): Linear(in_features=32, out_features=64, bias=False)
        (fc_neib): Linear(in_features=50, out_features=64, bias=False)
        (dropout): Dropout(p=0.5)
      )
      (13): AttentionAggregator2(
        (att): Sequential(
          (0): Linear(in_features=32, out_features=512, bias=False)
          (1): Tanh()
          (2): Linear(in_features=512, out_features=512, bias=False)
        )
        (att2): Sequential(
          (0): Linear(in_features=50, out_features=512, bias=False)
          (1): Tanh()
          (2): Linear(in_features=512, out_features=512, bias=False)
        )
        (fc_x): Linear(in_features=32, out_features=64, bias=False)
        (fc_neib): Linear(in_features=50, out_features=64, bias=False)
        (dropout): Dropout(p=0.5)
      )
      (14): AttentionAggregator2(
        (att): Sequential(
          (0): Linear(in_features=32, out_features=512, bias=False)
          (1): Tanh()
          (2): Linear(in_features=512, out_features=512, bias=False)
        )
        (att2): Sequential(
          (0): Linear(in_features=50, out_features=512, bias=False)
          (1): Tanh()
          (2): Linear(in_features=512, out_features=512, bias=False)
        )
        (fc_x): Linear(in_features=32, out_features=64, bias=False)
        (fc_neib): Linear(in_features=50, out_features=64, bias=False)
        (dropout): Dropout(p=0.5)
      )
      (15): AttentionAggregator2(
        (att): Sequential(
          (0): Linear(in_features=32, out_features=512, bias=False)
          (1): Tanh()
          (2): Linear(in_features=512, out_features=512, bias=False)
        )
        (att2): Sequential(
          (0): Linear(in_features=50, out_features=512, bias=False)
          (1): Tanh()
          (2): Linear(in_features=512, out_features=512, bias=False)
        )
        (fc_x): Linear(in_features=32, out_features=64, bias=False)
        (fc_neib): Linear(in_features=50, out_features=64, bias=False)
        (dropout): Dropout(p=0.5)
      )
    )
    (edge_0_0): IdEdgeAggregator(
      (dropout): Dropout(p=0.5)
    )
    (agg_1_0): ModuleList(
      (0): AttentionAggregator2(
        (att): Sequential(
          (0): Linear(in_features=32, out_features=512, bias=False)
          (1): Tanh()
          (2): Linear(in_features=512, out_features=512, bias=False)
        )
        (att2): Sequential(
          (0): Linear(in_features=50, out_features=512, bias=False)
          (1): Tanh()
          (2): Linear(in_features=512, out_features=512, bias=False)
        )
        (fc_x): Linear(in_features=32, out_features=64, bias=False)
        (fc_neib): Linear(in_features=50, out_features=64, bias=False)
        (dropout): Dropout(p=0.5)
      )
      (1): AttentionAggregator2(
        (att): Sequential(
          (0): Linear(in_features=32, out_features=512, bias=False)
          (1): Tanh()
          (2): Linear(in_features=512, out_features=512, bias=False)
        )
        (att2): Sequential(
          (0): Linear(in_features=50, out_features=512, bias=False)
          (1): Tanh()
          (2): Linear(in_features=512, out_features=512, bias=False)
        )
        (fc_x): Linear(in_features=32, out_features=64, bias=False)
        (fc_neib): Linear(in_features=50, out_features=64, bias=False)
        (dropout): Dropout(p=0.5)
      )
      (2): AttentionAggregator2(
        (att): Sequential(
          (0): Linear(in_features=32, out_features=512, bias=False)
          (1): Tanh()
          (2): Linear(in_features=512, out_features=512, bias=False)
        )
        (att2): Sequential(
          (0): Linear(in_features=50, out_features=512, bias=False)
          (1): Tanh()
          (2): Linear(in_features=512, out_features=512, bias=False)
        )
        (fc_x): Linear(in_features=32, out_features=64, bias=False)
        (fc_neib): Linear(in_features=50, out_features=64, bias=False)
        (dropout): Dropout(p=0.5)
      )
      (3): AttentionAggregator2(
        (att): Sequential(
          (0): Linear(in_features=32, out_features=512, bias=False)
          (1): Tanh()
          (2): Linear(in_features=512, out_features=512, bias=False)
        )
        (att2): Sequential(
          (0): Linear(in_features=50, out_features=512, bias=False)
          (1): Tanh()
          (2): Linear(in_features=512, out_features=512, bias=False)
        )
        (fc_x): Linear(in_features=32, out_features=64, bias=False)
        (fc_neib): Linear(in_features=50, out_features=64, bias=False)
        (dropout): Dropout(p=0.5)
      )
      (4): AttentionAggregator2(
        (att): Sequential(
          (0): Linear(in_features=32, out_features=512, bias=False)
          (1): Tanh()
          (2): Linear(in_features=512, out_features=512, bias=False)
        )
        (att2): Sequential(
          (0): Linear(in_features=50, out_features=512, bias=False)
          (1): Tanh()
          (2): Linear(in_features=512, out_features=512, bias=False)
        )
        (fc_x): Linear(in_features=32, out_features=64, bias=False)
        (fc_neib): Linear(in_features=50, out_features=64, bias=False)
        (dropout): Dropout(p=0.5)
      )
      (5): AttentionAggregator2(
        (att): Sequential(
          (0): Linear(in_features=32, out_features=512, bias=False)
          (1): Tanh()
          (2): Linear(in_features=512, out_features=512, bias=False)
        )
        (att2): Sequential(
          (0): Linear(in_features=50, out_features=512, bias=False)
          (1): Tanh()
          (2): Linear(in_features=512, out_features=512, bias=False)
        )
        (fc_x): Linear(in_features=32, out_features=64, bias=False)
        (fc_neib): Linear(in_features=50, out_features=64, bias=False)
        (dropout): Dropout(p=0.5)
      )
      (6): AttentionAggregator2(
        (att): Sequential(
          (0): Linear(in_features=32, out_features=512, bias=False)
          (1): Tanh()
          (2): Linear(in_features=512, out_features=512, bias=False)
        )
        (att2): Sequential(
          (0): Linear(in_features=50, out_features=512, bias=False)
          (1): Tanh()
          (2): Linear(in_features=512, out_features=512, bias=False)
        )
        (fc_x): Linear(in_features=32, out_features=64, bias=False)
        (fc_neib): Linear(in_features=50, out_features=64, bias=False)
        (dropout): Dropout(p=0.5)
      )
      (7): AttentionAggregator2(
        (att): Sequential(
          (0): Linear(in_features=32, out_features=512, bias=False)
          (1): Tanh()
          (2): Linear(in_features=512, out_features=512, bias=False)
        )
        (att2): Sequential(
          (0): Linear(in_features=50, out_features=512, bias=False)
          (1): Tanh()
          (2): Linear(in_features=512, out_features=512, bias=False)
        )
        (fc_x): Linear(in_features=32, out_features=64, bias=False)
        (fc_neib): Linear(in_features=50, out_features=64, bias=False)
        (dropout): Dropout(p=0.5)
      )
      (8): AttentionAggregator2(
        (att): Sequential(
          (0): Linear(in_features=32, out_features=512, bias=False)
          (1): Tanh()
          (2): Linear(in_features=512, out_features=512, bias=False)
        )
        (att2): Sequential(
          (0): Linear(in_features=50, out_features=512, bias=False)
          (1): Tanh()
          (2): Linear(in_features=512, out_features=512, bias=False)
        )
        (fc_x): Linear(in_features=32, out_features=64, bias=False)
        (fc_neib): Linear(in_features=50, out_features=64, bias=False)
        (dropout): Dropout(p=0.5)
      )
      (9): AttentionAggregator2(
        (att): Sequential(
          (0): Linear(in_features=32, out_features=512, bias=False)
          (1): Tanh()
          (2): Linear(in_features=512, out_features=512, bias=False)
        )
        (att2): Sequential(
          (0): Linear(in_features=50, out_features=512, bias=False)
          (1): Tanh()
          (2): Linear(in_features=512, out_features=512, bias=False)
        )
        (fc_x): Linear(in_features=32, out_features=64, bias=False)
        (fc_neib): Linear(in_features=50, out_features=64, bias=False)
        (dropout): Dropout(p=0.5)
      )
      (10): AttentionAggregator2(
        (att): Sequential(
          (0): Linear(in_features=32, out_features=512, bias=False)
          (1): Tanh()
          (2): Linear(in_features=512, out_features=512, bias=False)
        )
        (att2): Sequential(
          (0): Linear(in_features=50, out_features=512, bias=False)
          (1): Tanh()
          (2): Linear(in_features=512, out_features=512, bias=False)
        )
        (fc_x): Linear(in_features=32, out_features=64, bias=False)
        (fc_neib): Linear(in_features=50, out_features=64, bias=False)
        (dropout): Dropout(p=0.5)
      )
      (11): AttentionAggregator2(
        (att): Sequential(
          (0): Linear(in_features=32, out_features=512, bias=False)
          (1): Tanh()
          (2): Linear(in_features=512, out_features=512, bias=False)
        )
        (att2): Sequential(
          (0): Linear(in_features=50, out_features=512, bias=False)
          (1): Tanh()
          (2): Linear(in_features=512, out_features=512, bias=False)
        )
        (fc_x): Linear(in_features=32, out_features=64, bias=False)
        (fc_neib): Linear(in_features=50, out_features=64, bias=False)
        (dropout): Dropout(p=0.5)
      )
      (12): AttentionAggregator2(
        (att): Sequential(
          (0): Linear(in_features=32, out_features=512, bias=False)
          (1): Tanh()
          (2): Linear(in_features=512, out_features=512, bias=False)
        )
        (att2): Sequential(
          (0): Linear(in_features=50, out_features=512, bias=False)
          (1): Tanh()
          (2): Linear(in_features=512, out_features=512, bias=False)
        )
        (fc_x): Linear(in_features=32, out_features=64, bias=False)
        (fc_neib): Linear(in_features=50, out_features=64, bias=False)
        (dropout): Dropout(p=0.5)
      )
      (13): AttentionAggregator2(
        (att): Sequential(
          (0): Linear(in_features=32, out_features=512, bias=False)
          (1): Tanh()
          (2): Linear(in_features=512, out_features=512, bias=False)
        )
        (att2): Sequential(
          (0): Linear(in_features=50, out_features=512, bias=False)
          (1): Tanh()
          (2): Linear(in_features=512, out_features=512, bias=False)
        )
        (fc_x): Linear(in_features=32, out_features=64, bias=False)
        (fc_neib): Linear(in_features=50, out_features=64, bias=False)
        (dropout): Dropout(p=0.5)
      )
      (14): AttentionAggregator2(
        (att): Sequential(
          (0): Linear(in_features=32, out_features=512, bias=False)
          (1): Tanh()
          (2): Linear(in_features=512, out_features=512, bias=False)
        )
        (att2): Sequential(
          (0): Linear(in_features=50, out_features=512, bias=False)
          (1): Tanh()
          (2): Linear(in_features=512, out_features=512, bias=False)
        )
        (fc_x): Linear(in_features=32, out_features=64, bias=False)
        (fc_neib): Linear(in_features=50, out_features=64, bias=False)
        (dropout): Dropout(p=0.5)
      )
      (15): AttentionAggregator2(
        (att): Sequential(
          (0): Linear(in_features=32, out_features=512, bias=False)
          (1): Tanh()
          (2): Linear(in_features=512, out_features=512, bias=False)
        )
        (att2): Sequential(
          (0): Linear(in_features=50, out_features=512, bias=False)
          (1): Tanh()
          (2): Linear(in_features=512, out_features=512, bias=False)
        )
        (fc_x): Linear(in_features=32, out_features=64, bias=False)
        (fc_neib): Linear(in_features=50, out_features=64, bias=False)
        (dropout): Dropout(p=0.5)
      )
    )
    (edge_1_0): IdEdgeAggregator(
      (dropout): Dropout(p=0.5)
    )
    (agg_2_0): ModuleList(
      (0): AttentionAggregator2(
        (att): Sequential(
          (0): Linear(in_features=32, out_features=512, bias=False)
          (1): Tanh()
          (2): Linear(in_features=512, out_features=512, bias=False)
        )
        (att2): Sequential(
          (0): Linear(in_features=50, out_features=512, bias=False)
          (1): Tanh()
          (2): Linear(in_features=512, out_features=512, bias=False)
        )
        (fc_x): Linear(in_features=32, out_features=64, bias=False)
        (fc_neib): Linear(in_features=50, out_features=64, bias=False)
        (dropout): Dropout(p=0.5)
      )
      (1): AttentionAggregator2(
        (att): Sequential(
          (0): Linear(in_features=32, out_features=512, bias=False)
          (1): Tanh()
          (2): Linear(in_features=512, out_features=512, bias=False)
        )
        (att2): Sequential(
          (0): Linear(in_features=50, out_features=512, bias=False)
          (1): Tanh()
          (2): Linear(in_features=512, out_features=512, bias=False)
        )
        (fc_x): Linear(in_features=32, out_features=64, bias=False)
        (fc_neib): Linear(in_features=50, out_features=64, bias=False)
        (dropout): Dropout(p=0.5)
      )
      (2): AttentionAggregator2(
        (att): Sequential(
          (0): Linear(in_features=32, out_features=512, bias=False)
          (1): Tanh()
          (2): Linear(in_features=512, out_features=512, bias=False)
        )
        (att2): Sequential(
          (0): Linear(in_features=50, out_features=512, bias=False)
          (1): Tanh()
          (2): Linear(in_features=512, out_features=512, bias=False)
        )
        (fc_x): Linear(in_features=32, out_features=64, bias=False)
        (fc_neib): Linear(in_features=50, out_features=64, bias=False)
        (dropout): Dropout(p=0.5)
      )
      (3): AttentionAggregator2(
        (att): Sequential(
          (0): Linear(in_features=32, out_features=512, bias=False)
          (1): Tanh()
          (2): Linear(in_features=512, out_features=512, bias=False)
        )
        (att2): Sequential(
          (0): Linear(in_features=50, out_features=512, bias=False)
          (1): Tanh()
          (2): Linear(in_features=512, out_features=512, bias=False)
        )
        (fc_x): Linear(in_features=32, out_features=64, bias=False)
        (fc_neib): Linear(in_features=50, out_features=64, bias=False)
        (dropout): Dropout(p=0.5)
      )
      (4): AttentionAggregator2(
        (att): Sequential(
          (0): Linear(in_features=32, out_features=512, bias=False)
          (1): Tanh()
          (2): Linear(in_features=512, out_features=512, bias=False)
        )
        (att2): Sequential(
          (0): Linear(in_features=50, out_features=512, bias=False)
          (1): Tanh()
          (2): Linear(in_features=512, out_features=512, bias=False)
        )
        (fc_x): Linear(in_features=32, out_features=64, bias=False)
        (fc_neib): Linear(in_features=50, out_features=64, bias=False)
        (dropout): Dropout(p=0.5)
      )
      (5): AttentionAggregator2(
        (att): Sequential(
          (0): Linear(in_features=32, out_features=512, bias=False)
          (1): Tanh()
          (2): Linear(in_features=512, out_features=512, bias=False)
        )
        (att2): Sequential(
          (0): Linear(in_features=50, out_features=512, bias=False)
          (1): Tanh()
          (2): Linear(in_features=512, out_features=512, bias=False)
        )
        (fc_x): Linear(in_features=32, out_features=64, bias=False)
        (fc_neib): Linear(in_features=50, out_features=64, bias=False)
        (dropout): Dropout(p=0.5)
      )
      (6): AttentionAggregator2(
        (att): Sequential(
          (0): Linear(in_features=32, out_features=512, bias=False)
          (1): Tanh()
          (2): Linear(in_features=512, out_features=512, bias=False)
        )
        (att2): Sequential(
          (0): Linear(in_features=50, out_features=512, bias=False)
          (1): Tanh()
          (2): Linear(in_features=512, out_features=512, bias=False)
        )
        (fc_x): Linear(in_features=32, out_features=64, bias=False)
        (fc_neib): Linear(in_features=50, out_features=64, bias=False)
        (dropout): Dropout(p=0.5)
      )
      (7): AttentionAggregator2(
        (att): Sequential(
          (0): Linear(in_features=32, out_features=512, bias=False)
          (1): Tanh()
          (2): Linear(in_features=512, out_features=512, bias=False)
        )
        (att2): Sequential(
          (0): Linear(in_features=50, out_features=512, bias=False)
          (1): Tanh()
          (2): Linear(in_features=512, out_features=512, bias=False)
        )
        (fc_x): Linear(in_features=32, out_features=64, bias=False)
        (fc_neib): Linear(in_features=50, out_features=64, bias=False)
        (dropout): Dropout(p=0.5)
      )
      (8): AttentionAggregator2(
        (att): Sequential(
          (0): Linear(in_features=32, out_features=512, bias=False)
          (1): Tanh()
          (2): Linear(in_features=512, out_features=512, bias=False)
        )
        (att2): Sequential(
          (0): Linear(in_features=50, out_features=512, bias=False)
          (1): Tanh()
          (2): Linear(in_features=512, out_features=512, bias=False)
        )
        (fc_x): Linear(in_features=32, out_features=64, bias=False)
        (fc_neib): Linear(in_features=50, out_features=64, bias=False)
        (dropout): Dropout(p=0.5)
      )
      (9): AttentionAggregator2(
        (att): Sequential(
          (0): Linear(in_features=32, out_features=512, bias=False)
          (1): Tanh()
          (2): Linear(in_features=512, out_features=512, bias=False)
        )
        (att2): Sequential(
          (0): Linear(in_features=50, out_features=512, bias=False)
          (1): Tanh()
          (2): Linear(in_features=512, out_features=512, bias=False)
        )
        (fc_x): Linear(in_features=32, out_features=64, bias=False)
        (fc_neib): Linear(in_features=50, out_features=64, bias=False)
        (dropout): Dropout(p=0.5)
      )
      (10): AttentionAggregator2(
        (att): Sequential(
          (0): Linear(in_features=32, out_features=512, bias=False)
          (1): Tanh()
          (2): Linear(in_features=512, out_features=512, bias=False)
        )
        (att2): Sequential(
          (0): Linear(in_features=50, out_features=512, bias=False)
          (1): Tanh()
          (2): Linear(in_features=512, out_features=512, bias=False)
        )
        (fc_x): Linear(in_features=32, out_features=64, bias=False)
        (fc_neib): Linear(in_features=50, out_features=64, bias=False)
        (dropout): Dropout(p=0.5)
      )
      (11): AttentionAggregator2(
        (att): Sequential(
          (0): Linear(in_features=32, out_features=512, bias=False)
          (1): Tanh()
          (2): Linear(in_features=512, out_features=512, bias=False)
        )
        (att2): Sequential(
          (0): Linear(in_features=50, out_features=512, bias=False)
          (1): Tanh()
          (2): Linear(in_features=512, out_features=512, bias=False)
        )
        (fc_x): Linear(in_features=32, out_features=64, bias=False)
        (fc_neib): Linear(in_features=50, out_features=64, bias=False)
        (dropout): Dropout(p=0.5)
      )
      (12): AttentionAggregator2(
        (att): Sequential(
          (0): Linear(in_features=32, out_features=512, bias=False)
          (1): Tanh()
          (2): Linear(in_features=512, out_features=512, bias=False)
        )
        (att2): Sequential(
          (0): Linear(in_features=50, out_features=512, bias=False)
          (1): Tanh()
          (2): Linear(in_features=512, out_features=512, bias=False)
        )
        (fc_x): Linear(in_features=32, out_features=64, bias=False)
        (fc_neib): Linear(in_features=50, out_features=64, bias=False)
        (dropout): Dropout(p=0.5)
      )
      (13): AttentionAggregator2(
        (att): Sequential(
          (0): Linear(in_features=32, out_features=512, bias=False)
          (1): Tanh()
          (2): Linear(in_features=512, out_features=512, bias=False)
        )
        (att2): Sequential(
          (0): Linear(in_features=50, out_features=512, bias=False)
          (1): Tanh()
          (2): Linear(in_features=512, out_features=512, bias=False)
        )
        (fc_x): Linear(in_features=32, out_features=64, bias=False)
        (fc_neib): Linear(in_features=50, out_features=64, bias=False)
        (dropout): Dropout(p=0.5)
      )
      (14): AttentionAggregator2(
        (att): Sequential(
          (0): Linear(in_features=32, out_features=512, bias=False)
          (1): Tanh()
          (2): Linear(in_features=512, out_features=512, bias=False)
        )
        (att2): Sequential(
          (0): Linear(in_features=50, out_features=512, bias=False)
          (1): Tanh()
          (2): Linear(in_features=512, out_features=512, bias=False)
        )
        (fc_x): Linear(in_features=32, out_features=64, bias=False)
        (fc_neib): Linear(in_features=50, out_features=64, bias=False)
        (dropout): Dropout(p=0.5)
      )
      (15): AttentionAggregator2(
        (att): Sequential(
          (0): Linear(in_features=32, out_features=512, bias=False)
          (1): Tanh()
          (2): Linear(in_features=512, out_features=512, bias=False)
        )
        (att2): Sequential(
          (0): Linear(in_features=50, out_features=512, bias=False)
          (1): Tanh()
          (2): Linear(in_features=512, out_features=512, bias=False)
        )
        (fc_x): Linear(in_features=32, out_features=64, bias=False)
        (fc_neib): Linear(in_features=50, out_features=64, bias=False)
        (dropout): Dropout(p=0.5)
      )
    )
    (edge_2_0): IdEdgeAggregator(
      (dropout): Dropout(p=0.5)
    )
    (mp_agg): MetapathAttentionLayer (1024 -> 1024)
    (fc): Sequential(
      (0): Linear(in_features=1024, out_features=32, bias=True)
      (1): ReLU()
      (2): Dropout(p=0.5)
      (3): Linear(in_features=32, out_features=3, bias=True)
    )
  )
)
{"epoch":0,"time":14.64309,"train_loss":47.85051}
{"epoch":0,"val_loss":131.72872,"val_metric":{"accuracy":0.58329,"micro":0.58329,"macro":0.41468},"test_metric":{"accuracy":0.60944,"micro":0.60944,"macro":0.4348},"tolerance:":0}
{"epoch":1,"time":44.64564,"train_loss":44.46937}
{"epoch":1,"val_loss":123.82645,"val_metric":{"accuracy":0.63628,"micro":0.63628,"macro":0.46785},"test_metric":{"accuracy":0.67239,"micro":0.67239,"macro":0.49147},"tolerance:":0}
{"epoch":2,"time":74.43041,"train_loss":43.41806}
{"epoch":2,"val_loss":116.03418,"val_metric":{"accuracy":0.642,"micro":0.642,"macro":0.4719},"test_metric":{"accuracy":0.67096,"micro":0.67096,"macro":0.4904},"tolerance:":1}
{"epoch":3,"time":104.79001,"train_loss":41.43616}
{"epoch":3,"val_loss":113.6409,"val_metric":{"accuracy":0.64296,"micro":0.64296,"macro":0.47294},"test_metric":{"accuracy":0.67525,"micro":0.67525,"macro":0.49364},"tolerance:":0}
{"epoch":4,"time":134.99535,"train_loss":40.28652}
{"epoch":4,"val_loss":113.0103,"val_metric":{"accuracy":0.64678,"micro":0.64678,"macro":0.47586},"test_metric":{"accuracy":0.6824,"micro":0.6824,"macro":0.49883},"tolerance:":0}
{"epoch":5,"time":164.86674,"train_loss":40.03378}
{"epoch":5,"val_loss":112.45286,"val_metric":{"accuracy":0.65155,"micro":0.65155,"macro":0.47933},"test_metric":{"accuracy":0.6824,"micro":0.6824,"macro":0.4989},"tolerance:":0}
{"epoch":6,"time":195.05113,"train_loss":39.12494}
{"epoch":6,"val_loss":112.08301,"val_metric":{"accuracy":0.64916,"micro":0.64916,"macro":0.47756},"test_metric":{"accuracy":0.68383,"micro":0.68383,"macro":0.49973},"tolerance:":0}
{"epoch":7,"time":224.8236,"train_loss":38.83993}
{"epoch":7,"val_loss":113.04569,"val_metric":{"accuracy":0.6506,"micro":0.6506,"macro":0.47879},"test_metric":{"accuracy":0.68383,"micro":0.68383,"macro":0.50009},"tolerance:":1}
{"epoch":8,"time":254.46624,"train_loss":37.99544}
{"epoch":8,"val_loss":112.29596,"val_metric":{"accuracy":0.6506,"micro":0.6506,"macro":0.47878},"test_metric":{"accuracy":0.68383,"micro":0.68383,"macro":0.49993},"tolerance:":2}
{"epoch":9,"time":284.68372,"train_loss":37.59266}
{"epoch":9,"val_loss":111.96421,"val_metric":{"accuracy":0.64869,"micro":0.64869,"macro":0.47716},"test_metric":{"accuracy":0.68383,"micro":0.68383,"macro":0.50001},"tolerance:":0}
{"epoch":10,"time":314.62144,"train_loss":37.10363}
{"epoch":10,"val_loss":111.84331,"val_metric":{"accuracy":0.64916,"micro":0.64916,"macro":0.47771},"test_metric":{"accuracy":0.68383,"micro":0.68383,"macro":0.49993},"tolerance:":0}
{"epoch":11,"time":344.38041,"train_loss":37.1363}
{"epoch":11,"val_loss":111.57512,"val_metric":{"accuracy":0.65012,"micro":0.65012,"macro":0.47842},"test_metric":{"accuracy":0.68813,"micro":0.68813,"macro":0.50324},"tolerance:":0}
{"epoch":12,"time":374.17235,"train_loss":36.25241}
{"epoch":12,"val_loss":112.27747,"val_metric":{"accuracy":0.65155,"micro":0.65155,"macro":0.47953},"test_metric":{"accuracy":0.68956,"micro":0.68956,"macro":0.50425},"tolerance:":0}
{"epoch":13,"time":404.27461,"train_loss":35.69197}
{"epoch":13,"val_loss":112.32574,"val_metric":{"accuracy":0.65107,"micro":0.65107,"macro":0.47925},"test_metric":{"accuracy":0.68383,"micro":0.68383,"macro":0.49997},"tolerance:":1}
{"epoch":14,"time":434.45075,"train_loss":35.08411}
{"epoch":14,"val_loss":112.7259,"val_metric":{"accuracy":0.6506,"micro":0.6506,"macro":0.47871},"test_metric":{"accuracy":0.68526,"micro":0.68526,"macro":0.50105},"tolerance:":2}
{"epoch":15,"time":464.4062,"train_loss":35.50756}
{"epoch":15,"val_loss":112.47198,"val_metric":{"accuracy":0.65251,"micro":0.65251,"macro":0.48012},"test_metric":{"accuracy":0.68526,"micro":0.68526,"macro":0.50105},"tolerance:":3}
{"epoch":16,"time":494.64539,"train_loss":34.53491}
{"epoch":16,"val_loss":115.9468,"val_metric":{"accuracy":0.64964,"micro":0.64964,"macro":0.47796},"test_metric":{"accuracy":0.68813,"micro":0.68813,"macro":0.503},"tolerance:":4}
{"epoch":17,"time":524.75812,"train_loss":34.64758}
{"epoch":17,"val_loss":115.57615,"val_metric":{"accuracy":0.64773,"micro":0.64773,"macro":0.47645},"test_metric":{"accuracy":0.68383,"micro":0.68383,"macro":0.49973},"tolerance:":5}
{"epoch":18,"time":555.13699,"train_loss":33.09185}
{"epoch":18,"val_loss":116.6221,"val_metric":{"accuracy":0.64726,"micro":0.64726,"macro":0.47645},"test_metric":{"accuracy":0.68097,"micro":0.68097,"macro":0.49748},"tolerance:":6}
{"epoch":19,"time":585.10473,"train_loss":32.61963}
{"epoch":19,"val_loss":120.63414,"val_metric":{"accuracy":0.6463,"micro":0.6463,"macro":0.47533},"test_metric":{"accuracy":0.68526,"micro":0.68526,"macro":0.5009},"tolerance:":7}
{"epoch":20,"time":615.39186,"train_loss":32.27857}
{"epoch":20,"val_loss":114.8927,"val_metric":{"accuracy":0.64916,"micro":0.64916,"macro":0.47769},"test_metric":{"accuracy":0.6824,"micro":0.6824,"macro":0.49868},"tolerance:":8}
{"epoch":21,"time":645.39849,"train_loss":30.842}
{"epoch":21,"val_loss":118.73096,"val_metric":{"accuracy":0.64296,"micro":0.64296,"macro":0.47657},"test_metric":{"accuracy":0.67668,"micro":0.67668,"macro":0.49544},"tolerance:":9}
{"epoch":22,"time":675.54776,"train_loss":30.30555}
{"epoch":22,"val_loss":118.26388,"val_metric":{"accuracy":0.64248,"micro":0.64248,"macro":0.47721},"test_metric":{"accuracy":0.66667,"micro":0.66667,"macro":0.48798},"tolerance:":10}
{"epoch":23,"time":705.41207,"train_loss":29.83982}
{"epoch":23,"val_loss":120.14304,"val_metric":{"accuracy":0.64344,"micro":0.64344,"macro":0.47663},"test_metric":{"accuracy":0.67096,"micro":0.67096,"macro":0.4904},"tolerance:":11}
{"epoch":24,"time":735.62823,"train_loss":28.67371}
{"epoch":24,"val_loss":125.08641,"val_metric":{"accuracy":0.63866,"micro":0.63866,"macro":0.48633},"test_metric":{"accuracy":0.66094,"micro":0.66094,"macro":0.49823},"tolerance:":12}
{"epoch":25,"time":765.4791,"train_loss":25.86545}
{"epoch":25,"val_loss":134.23897,"val_metric":{"accuracy":0.6315,"micro":0.6315,"macro":0.49578},"test_metric":{"accuracy":0.65808,"micro":0.65808,"macro":0.50948},"tolerance:":13}
{"epoch":26,"time":795.25711,"train_loss":24.36081}
{"epoch":26,"val_loss":138.09492,"val_metric":{"accuracy":0.62005,"micro":0.62005,"macro":0.52224},"test_metric":{"accuracy":0.61803,"micro":0.61803,"macro":0.5195},"tolerance:":14}
{"epoch":27,"time":824.70953,"train_loss":23.35521}
{"epoch":27,"val_loss":140.35156,"val_metric":{"accuracy":0.60907,"micro":0.60907,"macro":0.52713},"test_metric":{"accuracy":0.62089,"micro":0.62089,"macro":0.52752},"tolerance:":15}
{"epoch":28,"time":854.75124,"train_loss":22.2341}
{"epoch":28,"val_loss":144.93851,"val_metric":{"accuracy":0.5957,"micro":0.5957,"macro":0.5277},"test_metric":{"accuracy":0.6166,"micro":0.6166,"macro":0.54345},"tolerance:":16}
{"epoch":29,"time":885.88872,"train_loss":19.23253}
{"epoch":29,"val_loss":160.12257,"val_metric":{"accuracy":0.60239,"micro":0.60239,"macro":0.51796},"test_metric":{"accuracy":0.6166,"micro":0.6166,"macro":0.54268},"tolerance:":17}
{"epoch":30,"time":915.88111,"train_loss":18.70393}
{"epoch":30,"val_loss":174.05406,"val_metric":{"accuracy":0.57327,"micro":0.57327,"macro":0.52104},"test_metric":{"accuracy":0.58083,"micro":0.58083,"macro":0.5306},"tolerance:":18}
{"epoch":31,"time":945.74289,"train_loss":19.23427}
{"epoch":31,"val_loss":178.1187,"val_metric":{"accuracy":0.59761,"micro":0.59761,"macro":0.53051},"test_metric":{"accuracy":0.61087,"micro":0.61087,"macro":0.54445},"tolerance:":19}
{"epoch":32,"time":975.79921,"train_loss":14.8176}
{"epoch":32,"val_loss":184.17854,"val_metric":{"accuracy":0.56993,"micro":0.56993,"macro":0.52254},"test_metric":{"accuracy":0.58083,"micro":0.58083,"macro":0.52381},"tolerance:":20}
{"epoch":33,"time":1005.36408,"train_loss":14.45943}
{"epoch":33,"val_loss":182.7686,"val_metric":{"accuracy":0.57327,"micro":0.57327,"macro":0.53257},"test_metric":{"accuracy":0.60086,"micro":0.60086,"macro":0.55633},"tolerance:":21}
{"epoch":34,"time":1034.85458,"train_loss":12.82509}
{"epoch":34,"val_loss":189.77712,"val_metric":{"accuracy":0.56468,"micro":0.56468,"macro":0.52822},"test_metric":{"accuracy":0.59943,"micro":0.59943,"macro":0.55326},"tolerance:":22}
{"epoch":35,"time":1065.37047,"train_loss":12.4174}
{"epoch":35,"val_loss":202.47752,"val_metric":{"accuracy":0.56802,"micro":0.56802,"macro":0.52677},"test_metric":{"accuracy":0.58655,"micro":0.58655,"macro":0.53264},"tolerance:":23}
{"epoch":36,"time":1095.4437,"train_loss":10.22888}
{"epoch":36,"val_loss":212.83762,"val_metric":{"accuracy":0.56897,"micro":0.56897,"macro":0.52894},"test_metric":{"accuracy":0.59514,"micro":0.59514,"macro":0.54261},"tolerance:":24}
{"epoch":37,"time":1125.38357,"train_loss":11.09999}
{"epoch":37,"val_loss":216.23816,"val_metric":{"accuracy":0.57041,"micro":0.57041,"macro":0.53351},"test_metric":{"accuracy":0.60658,"micro":0.60658,"macro":0.55934},"tolerance:":25}
{"epoch":38,"time":1155.54185,"train_loss":10.00014}
{"epoch":38,"val_loss":226.2605,"val_metric":{"accuracy":0.57184,"micro":0.57184,"macro":0.5337},"test_metric":{"accuracy":0.58798,"micro":0.58798,"macro":0.53898},"tolerance:":26}
{"epoch":39,"time":1185.30394,"train_loss":9.35416}
{"epoch":39,"val_loss":224.38763,"val_metric":{"accuracy":0.57566,"micro":0.57566,"macro":0.53889},"test_metric":{"accuracy":0.59227,"micro":0.59227,"macro":0.5502},"tolerance:":27}
{"epoch":40,"time":1215.47613,"train_loss":8.86413}
{"epoch":40,"val_loss":232.03038,"val_metric":{"accuracy":0.57566,"micro":0.57566,"macro":0.53745},"test_metric":{"accuracy":0.58655,"micro":0.58655,"macro":0.54003},"tolerance:":28}
{"epoch":41,"time":1245.12805,"train_loss":8.72017}
{"epoch":41,"val_loss":240.90965,"val_metric":{"accuracy":0.57661,"micro":0.57661,"macro":0.53796},"test_metric":{"accuracy":0.58798,"micro":0.58798,"macro":0.5385},"tolerance:":29}
{"epoch":42,"time":1275.06447,"train_loss":8.30916}
{"epoch":42,"val_loss":249.97708,"val_metric":{"accuracy":0.58329,"micro":0.58329,"macro":0.53953},"test_metric":{"accuracy":0.58798,"micro":0.58798,"macro":0.53411},"tolerance:":30}
{"epoch":43,"time":1305.2316,"train_loss":6.6955}
{"epoch":43,"val_loss":245.04292,"val_metric":{"accuracy":0.56802,"micro":0.56802,"macro":0.53493},"test_metric":{"accuracy":0.58941,"micro":0.58941,"macro":0.55175},"tolerance:":31}
{"epoch":44,"time":1335.44612,"train_loss":7.78719}
{"epoch":44,"val_loss":243.0609,"val_metric":{"accuracy":0.57232,"micro":0.57232,"macro":0.53781},"test_metric":{"accuracy":0.58655,"micro":0.58655,"macro":0.54683},"tolerance:":32}
{"epoch":45,"time":1365.29554,"train_loss":8.82421}
{"epoch":45,"val_loss":222.84816,"val_metric":{"accuracy":0.57136,"micro":0.57136,"macro":0.53561},"test_metric":{"accuracy":0.60658,"micro":0.60658,"macro":0.56718},"tolerance:":33}
{"epoch":46,"time":1395.22986,"train_loss":7.1574}
{"epoch":46,"val_loss":228.139,"val_metric":{"accuracy":0.57804,"micro":0.57804,"macro":0.53592},"test_metric":{"accuracy":0.6123,"micro":0.6123,"macro":0.5643},"tolerance:":34}
{"epoch":47,"time":1425.5266,"train_loss":6.15044}
{"epoch":47,"val_loss":241.85148,"val_metric":{"accuracy":0.57804,"micro":0.57804,"macro":0.54094},"test_metric":{"accuracy":0.61373,"micro":0.61373,"macro":0.56843},"tolerance:":35}
{"epoch":48,"time":1455.32972,"train_loss":6.18098}
{"epoch":48,"val_loss":236.40713,"val_metric":{"accuracy":0.56181,"micro":0.56181,"macro":0.53456},"test_metric":{"accuracy":0.58512,"micro":0.58512,"macro":0.55078},"tolerance:":36}
{"epoch":49,"time":1485.05888,"train_loss":5.93685}
{"epoch":49,"val_loss":236.06356,"val_metric":{"accuracy":0.57184,"micro":0.57184,"macro":0.53998},"test_metric":{"accuracy":0.59943,"micro":0.59943,"macro":0.55625},"tolerance:":37}
{"epoch":50,"time":1515.13852,"train_loss":5.88403}
{"epoch":50,"val_loss":230.16443,"val_metric":{"accuracy":0.56754,"micro":0.56754,"macro":0.53789},"test_metric":{"accuracy":0.598,"micro":0.598,"macro":0.55882},"tolerance:":38}
{"epoch":51,"time":1545.23627,"train_loss":4.70869}
{"epoch":51,"val_loss":247.81694,"val_metric":{"accuracy":0.58377,"micro":0.58377,"macro":0.54383},"test_metric":{"accuracy":0.60372,"micro":0.60372,"macro":0.55413},"tolerance:":39}
{"epoch":52,"time":1575.04119,"train_loss":6.06175}
{"epoch":52,"val_loss":248.24498,"val_metric":{"accuracy":0.58616,"micro":0.58616,"macro":0.5433},"test_metric":{"accuracy":0.61946,"micro":0.61946,"macro":0.56444},"tolerance:":40}
{"epoch":53,"time":1605.06714,"train_loss":4.49054}
{"epoch":53,"val_loss":246.87565,"val_metric":{"accuracy":0.57947,"micro":0.57947,"macro":0.546},"test_metric":{"accuracy":0.59514,"micro":0.59514,"macro":0.54898},"tolerance:":41}
{"epoch":54,"time":1635.06766,"train_loss":4.51932}
{"epoch":54,"val_loss":247.81118,"val_metric":{"accuracy":0.5852,"micro":0.5852,"macro":0.55015},"test_metric":{"accuracy":0.60944,"micro":0.60944,"macro":0.56118},"tolerance:":42}
{"epoch":55,"time":1664.83285,"train_loss":4.39651}
{"epoch":55,"val_loss":251.59134,"val_metric":{"accuracy":0.5957,"micro":0.5957,"macro":0.5579},"test_metric":{"accuracy":0.60944,"micro":0.60944,"macro":0.56129},"tolerance:":43}
{"epoch":56,"time":1695.04269,"train_loss":3.6816}
{"epoch":56,"val_loss":246.8165,"val_metric":{"accuracy":0.58568,"micro":0.58568,"macro":0.55177},"test_metric":{"accuracy":0.60515,"micro":0.60515,"macro":0.56424},"tolerance:":44}
{"epoch":57,"time":1725.21841,"train_loss":3.52926}
{"epoch":57,"val_loss":260.42258,"val_metric":{"accuracy":0.57279,"micro":0.57279,"macro":0.54497},"test_metric":{"accuracy":0.59084,"micro":0.59084,"macro":0.55427},"tolerance:":45}
{"epoch":58,"time":1755.25683,"train_loss":3.44522}
{"epoch":58,"val_loss":265.04704,"val_metric":{"accuracy":0.59284,"micro":0.59284,"macro":0.54954},"test_metric":{"accuracy":0.6166,"micro":0.6166,"macro":0.56131},"tolerance:":46}
{"epoch":59,"time":1785.41444,"train_loss":3.98157}
{"epoch":59,"val_loss":253.99243,"val_metric":{"accuracy":0.59427,"micro":0.59427,"macro":0.55359},"test_metric":{"accuracy":0.62518,"micro":0.62518,"macro":0.57613},"tolerance:":47}
{"epoch":60,"time":1815.32893,"train_loss":4.66655}
{"epoch":60,"val_loss":247.80538,"val_metric":{"accuracy":0.59618,"micro":0.59618,"macro":0.54823},"test_metric":{"accuracy":0.61803,"micro":0.61803,"macro":0.55724},"tolerance:":48}
{"epoch":61,"time":1845.36599,"train_loss":3.14842}
{"epoch":61,"val_loss":261.73831,"val_metric":{"accuracy":0.58282,"micro":0.58282,"macro":0.53967},"test_metric":{"accuracy":0.60944,"micro":0.60944,"macro":0.5625},"tolerance:":49}
{"epoch":62,"time":1875.65104,"train_loss":5.073}
{"epoch":62,"val_loss":246.17148,"val_metric":{"accuracy":0.59379,"micro":0.59379,"macro":0.54903},"test_metric":{"accuracy":0.62375,"micro":0.62375,"macro":0.57037},"tolerance:":50}
{"epoch":63,"time":1905.63962,"train_loss":3.48227}
{"epoch":63,"val_loss":252.42903,"val_metric":{"accuracy":0.59905,"micro":0.59905,"macro":0.54998},"test_metric":{"accuracy":0.62947,"micro":0.62947,"macro":0.57086},"tolerance:":51}
{"epoch":64,"time":1935.54659,"train_loss":4.65736}
{"epoch":64,"val_loss":249.38821,"val_metric":{"accuracy":0.59379,"micro":0.59379,"macro":0.54745},"test_metric":{"accuracy":0.62518,"micro":0.62518,"macro":0.57106},"tolerance:":52}
{"epoch":65,"time":1965.38453,"train_loss":3.16158}
{"epoch":65,"val_loss":262.90248,"val_metric":{"accuracy":0.59905,"micro":0.59905,"macro":0.54676},"test_metric":{"accuracy":0.63805,"micro":0.63805,"macro":0.57974},"tolerance:":53}
{"epoch":66,"time":1995.41413,"train_loss":2.95215}
{"epoch":66,"val_loss":268.38787,"val_metric":{"accuracy":0.59666,"micro":0.59666,"macro":0.54662},"test_metric":{"accuracy":0.64092,"micro":0.64092,"macro":0.58463},"tolerance:":54}
{"epoch":67,"time":2025.42905,"train_loss":3.06702}
{"epoch":67,"val_loss":264.09559,"val_metric":{"accuracy":0.59427,"micro":0.59427,"macro":0.54443},"test_metric":{"accuracy":0.6309,"micro":0.6309,"macro":0.57413},"tolerance:":55}
{"epoch":68,"time":2055.37747,"train_loss":2.73182}
{"epoch":68,"val_loss":265.24968,"val_metric":{"accuracy":0.60334,"micro":0.60334,"macro":0.55545},"test_metric":{"accuracy":0.63948,"micro":0.63948,"macro":0.58087},"tolerance:":56}
{"epoch":69,"time":2085.21941,"train_loss":3.31714}
{"epoch":69,"val_loss":271.31858,"val_metric":{"accuracy":0.61814,"micro":0.61814,"macro":0.56359},"test_metric":{"accuracy":0.64521,"micro":0.64521,"macro":0.57948},"tolerance:":57}
{"epoch":70,"time":2115.31284,"train_loss":4.01913}
{"epoch":70,"val_loss":268.0022,"val_metric":{"accuracy":0.61098,"micro":0.61098,"macro":0.5552},"test_metric":{"accuracy":0.65236,"micro":0.65236,"macro":0.58671},"tolerance:":58}
{"epoch":71,"time":2145.49567,"train_loss":2.2651}
{"epoch":71,"val_loss":268.7574,"val_metric":{"accuracy":0.61241,"micro":0.61241,"macro":0.5555},"test_metric":{"accuracy":0.65808,"micro":0.65808,"macro":0.59515},"tolerance:":59}
{"epoch":72,"time":2175.54439,"train_loss":2.08324}
{"epoch":72,"val_loss":286.07138,"val_metric":{"accuracy":0.62673,"micro":0.62673,"macro":0.55382},"test_metric":{"accuracy":0.67382,"micro":0.67382,"macro":0.59364},"tolerance:":60}
{"epoch":73,"time":2205.42401,"train_loss":3.12193}
{"epoch":73,"val_loss":279.20768,"val_metric":{"accuracy":0.62005,"micro":0.62005,"macro":0.56325},"test_metric":{"accuracy":0.65951,"micro":0.65951,"macro":0.58898},"tolerance:":61}
{"epoch":74,"time":2235.76846,"train_loss":3.39951}
{"epoch":74,"val_loss":279.72044,"val_metric":{"accuracy":0.62148,"micro":0.62148,"macro":0.55752},"test_metric":{"accuracy":0.67239,"micro":0.67239,"macro":0.60045},"tolerance:":62}
{"epoch":75,"time":2266.21291,"train_loss":2.44977}
{"epoch":75,"val_loss":268.86077,"val_metric":{"accuracy":0.61384,"micro":0.61384,"macro":0.5643},"test_metric":{"accuracy":0.65379,"micro":0.65379,"macro":0.59743},"tolerance:":63}
{"epoch":76,"time":2296.19548,"train_loss":2.27359}
{"epoch":76,"val_loss":282.45297,"val_metric":{"accuracy":0.61432,"micro":0.61432,"macro":0.55735},"test_metric":{"accuracy":0.65236,"micro":0.65236,"macro":0.58834},"tolerance:":64}
{"epoch":77,"time":2325.96342,"train_loss":2.89716}
{"epoch":77,"val_loss":293.31186,"val_metric":{"accuracy":0.62291,"micro":0.62291,"macro":0.55649},"test_metric":{"accuracy":0.67382,"micro":0.67382,"macro":0.6071},"tolerance:":65}
{"epoch":78,"time":2356.17194,"train_loss":2.11639}
{"epoch":78,"val_loss":293.06568,"val_metric":{"accuracy":0.62673,"micro":0.62673,"macro":0.56202},"test_metric":{"accuracy":0.67525,"micro":0.67525,"macro":0.60248},"tolerance:":66}
{"epoch":79,"time":2386.05312,"train_loss":1.76274}
{"epoch":79,"val_loss":299.07203,"val_metric":{"accuracy":0.62768,"micro":0.62768,"macro":0.56099},"test_metric":{"accuracy":0.67382,"micro":0.67382,"macro":0.60118},"tolerance:":67}
{"epoch":80,"time":2416.36391,"train_loss":2.69238}
{"epoch":80,"val_loss":303.98081,"val_metric":{"accuracy":0.62768,"micro":0.62768,"macro":0.5534},"test_metric":{"accuracy":0.66953,"micro":0.66953,"macro":0.58574},"tolerance:":68}
{"epoch":81,"time":2446.59986,"train_loss":2.66654}
{"epoch":81,"val_loss":272.31142,"val_metric":{"accuracy":0.62387,"micro":0.62387,"macro":0.55507},"test_metric":{"accuracy":0.6495,"micro":0.6495,"macro":0.57581},"tolerance:":69}
{"epoch":82,"time":2476.88925,"train_loss":2.95646}
{"epoch":82,"val_loss":290.35792,"val_metric":{"accuracy":0.62864,"micro":0.62864,"macro":0.55724},"test_metric":{"accuracy":0.67239,"micro":0.67239,"macro":0.59836},"tolerance:":70}
{"epoch":83,"time":2507.3689,"train_loss":3.61726}
{"epoch":83,"val_loss":286.33585,"val_metric":{"accuracy":0.63341,"micro":0.63341,"macro":0.56236},"test_metric":{"accuracy":0.66953,"micro":0.66953,"macro":0.596},"tolerance:":71}
{"epoch":84,"time":2537.22244,"train_loss":1.98968}
{"epoch":84,"val_loss":286.87969,"val_metric":{"accuracy":0.63484,"micro":0.63484,"macro":0.56291},"test_metric":{"accuracy":0.66524,"micro":0.66524,"macro":0.59051},"tolerance:":72}
{"epoch":85,"time":2567.09416,"train_loss":1.86723}
{"epoch":85,"val_loss":289.12754,"val_metric":{"accuracy":0.62482,"micro":0.62482,"macro":0.55285},"test_metric":{"accuracy":0.66381,"micro":0.66381,"macro":0.58727},"tolerance:":73}
{"epoch":86,"time":2596.98644,"train_loss":1.9182}
{"epoch":86,"val_loss":290.01125,"val_metric":{"accuracy":0.63484,"micro":0.63484,"macro":0.56603},"test_metric":{"accuracy":0.67096,"micro":0.67096,"macro":0.6024},"tolerance:":74}
{"epoch":87,"time":2627.26795,"train_loss":2.02302}
{"epoch":87,"val_loss":291.51267,"val_metric":{"accuracy":0.6315,"micro":0.6315,"macro":0.56245},"test_metric":{"accuracy":0.66667,"micro":0.66667,"macro":0.59488},"tolerance:":75}
{"epoch":88,"time":2657.21613,"train_loss":2.67875}
{"epoch":88,"val_loss":297.94488,"val_metric":{"accuracy":0.63532,"micro":0.63532,"macro":0.56271},"test_metric":{"accuracy":0.66667,"micro":0.66667,"macro":0.58933},"tolerance:":76}
{"epoch":89,"time":2687.27772,"train_loss":2.58937}
{"epoch":89,"val_loss":297.18464,"val_metric":{"accuracy":0.63246,"micro":0.63246,"macro":0.56827},"test_metric":{"accuracy":0.65951,"micro":0.65951,"macro":0.59062},"tolerance:":77}
{"epoch":90,"time":2717.37185,"train_loss":1.70892}
{"epoch":90,"val_loss":316.93224,"val_metric":{"accuracy":0.6358,"micro":0.6358,"macro":0.55647},"test_metric":{"accuracy":0.66953,"micro":0.66953,"macro":0.59005},"tolerance:":78}
{"epoch":91,"time":2747.42785,"train_loss":2.60838}
{"epoch":91,"val_loss":298.42809,"val_metric":{"accuracy":0.63246,"micro":0.63246,"macro":0.56884},"test_metric":{"accuracy":0.66524,"micro":0.66524,"macro":0.59547},"tolerance:":79}
{"epoch":92,"time":2777.37966,"train_loss":2.80202}
{"epoch":92,"val_loss":298.00526,"val_metric":{"accuracy":0.63103,"micro":0.63103,"macro":0.57388},"test_metric":{"accuracy":0.67096,"micro":0.67096,"macro":0.61029},"tolerance:":80}
{"epoch":93,"time":2807.16479,"train_loss":3.06615}
{"epoch":93,"val_loss":289.50192,"val_metric":{"accuracy":0.63437,"micro":0.63437,"macro":0.56124},"test_metric":{"accuracy":0.66381,"micro":0.66381,"macro":0.58908},"tolerance:":81}
{"epoch":94,"time":2837.28736,"train_loss":1.98911}
{"epoch":94,"val_loss":287.14259,"val_metric":{"accuracy":0.63246,"micro":0.63246,"macro":0.56066},"test_metric":{"accuracy":0.66524,"micro":0.66524,"macro":0.59189},"tolerance:":82}
{"epoch":95,"time":2867.47343,"train_loss":1.46283}
{"epoch":95,"val_loss":306.15447,"val_metric":{"accuracy":0.63675,"micro":0.63675,"macro":0.56074},"test_metric":{"accuracy":0.67668,"micro":0.67668,"macro":0.59584},"tolerance:":83}
{"epoch":96,"time":2897.30072,"train_loss":1.80969}
{"epoch":96,"val_loss":306.72435,"val_metric":{"accuracy":0.63628,"micro":0.63628,"macro":0.56912},"test_metric":{"accuracy":0.68526,"micro":0.68526,"macro":0.6179},"tolerance:":84}
{"epoch":97,"time":2927.35751,"train_loss":2.80298}
{"epoch":97,"val_loss":304.38625,"val_metric":{"accuracy":0.64153,"micro":0.64153,"macro":0.58154},"test_metric":{"accuracy":0.6824,"micro":0.6824,"macro":0.62208},"tolerance:":85}
{"epoch":98,"time":2957.36006,"train_loss":3.80551}
{"epoch":98,"val_loss":298.83083,"val_metric":{"accuracy":0.64153,"micro":0.64153,"macro":0.577},"test_metric":{"accuracy":0.67525,"micro":0.67525,"macro":0.60931},"tolerance:":86}
{"epoch":99,"time":2987.42711,"train_loss":3.02425}
{"epoch":99,"val_loss":296.01108,"val_metric":{"accuracy":0.63437,"micro":0.63437,"macro":0.55307},"test_metric":{"accuracy":0.68097,"micro":0.68097,"macro":0.59695},"tolerance:":87}
{"epoch":100,"time":3017.47638,"train_loss":2.19638}
{"epoch":100,"val_loss":297.58609,"val_metric":{"accuracy":0.63437,"micro":0.63437,"macro":0.56466},"test_metric":{"accuracy":0.67954,"micro":0.67954,"macro":0.60704},"tolerance:":88}
{"epoch":101,"time":3047.5851,"train_loss":2.38833}
{"epoch":101,"val_loss":300.50885,"val_metric":{"accuracy":0.63628,"micro":0.63628,"macro":0.56362},"test_metric":{"accuracy":0.67954,"micro":0.67954,"macro":0.60336},"tolerance:":89}
{"epoch":102,"time":3077.49244,"train_loss":2.35452}
{"epoch":102,"val_loss":299.43685,"val_metric":{"accuracy":0.63484,"micro":0.63484,"macro":0.56104},"test_metric":{"accuracy":0.67811,"micro":0.67811,"macro":0.59827},"tolerance:":90}
{"epoch":103,"time":3107.80422,"train_loss":1.62862}
{"epoch":103,"val_loss":303.23616,"val_metric":{"accuracy":0.63771,"micro":0.63771,"macro":0.56961},"test_metric":{"accuracy":0.6824,"micro":0.6824,"macro":0.61354},"tolerance:":91}
{"epoch":104,"time":3137.68177,"train_loss":2.17792}
{"epoch":104,"val_loss":312.45248,"val_metric":{"accuracy":0.63771,"micro":0.63771,"macro":0.55816},"test_metric":{"accuracy":0.67954,"micro":0.67954,"macro":0.58881},"tolerance:":92}
{"epoch":105,"time":3167.69423,"train_loss":2.05362}
{"epoch":105,"val_loss":316.33325,"val_metric":{"accuracy":0.63819,"micro":0.63819,"macro":0.55467},"test_metric":{"accuracy":0.67811,"micro":0.67811,"macro":0.5859},"tolerance:":93}
{"epoch":106,"time":3197.72101,"train_loss":3.32831}
{"epoch":106,"val_loss":293.503,"val_metric":{"accuracy":0.63675,"micro":0.63675,"macro":0.56743},"test_metric":{"accuracy":0.67954,"micro":0.67954,"macro":0.60336},"tolerance:":94}
{"epoch":107,"time":3227.88598,"train_loss":2.15823}
{"epoch":107,"val_loss":273.7842,"val_metric":{"accuracy":0.62816,"micro":0.62816,"macro":0.57077},"test_metric":{"accuracy":0.67525,"micro":0.67525,"macro":0.62158},"tolerance:":95}
{"epoch":108,"time":3258.09303,"train_loss":2.26625}
{"epoch":108,"val_loss":300.63829,"val_metric":{"accuracy":0.64057,"micro":0.64057,"macro":0.55503},"test_metric":{"accuracy":0.68097,"micro":0.68097,"macro":0.58558},"tolerance:":96}
{"epoch":109,"time":3287.93532,"train_loss":1.98027}
{"epoch":109,"val_loss":322.6062,"val_metric":{"accuracy":0.63628,"micro":0.63628,"macro":0.55682},"test_metric":{"accuracy":0.67382,"micro":0.67382,"macro":0.58192},"tolerance:":97}
{"epoch":110,"time":3317.99635,"train_loss":2.08441}
{"epoch":110,"val_loss":316.32207,"val_metric":{"accuracy":0.63437,"micro":0.63437,"macro":0.55858},"test_metric":{"accuracy":0.67382,"micro":0.67382,"macro":0.58432},"tolerance:":98}
{"epoch":111,"time":3348.15006,"train_loss":2.49966}
{"epoch":111,"val_loss":305.54343,"val_metric":{"accuracy":0.64153,"micro":0.64153,"macro":0.56522},"test_metric":{"accuracy":0.67954,"micro":0.67954,"macro":0.58908},"tolerance:":99}
{"epoch":112,"time":3378.10239,"train_loss":1.38627}
{"epoch":112,"val_loss":311.48275,"val_metric":{"accuracy":0.63914,"micro":0.63914,"macro":0.55524},"test_metric":{"accuracy":0.67668,"micro":0.67668,"macro":0.58213},"tolerance:":100}
{"epoch":113,"time":3408.01916,"train_loss":1.39402}
{"epoch":113,"val_loss":330.42932,"val_metric":{"accuracy":0.642,"micro":0.642,"macro":0.54751},"test_metric":{"accuracy":0.6824,"micro":0.6824,"macro":0.57411},"tolerance:":101}
{"epoch":12,"val_loss":112.27747,"val_metric":{"accuracy":0.65155,"micro":0.65155,"macro":0.47953},"test_metric":{"accuracy":0.68956,"micro":0.68956,"macro":0.50425}}
/home/daniel/local/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/home/daniel/local/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1145: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.
  'recall', 'true', average, warn_for)
-- done --
